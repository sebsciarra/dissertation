% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See https://www.reed.edu/cis/help/LaTeX/index.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

%%
%% Preamble
\documentclass[
12pt, % The default document font size, options: 10pt, 11pt, 12pt
twoside,
english]{guelphthesis}
%----------------------------------------------------------------------------------------
% PACKAGES
%----------------------------------------------------------------------------------------

\usepackage{tocloft} %needed for table of contents, list of figures, list of tables, list of appendices
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}

\usepackage{longtable,booktabs,setspace}
\usepackage{lmodern}
\usepackage{float}
\usepackage{etoolbox}
\floatplacement{figure}{H}
% Thanks, @Xyv
\usepackage{calc}
% End of CII addition
\usepackage{rotating}
\usepackage{tocbibind} %includes list of figures, list of tables, and table of contents in table of contents
\usepackage{indentfirst} %needed so that first paragraph after each section titles has indent
\usepackage{lineno} %allows option for line numbering
\usepackage{draftwatermark} %for draft watermark
\SetWatermarkText{} %ensures draft is not printed when draft:false


% Syntax highlighting #22
  \usepackage{color}
  \usepackage{fancyvrb}
  \newcommand{\VerbBar}{|}
  \newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
  % Add ',fontsize=\small' for more characters per line
  \usepackage{framed}
  \definecolor{shadecolor}{RGB}{248,248,248}
  \newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
  \newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
  \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
  \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\BuiltInTok}[1]{#1}
  \newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
  \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
  \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
  \newcommand{\ExtensionTok}[1]{#1}
  \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\ImportTok}[1]{#1}
  \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\NormalTok}[1]{#1}
  \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
  \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
  \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\RegionMarkerTok}[1]{#1}
  \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
  \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}



% To pass between YAML and LaTeX the dollar signs are added by CII
\title{Is Timing Everything? The Effects of Measurement Timing on the Performance of Nonlinear Longitudinal Models}
\author{Sebastian L.V. Sciarra}
\year{2023}
\date{March, 2023}
\advisor{David Stanley}
\institution{University of Guelph}
\degree{Doctorate of Philosophy}



\field{Industrial-Organizational Psychology}
\department{Psychology}



  \let\cleardoublepage\clearpage

% From {rticles}
%


\urlstyle{rm}

%----------------------------------------------------------------------------------------
% CUSTOM COMMANDS
%----------------------------------------------------------------------------------------
%numbers lines before equations
%taken from https://tex.stackexchange.com/questions/43648/why-doesnt-lineno-number-a-paragraph-when-it-is-followed-by-an-align-equation
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
  \expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
  \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
  \renewenvironment{#1}%
     {\linenomath\csname old#1\endcsname}%
     {\csname oldend#1\endcsname\endlinenomath}}%
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
  \patchAmsMathEnvironmentForLineno{#1}%
  \patchAmsMathEnvironmentForLineno{#1*}}%
\AtBeginDocument{%
\patchBothAmsMathEnvironmentsForLineno{equation}%
\patchBothAmsMathEnvironmentsForLineno{align}%
\patchBothAmsMathEnvironmentsForLineno{flalign}%
\patchBothAmsMathEnvironmentsForLineno{alignat}%
\patchBothAmsMathEnvironmentsForLineno{gather}%
\patchBothAmsMathEnvironmentsForLineno{multline}%
}


%nest all the \frontmatter functions in \oldfrontmatter, which allows us to redefine \frontmatter as everything it was with one modification to the
%draft watermark
\let\oldfrontmatter\frontmatter
%set page numbering to bottom center for \frontmatter
\fancypagestyle{frontmatter}{%
 \fancyhf{}% clear all header and footer fields
  \renewcommand{\headrulewidth}{0pt}
  \fancyhead[R]{\roman{page}}% Roman page number in footer centre

  }

\renewcommand{\frontmatter}{
  \oldfrontmatter
  
   %set page number font to Arial if ArialFont: false in YAML header
  
   \pagestyle{frontmatter} % add this to center page numbers
}

%set page numbering to bottom center for \mainmatter
\fancypagestyle{mainmatter}{%
 \fancyhf{}% clear all header and footer fields
  \renewcommand{\headrulewidth}{0pt}
  \fancyfoot[C]{\arabic{page}}% Roman page number in footer centre

   \hypersetup{pdfpagemode={UseOutlines},
    bookmarksopen=true,
    hypertexnames=true,
    colorlinks = true,
    allcolors = blue,
    %linkcolor = blue,
    %urlcolor= blue,
    %anchorcolor = blue,
    pdfstartview={FitV},
    breaklinks=true,
    hyperindex = true,
    backref=page}

  \cleardoublepage

  


}

%nest all the \mainmatter functions in \oldmainmatter, which allows us to redefine \mainmatter as everything it was with one modification to the
%page numbering format
\newcommand{\setMainMatterLinespacing}{
 \setstretch{2} %default line spacing

  %change line spacing if specified in YAML header
        \setstretch{2}
  }

\let\oldmainmatter\mainmatter
\renewcommand{\mainmatter}{
  \oldmainmatter

  %change line spacing if specified in YAML header
  \setMainMatterLinespacing

      \linenumbers
  
  \pagestyle{mainmatter} % add this to center page numbers

}

%code below is important for linespacing to remain unaffected when kableExtra::landscape() is used andthe margin is specifically defined. Otherwise,
%linespacing for entire document goes to singlespacing for the text that follows the table.
\let\oldRestoreGeometry\restoregeometry
\renewcommand{\restoregeometry}{
  \oldRestoreGeometry

  %change line spacing if specified in YAML header
  \setMainMatterLinespacing
}

%change footnote and page number font to arial if desired

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS, LIST OF FIGURES, & LIST OF TABLES
%----------------------------------------------------------------------------------------
%TABLE OF CONTENTS
\setlength{\cftbeforetoctitleskip}{0cm} %remove vertical space above table of contents

%two lines below ensure centered title for toc
%needed so that table of contents entry is not indented
\renewcommand{\contentsname}{Table of Contents} %change title for toc
\renewcommand{\cfttoctitlefont}{\hfill\fontsize{14}{14}\selectfont\bfseries\MakeUppercase}
\renewcommand{\cftaftertoctitle}{\hfill\hfill} %sometimes another \hfill is needed; depends on some setting in abovce code

%fonts for all entry level titles
\renewcommand\cftchapfont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsecfont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsubsecfont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsubsubsecfont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftparafont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsubparafont{\mdseries} %eliminate bolded chapter titles in toc

%fonts for all entry level page numbers
\renewcommand{\cftchappagefont}{\mdseries} %remove bolding of page numbers for chapter headers in toc
\renewcommand\cftsecpagefont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsubsecpagefont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsubsubsecpagefont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftparapagefont{\mdseries} %eliminate bolded chapter titles in toc
\renewcommand\cftsubparapagefont{\mdseries} %eliminate bolded chapter titles in toc

\renewcommand{\cftchapleader}{\cftdotfill{0.1}} %remove chapter bolding + modif dot spacing
\renewcommand{\cftdotsep}{0.1} %make dots in toc closer together

%spacing between toc items (should be all equal)
\setlength{\cftbeforechapskip}{0cm} %removes spacing before each chapter element
\renewcommand{\cftchapafterpnum}{\vskip6pt}
\renewcommand{\cftsecafterpnum}{\vskip6pt}
\renewcommand{\cftsubsecafterpnum}{\vskip6pt}
\renewcommand{\cftsubsubsecafterpnum}{\vskip6pt}
\renewcommand{\cftparaafterpnum}{\vskip6pt}
\renewcommand{\cftsubparaafterpnum}{\vskip6pt}

%remove header that appears in table of contents after first page
\renewcommand{\cftmarktoc}{}

%commands need to be redefined so that leading dots go all the way to the page numbers for all header levels (chap, sec, subsec, subsubsec, para, subpara
%%%general framework for commands below: cftXfillnum sets the format for the leading dots (\cftchapleader) and the page number (\cftchappagefont) such that leading dots proceed all the way to the page number with no spaces between dots and page number (\nobreak) at which wpoint paragraph mode ends (\par) and vertical spacing (defined  above) after item entry is inserted
%chapter (level 0)
\renewcommand{\cftchapfillnum}[1]{%
  {\cftchapleader}\nobreak
  {\cftchappagefont #1}\par\cftchapafterpnum
}

%sec (level 1)
\renewcommand{\cftsecfillnum}[1]{%
  {\cftsecleader}\nobreak
  {\cftsecpagefont #1}\par\cftsecafterpnum
}

%subsec (level 2)
\renewcommand{\cftsubsecfillnum}[1]{%
  {\cftsubsecleader}\nobreak
  {\cftsubsecpagefont #1}\par\cftsubsecafterpnum
}

%subsubsec (level 3)
\renewcommand{\cftsubsubsecfillnum}[1]{%
  {\cftsubsubsecleader}\nobreak
  {\cftsubsubsecpagefont #1}\par\cftsubsubsecafterpnum
}

%para (level 4)
\renewcommand{\cftparafillnum}[1]{%
  {\cftparaleader}\nobreak
  {\cftparapagefont #1}\par\cftparaafterpnum
}

%subpara (level 5)
\renewcommand{\cftsubparafillnum}[1]{%
  {\cftsubparaleader}\nobreak
  {\cftsubparapagefont #1}\par\cftsubparaafterpnum
}

%LIST OF TABLES
\renewcommand{\cfttabfont}{\mdseries} %set font for entries in lot
\renewcommand{\cfttabpagefont}{\mdseries} %set front for page numbers

\setlength{\cftbeforelottitleskip}{0cm} %remove vertical space above table of contents
\setlength{\cftafterlottitleskip}{0.5cm} %space between title for list of tables and list entries
%two lines below ensure centered title for toc
%needed so that table of contents entry is not indented
\renewcommand{\cftlottitlefont}{\hfill\fontsize{14}{14}\selectfont\bfseries\MakeUppercase}
\renewcommand{\cftafterlottitle}{\hfill} %sometimes another \hfill is needed; depends on some setting in abovce code

%commands need to be redefined so that leading dots go all the way to the page numbers for tables
%%%general framework for command below: cftfigfillnum sets the format for the leading dots (\cftfigleader) and the page number (\cftfigpagefont) such that leading dots proceed all the way to the page number with no spaces between dots and page number (\nobreak) at which point paragraph mode ends (\par) and vertical spacing (defined  below) after item entry is inserted
\setlength{\cftbeforetabskip}{0cm} %removes spacing before each chapter element
\renewcommand{\cfttabafterpnum}{\vskip6pt}

\renewcommand{\cfttabfillnum}[1]{%
  {\cfttableader}\nobreak
  {\cfttabpagefont #1}\par\cfttabafterpnum
}

%remove header that appears in list of tables after first page
\renewcommand{\cftmarklot}{}

%LIST OF FIGURES
\renewcommand{\cftfigfont}{\mdseries} %set font for entries in lof
\renewcommand{\cftfigpagefont}{\mdseries} %set front for page numbers

\setlength{\cftbeforeloftitleskip}{0cm} %remove vertical space above table of contents
\setlength{\cftafterloftitleskip}{0.5cm} %space between title for list of figures and list entries

%two lines below ensure centered title for toc
%needed so that table of contents entry is not indented
\renewcommand{\cftloftitlefont}{\hfill\fontsize{14}{14}\selectfont\bfseries\MakeUppercase}
\renewcommand{\cftafterloftitle}{\hfill} %sometimes another \hfill is needed; depends on some setting in abovce code

%commands need to be redefined so that leading dots go all the way to the page numbers for figures
%%%general framework for command below: cftfigfillnum sets the format for the leading dots (\cftfigleader) and the page number (\cftfigpagefont) such that leading dots proceed all the way to the page number with no spaces between dots and page number (\nobreak) at which wpoint paragraph mode ends (\par) and vertical spacing (defined  below) after item entry is inserted
\setlength{\cftbeforefigskip}{0cm} %removes spacing before each chapter element
\renewcommand{\cftfigafterpnum}{\vskip6pt}

\renewcommand{\cftfigfillnum}[1]{%
  {\cftfigleader}\nobreak
  {\cftfigpagefont #1}\par\cftfigafterpnum
}

%remove header that appears in list of figures after first page
\renewcommand{\cftmarklof}{}

%----------------------------------------------------------------------------------------
% LIST OF APPENDICES
%----------------------------------------------------------------------------------------
\newcommand{\listappname}{List of Appendices}
\newlistof[chapter]{app}{loa}{\listappname} %creates a new appendix counter that will be reset at the start of each \chapter

\setcounter{loadepth}{5} %loa will  go to depth of level 5
\setlength{\cftbeforeloatitleskip}{0cm} %remove vertical space above loa
\setlength{\cftafterloatitleskip}{0.5cm} %space between title for loa and list entries
\renewcommand{\cftmarkloa}{} %remove header titles

%two lines below ensure centered title for loa
%needed so that table of contents entry is not indented
\renewcommand{\cftloatitlefont}{\hfill\fontsize{14}{14}\selectfont\bfseries\MakeUppercase}
\renewcommand{\cftafterloatitle}{\hfill\hfill} %sometimes another \hfill is needed; depends on some setting in above code


%APPENDIX (level 0)
\renewcommand{\theapp}{\Alph{app}} %sets alphabetic counter for appendix
\renewcommand{\cftappfont}{\mdseries} %set font for level 0 entry in loa
\renewcommand{\cftapppagefont}{\mdseries} %set front for page numbers

\renewcommand{\cftapppresnum}{Appendix\space}
\renewcommand{\cftappaftersnum}{:\space}
\settowidth{\cftappnumwidth}{\cftapppresnum\theapp\cftappaftersnum\space}

\setlength{\cftbeforeappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftappafterpnum}{\vskip6pt}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\app}[1]{%
  \refstepcounter{app}\pdfbookmark[-1]{\cftapppresnum\theapp\cftappaftersnum#1}{#1\theapp}%
  \chapter*{\fontsize{16}{16}\selectfont\bfseries\cftapppresnum\theapp\cftappaftersnum #1} %formats entry in document
  \addcontentsline{loa}{app}{{\cftapppresnum\theapp\cftappaftersnum}#1}%
  \par
}

% figure and table counting in appendix
\usepackage{chngcntr}


%leading dots for appendix (end immediately before page number)
\renewcommand{\cftappfillnum}[1]{%
 {\cftappleader}\nobreak{\cftapppagefont #1}\par\cftappafterpnum
}

%SECAPPENDIX (level 1; format A.1 : title)
\newlistentry[app]{secapp}{loa}{1}
\renewcommand{\thesecapp}{\theapp.\arabic{secapp}}
\renewcommand{\cftsecappfont}{\mdseries} %set font for level 1 entry in loa
\renewcommand{\cftsecapppagefont}{\mdseries} %set front for page numbers

\renewcommand{\cftsecapppresnum}{} %remove word 'Appendix'
\renewcommand{\cftsecappaftersnum}{\hspace{0.5cm}}  %replicate toc format for sub-level-0 headers \thesubappendix (i.e., A.1   title )

\setlength{\cftbeforesecappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftsecappafterpnum}{\vskip6pt}
\setlength{\cftsecappindent}{1.55em} %indentation in loa
\settowidth{\cftsecappnumwidth}{\cftsecapppresnum\thesecapp\cftsecappaftersnum\hspace{0.3cm}}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\secapp}[1]{%
  \refstepcounter{secapp}\pdfbookmark[0]{#1}{#1\thesubapp}%
  \section*{\thesecapp\hspace{0.3cm} #1} %spacing between section number and title in text
  \addcontentsline{loa}{secapp}{{\thesecapp\cftsecappaftersnum}#1}%
  \par
}

%leading dots for appendix (end immediately before page number)
\renewcommand{\cftsecappfillnum}[1]{%
 {\cftsecappleader}\nobreak{\cftsecapppagefont #1}\par\cftsecappafterpnum
}


%SUBAPPENDIX (level 2; format A.1.1 : title)
\newlistentry[app]{subapp}{loa}{1}
\renewcommand{\thesubapp}{\thesecapp.\arabic{subapp}}
\renewcommand{\cftsubappfont}{\mdseries} %set font for level 2 entry in loa
\renewcommand{\cftsubapppagefont}{\mdseries} %set front for page numbers

\renewcommand{\cftsubapppresnum}{} %remove word 'Appendix'
\renewcommand{\cftsubappaftersnum}{\hspace{0.5cm}}  %replicate toc format for sub-level-0 headers \thesubappendix (i.e., A.1   title )

\setlength{\cftbeforesubappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftsubappafterpnum}{\vskip6pt}
\setlength{\cftsubappindent}{3.10em} %indentation in loa
%\renewcommand{\cftsubappnumwidth}{1.47cm}
\settowidth{\cftsubappnumwidth}{\thesubapp\cftsubappaftersnum\hspace{0.3cm}}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\subapp}[1]{%
  \refstepcounter{subapp}\pdfbookmark[1]{#1}{#1\thesubapp}%
  \subsection*{\thesubapp\hspace{0.3cm} #1}%
  \addcontentsline{loa}{subapp}{{\thesubapp\cftsubappaftersnum}#1}%
  \par
}

%leading dots for appendix (end immediately before page number)
\renewcommand{\cftsubappfillnum}[1]{%
 {\cftsubappleader}\nobreak{\cftsubapppagefont #1}\par\cftsubappafterpnum
}


% SUBSUBAPPENDIX (level 3; format A.1.1.1  title)
\newlistentry[app]{subsubapp}{loa}{1}
\renewcommand{\thesubsubapp}{\thesubapp.\arabic{subsubapp}}
\renewcommand{\cftsubsubappfont}{\mdseries} %set font for level 3 entry in loa
\renewcommand{\cftsubsubapppagefont}{\mdseries} %set front for page numbers


\renewcommand{\cftsubsubapppresnum}{} %remove word 'Appendix'
\renewcommand{\cftsubsubappaftersnum}{\hspace{0.5cm}}  %space after subsubapp title

\setlength{\cftbeforesubsubappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftsubsubappafterpnum}{\vskip6pt}
\setlength{\cftsubsubappindent}{4.65em} %indentation in loa (1.55 *2)
\settowidth{\cftsubsubappnumwidth}{\thesubsubapp\cftsubsubappaftersnum\hspace{0.3cm}}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\subsubapp}[1]{%
  \refstepcounter{subsubapp}\pdfbookmark[2]{#1}{#1\thesubsubapp}%
  \subsubsection*{\thesubsubapp\hspace{0.3cm} #1}%
  \addcontentsline{loa}{subsubapp}{{\thesubsubapp\cftsubsubappaftersnum}#1}%
  \par
}

%leading dots for appendix (end immediately before page number)
\renewcommand{\cftsubsubappfillnum}[1]{%
 {\cftsubsubappleader}\nobreak{\cftsubsubapppagefont #1}\par\cftsubsubappafterpnum
}

% PARA (level 4; format A.1.1.1.1  title)
\newlistentry[app]{paraapp}{loa}{1}
\renewcommand{\theparaapp}{\thesubsubapp.\arabic{paraapp}}
\renewcommand{\cftparaappfont}{\mdseries} %set font for level 4 entry in loa
\renewcommand{\cftparaapppagefont}{\mdseries} %set front for page numbers

\renewcommand{\cftparaapppresnum}{} %remove word 'Appendix'
\renewcommand{\cftparaappaftersnum}{\hspace{0.5cm}}  %space after paraapp title

\setlength{\cftbeforeparaappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftparaappafterpnum}{\vskip6pt}
\setlength{\cftparaappindent}{6.2em} %indentation in loa (1.55 *2)
\settowidth{\cftparaappnumwidth}{\theparaapp\cftparaappaftersnum\hspace{0.3cm}}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\paraapp}[1]{%
  \refstepcounter{paraapp}\pdfbookmark[3]{#1}{#1\theparaapp}%
  \paragraph*{\theparaapp\hspace{0.3cm} #1}%
  \addcontentsline{loa}{paraapp}{{\theparaapp\cftparaappaftersnum}#1}%
  \par
}

%leading dots for appendix (end immediately before page number)
\renewcommand{\cftparaappfillnum}[1]{%
 {\cftparaappleader}\nobreak{\cftparaapppagefont #1}\par\cftparaappafterpnum
}

% SUBPARA (level 5; format A.1.1.1.1  title)
\newlistentry[app]{subparaapp}{loa}{1}
\renewcommand{\thesubparaapp}{\theparaapp.\arabic{subparaapp}}
\renewcommand{\cftsubparaappfont}{\mdseries} %set font for level 5 entry in loa
\renewcommand{\cftsubparaapppagefont}{\mdseries} %set front for page numbers

\renewcommand{\cftsubparaapppresnum}{} %remove word 'Appendix'
\renewcommand{\cftsubparaappaftersnum}{\hspace{0.5cm}}  %space after subparaapp title

\setlength{\cftbeforesubparaappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftsubparaappafterpnum}{\vskip6pt}
\setlength{\cftsubparaappindent}{7.75em} %indentation in loa (1.55 *2)
\settowidth{\cftsubparaappnumwidth}{\thesubparaapp\cftsubparaappaftersnum\hspace{0.3cm}}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\subparaapp}[1]{%
  \refstepcounter{subparaapp}\pdfbookmark[4]{#1}{#1\thesubparaapp}%
  \paragraph*{\thesubparaapp\hspace{0.3cm} #1} %paragraph is used because subparagraph has weird numbering problem
  \addcontentsline{loa}{subparaapp}{{\thesubparaapp\cftsubparaappaftersnum}#1}%
  \par
}

%SUBSUBPARA (level 6; format A.1.1.1.1.1  title)
\newlistentry[app]{subsubparaapp}{loa}{1}
\renewcommand{\thesubsubparaapp}{\thesubparaapp.\arabic{subsubparaapp}}

\renewcommand{\cftsubsubparaapppresnum}{} %remove word 'Appendix'
\renewcommand{\cftsubsubparaappaftersnum}{\hspace{0.5cm}}  %space after subparaapp title

\setlength{\cftbeforesubsubparaappskip}{0cm} %removes vertical spacing before each chapter element
\renewcommand{\cftsubsubparaappafterpnum}{\vskip6pt}
\setlength{\cftsubsubparaappindent}{9.3em} %indentation in loa (1.55 *2)
\settowidth{\cftsubsubparaappnumwidth}{\thesubsubparaapp\cftsubsubparaappaftersnum\hspace{0.3cm}}

%updates appendix counter, modifies chapter title such so that it is Appendix _letter_: #1
\newcommand{\subsubparaapp}[1]{%
  \refstepcounter{subsubparaapp}\pdfbookmark[5]{#1}{#1\thesubsubparaapp}%
  \subparagraph*{\thesubsubparaapp\hspace{0.3cm} #1} %paragraph is used because subparagraph has weird numbering problem
  \addcontentsline{loa}{subsubparaapp}{{\thesubsubparaapp\cftsubsubparaappaftersnum}#1}%
  \par
}

%leading dots for appendix (end immediately before page number)
\renewcommand{\cftsubsubparaappfillnum}[1]{%
 {\cftsubsubparaappleader}\nobreak{\cftsubsubparaapppagefont #1}\par\cftsubsubparaappafterpnum
}

\newcommand{\listabbname}{List of Abbreviations}
\newlistof[chapter]{abb}{loab}{\listabbname} %creates a new appendix counter that will be reset at the start of each \chapter

\setlength{\cftbeforeloabtitleskip}{0cm} %remove vertical space above loab
\setlength{\cftafterloabtitleskip}{0.2cm} %space between title for loab and list entries

\renewcommand{\cftmarkloab}{} %remove header titles

%two lines below ensure centered title for loa
%needed so that table of contents entry is not indented
\renewcommand{\cftloabtitlefont}{\hfill\fontsize{14}{14}\selectfont\bfseries\MakeUppercase}
\renewcommand{\cftafterloabtitle}{\hfill\hfill} %sometimes another \hfill is needed; depends on some setting in above code



%----------------------------------------------------------------------------------------
% REFERENCES & HYPERLINKING
%----------------------------------------------------------------------------------------

\usepackage{hyperref}

\PassOptionsToPackage{backref=true}{biblatex}

\RequirePackage[autocite=inline, style = apa]{biblatex}
\addbibresource{bib/references.bib}


\DeclareSourcemap{\maps[datatype = bibtex]{\map{\step[fieldsource = journal, match = \regexp{\x{26}}, replace = \regexp{\{\\\x{26}\}}] }}}
\DeclareSourcemap{\maps[datatype = bibtex]{\map{\step[fieldsource = title, match = \regexp{\x{26}}, replace = \regexp{\{\\\x{26}\}}] }}}

\hypersetup{pdfpagemode={UseOutlines},
    bookmarksopen=true,
    backref=page}
\usepackage{hypernat}
%%adds escape character to ampersand characters in journal fields of .bib file
\DefineBibliographyStrings{english}{backrefpage={cited on p.},backrefpages={cited on pp.}}




\hypersetup{pdfpagemode={UseOutlines},
bookmarksopen=true, %allows bookmarks in pdf
hypertexnames=true, %enables counting when referencing to sections
colorlinks = true, % Set to true to enable coloring links, a nice option, false to turn them off
%citecolor = blue, % The color of citations
%linkcolor = blue, % The color of references to document elements (sections, figures, etc)
%urlcolor= blue,
%anchorcolor = blue, % The color of hyperlinks (URLs)
allcolors = blue,
pdfstartview={FitV},
breaklinks=true, backref=page
}


%example numbering
\newtheorem{theorem}{Theorem}[section]
\renewcommand{\thetheorem}{\theapp.\arabic{theorem}}
\newtheorem{example}{Example}
\renewcommand{\theexample}{\theapp.\arabic{example}}


%load additional latex packages needed within document
	\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

%----------------------------------------------------------------------------------------
% DOCUMENT OUTLINE
%----------------------------------------------------------------------------------------

% BEGIN DOCUMENT
\begin{document}
\frontmatter %pages will be numbered with roman numerals

  \maketitle

\setcounter{page}{2} %ensures abstract page number starts at roman numberal ii

\cleardoublepage
\thispagestyle{empty} %removes page number only for abstract page
  \begin{abstract}{2}{Despite the value that longitudinal research offers for understanding psychological processes, studies in organizational research rarely use longitudinal designs. One reason for the paucity of longitudinal designs may be the challenges they present for researchers. Three challenges of particular importance are that researchers have to determine 1) how many measurements to take, 2) how to space measurements, and 3) how to design studies when participants provide data with different response schedules (time unstructuredness). In systematically reviewing the simulation literature, I found that few studies comprehensively investigated the effects of measurement number, measurement spacing, and time structuredness (in addition to sample size) on model performance. As a consequence, researchers have little guidance when trying to conduct longitudinal research. To address these gaps in the literature, I conducted a series of simulation experiments. I found poor model performance across all measurement number/sample size pairings. That is, bias and precision were never concurrently optimized under any combination of manipulated variables. Bias was often low, however, with moderate measurement numbers and sample sizes. Although precision was frequently low, the greatest improvements in precision resulted from using either seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\). With time-unstructured data, model performance systematically decreased across all measurement number/sample size pairings when the model incorrectly assumed an identical response pattern across all participants (i.e., time-structured data). Fortunately, when models were equipped to handle heterogeneous response patterns using definition variables, the poor model performance observed across all measurement number/sample size pairings no longer appeared. Altogether, the results of the current simulation experiments provide guidelines for researchers interested in modelling nonlinear change.}  %[linespacing][abstract][

  \end{abstract}

% notice how yaml variables are indexed with dollar signs and then passed into second argument of preambleItem environments
  \cleardoublepage
  \begin{preambleItem}{2}{Dedication}{{[}To be completed after defence{]}}
  \end{preambleItem}
  \cleardoublepage
   \begin{preambleItem}{2}{Acknowledgements}{{[}To be completed after defence{]}}
  \end{preambleItem}


%move page numbers to top right for list of tables, figures, and tables
\fancypagestyle{plain}{%
  \fancyhf{}% clear all header and footer fields
  \renewcommand{\headrulewidth}{0pt}
  \fancyhead[R]{\thepage}

   }

%table of contents
  \cleardoublepage
  \hypersetup{linkcolor = black, pdfborder= 0 0 0} %remove red borders around toc items
  \setcounter{secnumdepth}{5}
  \setcounter{tocdepth}{5}
  \tableofcontents
  \newpage

%list of tables
  \cleardoublepage
  \listoftables
  \newpage

%list of figures
  \cleardoublepage
  \listoffigures
  \newpage


%list of appendices
  \cleardoublepage
  \phantomsection
  \addcontentsline{toc}{chapter}{\listappname}
  \listofapp

  \newpage

\mainmatter % here the regular arabic numbering starts

\nocite{R-tidyverse, R-nonlinSims, R-nonlinSimsAnalysis, R-devtools, R-RColorBrewer, R-cowplot, R-data.table, R-egg, R-ggbrace, R-ggtext, R-kableExtra, R-knitr}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}
\begin{quote}
    ``Neither the behavior of human beings nor the activities of organizations can be defined without reference to time, and temporal aspects are critical for understanding them" \parencite[][p. 136]{navarro2015}.
\end{quote}
The topic of time has received considerable attention in organizational psychology over the past 20 years. Examples of well-received articles published around the beginning of the 21\textsuperscript{st} century have discussed how investigating time is important for
understanding patterns of change and boundary conditions of theory
\autocite{zaheer1999}, how longitudinal research is necessary for disentangling
different types of causality \autocite{mitchell2001}, and explicated patterns
of organizational change \autocite[or institutionalization;][]{lawrence2001}.
Since then, articles have emphasized the need to address time in
specific areas such as performance \autocite{fisher2008,dalal2014}, teams \autocite{roe2012}, and goal setting \autocite{fried2004} and, more generally, throughout organizational research \autocite{george2000,roe2008,ployhart2010,sonnentag2012,navarro2015,shipp2015,kunisch2017,vantilborgh2018,aguinis2021}.

The importance of time has also been recognized in organizational theory. In defining a theoretical contribution, \textcite{whetten1989} stated that time must be discussed in setting boundary conditions (i.e., under what circumstances does the theory apply) and in specifying relations between variables over time \autocite{mitchell2001,george2000}. Even if a considerable number of organizational theories do not adhere to the definition of \textcite{whetten1989}, theoretical models in organizational psychology consist of path diagrams that delineate the causal events of processes. Given that temporal precedence is a necessary condition for establishing causality \autocite{mill2011}, time has a role, whether implicitly or explicitly, in organizational theory.

Despite the considerable attention given towards investigating processes over time and the ubiquity of time in organizational theory, the prevalence of longitudinal research has historically remained low. One study examined the prevalence of longitudinal research from 1970--2006 across five organizational psychology journals and found that 4\% of articles used longitudinal designs \autocite{roe2014b}. Another survey of two applied psychology journals in 2005 found that approximately 10\% (10 of 105 studies) of studies used longitudinal designs \autocite{roe2008}. Similarly, two surveys of studies employing longitudinal designs with mediation analysis found that, across five journals, only about 10\% (7 of 72 studies) did so in 2005 \autocite{maxwell2007} and approximately 16\% (15 of 92 studies) did so in 2006 \autocite{mitchell2013}.\footnote{Note that the definition of a longitudinal design in \textcite{maxwell2007} and \textcite{mitchell2013} required that measurements be taken over at least three time points so that measurements of the predictor, mediator, and outcome variables were separated over time.} Thus, the prevalence of longitudinal research has remained low.

In the seven sections that follow, I will explain why longitudinal research is necessary and the factors that must be considered when conducting such research. In the first section, I will explain why conducting longitudinal research is essential for understanding the dynamics of psychological processes. In the second section, I will overview patterns of change that are likely to emerge over time. In the third section, I will overview design and analytical issues involved in conducting longitudinal studies. In the fourth section, I will explain how design and analytical issues encountered in conducting longitudinal research can be investigated. In the fifth section, I will provide a systematic review of the research that has investigated design and analytical issues involved in conducting longitudinal research. Finally, in the sixth and seventh sections, I will, respectively, discuss some methods for modelling nonlinear change and the frameworks in which they can be used. A summary of the three simulation experiments that I conducted in my dissertation will then be provided.

\hypertarget{the-need-to-conduct-longitudinal-research}{%
\section{The Need to Conduct Longitudinal Research}\label{the-need-to-conduct-longitudinal-research}}

Longitudinal designs provide several advantages over cross-sectional designs that allow them to more accurately investigate change (e.g., temporal precedence, testing reverse causality). Unfortunately, even though longitudinal studies often produce results that differ from those of cross-sectional studies, researchers commonly discuss the results of cross-sectional studies as if they have been obtained with a longitudinal design. One example of the assumption of equivalence between cross-sectional and longitudinal findings comes from the large number of studies employing mediation analysis. Given that mediation is used to understand chains of causality in psychological processes \autocite{baron1986}, it would thus make sense to pair mediation analysis with a longitudinal design because understanding causality, after all, requires temporal precedence. Unfortunately, the majority of studies that have used mediation analysis have done so using cross-sectional designs---with estimates of approximately 90\% \autocite{maxwell2007} and 84\% \autocite{mitchell2013}---and often discuss the results as if they are longitudinal. Investigations into whether mediation results remain equivalent across cross-sectional and longitudinal designs have repeatedly concluded that using mediation analysis on cross-sectional data can return different, and sometimes completely opposite, results from using it on longitudinal data \autocite{cole2003,maxwell2007,maxwell2011,mitchell2013,olaughlin2018}. Therefore, mediation analyses based on cross-sectional analyses may be misleading.

The non-equivalence of cross-sectional and longitudinal results that occurs with mediation analysis is, unfortunately, not due to a specific set of circumstances that only arise with mediation analysis, but a consequence of a broader systematic cause that affects the results of many analyses. The concept of ergodicity explains why cross-sectional and longitudinal analyses seldom yield similar results. To understand ergodicity, it is first important to realize that variance is central to many statistical analyses---correlation, regression, factor analysis, and mediation are some examples. Thus, if variance remains unchanged across cross-sectional and longitudinal data sets, then analyses of either data set would return the same results. Importantly, variance only remains equal across cross-sectional and longitudinal data sets if two conditions put forth by ergodic theory are satisfied \autocites[homogeneity and stationarity;][]{molenaar2004,molenaar2009}. If these two conditions are met, then a process is said to be ergodic. Unfortunately, the two conditions required for ergodicity are highly unlikely to be satisfied and so cross-sectional findings will frequently deviate from longitudinal findings (for a detailed discussion, see Appendix \ref{ergodicity}).

Given that cross-sectional and longitudinal analyses are, in general, unlikely to return equivalent findings, it is unsurprising that several investigations in organizational research---and psychology as a whole---have found these analyses to return different results. Beginning with an example from \textcite{curran2011}, heart attacks are less likely to occur in people who exercise regularly (longitudinal finding), but more likely to happen when exercising (cross-sectional finding). Correlational studies find differences in correlation magnitudes between cross-sectional and longitudinal data sets \autocites[for a meta-analytic review, see][]{nixon2011,fisher2018}.\footnote{Note that \textcite{fisher2018} also found the variability of longitudinal correlations to be considerably larger than the variability of cross-sectional correlations.} Moving on to perhaps the most commonly employed analysis in organizational research of mediation, several articles have highlighted that cross-sectional data can return different, and sometimes completely opposite, results than those obtained from longitudinal data \autocite{cole2003,maxwell2007,maxwell2011,olaughlin2018}. Factor analysis is perhaps the most interesting example: The well-documented five-factor model of personality seldom arises when analyzing person-level data consisting of personality measurements over 90 consecutive days \autocite{hamaker2005}. Therefore, cross-sectional analyses are rarely equivalent to longitudinal analyses.

With longitudinal analyses often producing results that differ from those of cross-sectional analyses, it is paramount that longitudinal designs be used to more accurately understand change. Fortunately, technological advancements have allowed researchers to more easily conduct longitudinal research in two ways. First, the use of the experience sampling method \autocite{beal2015} in conjunction with modern information transmission technologies---whether through phone applications or short message services---allows data to often be sampled over time with relative ease. Second, the development of longitudinal analyses (along with their integration in commonly used software) that enable person-level data to be modelled such as multilevel models \autocite{raudenbush2002}, growth mixture models \autocite{wang2007}, and dynamic factor analysis \autocite{ram2013} provide researchers with avenues to explore the temporal dynamics of psychological processes. With one recent survey estimating that 43.3\% of mediation studies (26 of 60 studies) used a longitudinal design \autocite{olaughlin2018}, it appears that the prevalence of longitudinal research has increased from the 9.5\% \autocite{roe2008} and 16.3\% \autocite{mitchell2013} values estimated at the beginning of the 21\textsuperscript{st} century. Although the frequency of longitudinal research appears to have increased over the past 20 years, several avenues exist where the quality of longitudinal research can be improved, and in my dissertation, I focus on investigating these avenues.

\hypertarget{understanding-patterns-of-change-that-emerge-over-time}{%
\section{Understanding Patterns of Change That Emerge Over Time}\label{understanding-patterns-of-change-that-emerge-over-time}}

Change can occur in many ways over time. One pattern of change commonly assumed to occur over time is that of linear change. When change follows a linear pattern, the rate of change over time remains constant. Unfortunately, a linear pattern places demanding restrictions on the possible trajectories of change. If change were to follow a linear pattern, then any pauses in change (or plateaus) or changes in direction could not occur: Change would simply grow over time. Unfortunately, effect sizes have been shown to diminish over time after peaking \autocites[for meta-analytic examples, see][]{cohen1993,griffeth2000,hom1992,riketta2008,steel1984,steel1990}. Moreover, many variables display cyclic patterns of change over time, with mood \autocite{larsen1990}, daily stress \autocite{bodenmann2010}, and daily drinking behaviour \autocite{huh2015} as some examples. Therefore, change over is unlikely to follow a linear pattern.

A more realistic pattern of change to occur over time is a nonlinear pattern \autocite[for a review, see][]{cudeck2007}. Nonlinear change allows the rate of change to be nonconstant; that is, change may occur more rapidly during certain periods of time, stop altogether, or reverse direction. When looking at patterns of change observed across psychology, several examples of nonlinear change have been found in the declining rate of speech errors throughout child development \autocite{burchinal1991}, rates of forgetting \autocite{murre2015}, development of habits \autocite{fournier2017}, and the formation of opinions \autocite{xia2020}. Given that nonlinear change appears more likely than linear change, my dissertation will assume change over time to be nonlinear.

\hypertarget{challenges-involved-in-conducting-longitudinal-research}{%
\section{Challenges Involved in Conducting Longitudinal Research}\label{challenges-involved-in-conducting-longitudinal-research}}

Conducting longitudinal research presents researchers with several challenges. Many challenges are those from cross-sectional research only amplified \autocite[for a review, see][]{bergman1993}.\footnote{It should be noted that conducting a longitudinal study does alleviate some issues encountered in conducting cross-sectional research. For example, taking measurements over multiple time points likely reduces common method variance \parencites{podsakoff2003}[for an example, see ][]{ostroff2002}.} For example, greater efforts have to be made to to prevent missing data which can increase over time \autocite{newman2008,dillman2014}. Likewise, the adverse effects of well-documented biases such as demand characteristics \autocite{orne1962} and social desirability \autocite{nederhof1985} have to be countered at each time point. Outside of challenges shared with cross-sectional research, conducting longitudinal research also presents new challenges. Analyses of longitudinal data have to consider complications such as how to model error structures \autocite{grimm2010a}, check for measurement non-invariance over time \autocite[the extent to which a construct is measured with the same measurement model over time;][]{mellenbergh1989}, and how to center/process data to appropriately answer research questions \autocite{enders2007,wang2015}.

Although researchers must contend with several issues in conducting longitudinal research, three issues are of particular interest in my dissertation. The first issue concerns how many measurements to use in a longitudinal design. The second issue concerns how to space the measurements. The third issue focuses on how much error is incurred if the time structuredness of the data is overlooked. The sections that follow will review each of these issues.

\hypertarget{number-of-measurements}{%
\subsection{Number of Measurements}\label{number-of-measurements}}

Researchers have to decide on the number of measurements to include in a longitudinal study. Although using more measurements increases the accuracy of results---as noted in the results of several studies \autocites[e.g.,][]{coulombe2016,timmons2015,finch2017,fine2019}---taking additional measurements often comes at a cost that a researcher may be unable to absorb given a limited budget. One important point to mention is that a researcher designing a longitudinal study must take at least three measurements to allow a reliable estimate of change and, perhaps more importantly, to allow a nonlinear pattern of change to be modelled \autocite{ployhart2010}. In my dissertation, I hope to determine whether an optimal number of measurements exists when modelling a nonlinear pattern of change.

\hypertarget{spacing-of-measurements}{%
\subsection{Spacing of Measurements}\label{spacing-of-measurements}}

Additionally, a researcher must decide on the spacing of measurements in a longitudinal study. Although discussions of measurement spacing often recommend that researchers use theory and previous studies to determine measurement spacing \autocite{mitchell2001,cole2003,collins2006,dormann2014,dormann2015}, organizational theories seldom delineate periods of time over which a processes unfold, and so the majority of longitudinal research uses intervals of convention and/or convenience to space measurements \autocite{mitchell2001,dormann2014}. Unfortunately, using measurement spacings that do not account for the temporal pattern of change of a psychological process can lead to inaccurate results \autocite[e.g.,][]{chen2014}. As an example, \textcite{cole2009} show how correlation magnitudes are affected by the choice of measurement spacing intervals. In my dissertation, I hope to determine whether an optimal measurement spacing schedule exists when modelling a nonlinear pattern of change.

\hypertarget{time-structuredness}{%
\subsection{Time Structuredness}\label{time-structuredness}}

Last, and perhaps most pernicious, latent variable analyses of longitudinal data are likely to incur error from an assumption they make about data collection conditions. Latent variable analyses assume that, across all collection points, participants provide their data at the same time. Unfortunately, such a high level of regularity in the response patterns of participants is unlikely: Participants are more likely to provide their data over some period of time after a data collection window has opened. As an example, consider a study that collects data from participants at the beginning of each month. If participants respond with perfect regularity, then they would all provide their data at the exact same time (e.g., noon on the second day of each month). If the participants respond with imperfect regularity, then they would provide their at different times after the beginning of each month. The regularity of response patterns observed across participants in a longitudinal study determines the time structuredness of the data and the sections that follow will provide overview of time structuredness.

\hypertarget{time-structured-data}{%
\subsubsection{Time-Structured Data}\label{time-structured-data}}

Many analyses assume that data are \emph{time structured}: Participants provide data at the same time at each collection point. By assuming time-structured data, an analysis can incur error because it will map time intervals of inappropriate lengths onto the time intervals that occurred between participant's responses.\footnote{It should be noted that, although seldom implemented, analyses can be accessorized to handle time-unstructured data by using definition variables \parencites{mehta2000}{mehta2005}.} As an example of the consequences of incorrectly assuming data to be time structured, consider a study that assessed the effects of an intervention on the development of leadership by collecting leadership ratings at four time points each separated by four weeks \autocite{day2011}. The employed analysis assumed time-structured data; that is, each each participant provided ratings on the same day---more specifically, the exact same moment---each time these ratings were collected. Unfortunately, it is unlikely that the data collected from participants were time structured: At any given collection point, some participants may have provided leadership ratings at the beginning of the week, while others may only provide ratings two weeks after the survey opened. Importantly, ratings provided two weeks after the survey opened were likely influenced by changes in leadership that occurred over the two weeks. If an analysis incorrectly assumes time-structured data, then it assumes each participant has the same response pattern and, therefore, will incorrectly attribute the amount of time that elapses between most participants' responses. For instance, if a participant only provides a leadership rating two weeks after having received a survey (and six weeks after providing their previous rating), then using an analysis that assumes time-structured data would incorrectly assume that each collection point of this participant is separated by four weeks (the interval used in the experiment) and would, consequently, model the observed change as if it had occurred over four weeks. Therefore, incorrectly assuming data to be time structured leads an analysis to overlook the unique response rates of participants across the collection points and, as a consequence, incur error \autocite{mehta2000,mehta2005,coulombe2016}.

\hypertarget{time-unstructured-data}{%
\subsubsection{Time-Unstructured Data}\label{time-unstructured-data}}

Conversely, other analyses assume that data are \emph{time unstructured}: Participants provide data at different times at each collection point. Given the unlikelihood of one response pattern describing the response rates of all participants in a given study, the data obtained in a study are unlikely to be time structured. Instead, and because participants are likely to exhibit unique response patterns in their response rates, data are likely to be time unstructured. One way to conceptualize the distinction between time-structured and time-unstructured data is on a continuum. On one end of the continuum, participants all provide data with identical response patterns, thus giving time-structured data. When participants exhibit unique response patterns, the resulting data are time unstructured, with the extent of time-unstructuredness depending on the average uniqueness of all response patterns. For example, if data are collected at the beginning of each month and participants only have one day to provide data at each time point, then the resulting data will have a low amount of time structuredness because response patterns can only differ from each other over the course of one day. Alternatively, if data are collected at the beginning of each month and participants have 30 days to provide data at each time point, then the resulting data will have a high amount of time structuredness because response patterns can differ from each other over the course of 30 days. Therefore, the continuum of time struturedness has time-structured data on one end and time-unstructured data with long response windows on another end. In my dissertation, I hope to determine how much error is incurred when time-unstructured data of varying degrees are assumed to be time structured.

\hypertarget{summary}{%
\subsection{Summary}\label{summary}}

In summary, researchers must contend with several issues when conducting longitudinal research. In addition to contending with issues encountered in conducting cross-sectional research, researchers must contend with new issues that arise from conducting longitudinal research. Three issues of particular importance in my dissertation are the number of measurements, the spacing of measurements, and incorrectly assuming time-unstructured data to be time structured. These issues will be serve as a basis for a systematic review of the simulation literature.

\hypertarget{using-simulations-to-assess-modelling-accuracy}{%
\section{Using Simulations To Assess Modelling Accuracy}\label{using-simulations-to-assess-modelling-accuracy}}

In the next section, I will present the results of a systematic review of the literature that has investigated the issues of measurement number, measurement spacing, and time structuredness. Before presenting the results of the systematic review, I will provide an overview of the Monte Carlo method used to investigate the issues involved in conducting longitudinal research.

To understand how the effects of longitudinal issues on modelling accuracy can be investigated, the inferential method commonly employed in psychological research will first be reviewed with an emphasis on its shortcomings (see Figure \ref{fig:MonteCarlo-comparison}). Consider an example where a researcher wants to understand how sampling error affects the accuracy with which a sample mean (\(\bar{x}\)) estimates a population mean (\(\upmu\)). Using the inferential method, the researcher samples data and then estimates the population mean (\(\upmu\)) by computing the mean of the sampled data (\(\bar{x}_1\)). Because collected samples are almost always contaminated by a variety of methodological and/or statistical deficiencies (such as sampling error, measurement error, assumption violations, etc.), the estimation of the population parameter is likely to be imperfect. Unfortunately, to estimate the effect of sampling error on the accuracy of the population mean estimate (\(\bar{x}_1\)), the researcher would need to know the value of the population mean; without knowing the value of the population mean, it is impossible to know how much error was incurred in estimating the population mean and, as as a result, impossible to know the extent to which sampling error contributed to this error. Therefore, a study following the inferential approach can only provide estimates of population parameters.

The Monte Carlo method has a different goal. Whereas the inferential method focuses on estimating parameters from sample data, the Monte Carlo method is used to understand the factors that influence the accuracy of the inferential approach. Figure \ref{fig:MonteCarlo-comparison} shows that the Monte Carlo method works in the opposite direction of the inferential approach: Instead of collecting a sample, the Monte Carlo method begins by assigning a value to at least one parameter to define a population. Many sample data sets are then generated from the defined population (\(s_1, s_2, ..., s_n\)) and the data from each sample are then modelled by computing a sample mean (\(\bar{x}_1, \bar{x}_2, ..., \bar{x}_n\)). Importantly, manipulations can be applied to the sampling and/or modelling of the data. In the current example,the population estimates of each statistical model are averaged (\(\bar{\bar{x}}\)) and compared to the pre-determined parameter value (\(\upmu\)). The difference between the average of the estimates and the known population value constitutes bias in parameter estimation (i.e., parameter bias). In the current example, the manipulation causes a systematic underestimation, on average, of the population parameter. By randomly generating data, the Monte Carlo method can estimate how a variety of methodological and statistical factors affect the accuracy of a model \autocite[for a review, see][]{robert2010}.

Monte Carlo simulations have been used to evaluate the effects of a variety of methodological and statistical deficiencies for several decades. Beginning with an early use of the Monte Carlo method, \textcite{boneau1960} used it to evaluate the effects of assumption violations on the fidelity of \emph{t}-value distributions. In more recent years, implementations of the the Monte Carlo method have shown that realistic values of sample size
and measurement accuracy produce considerable variability in estimated correlation values \autocite{stanley2014}. Monte Carlo simulations have also provided valuable insights into more complicated statistical analyses. In investigating more complex statistical analyses, simulations have shown that mediation analyses are biased to produce results of complete mediation because the statistical power to detect direct effects falls well below the statistical power to detect indirect effects \autocite{kenny2014}. Given the ability of the Monte Carlo method to evaluate statistical methods, the experiments in my dissertation used it to evaluate the effects of measurement number, measurement spacing, and time structuredness on modelling accuracy.\footnote{My simulation experiments also investigated the effects of sample size and nature of change on modelling accuracy.}

\hypertarget{systematic-review-of-simulation-literature}{%
\section{Systematic Review of Simulation Literature}\label{systematic-review-of-simulation-literature}}

To understand the extent to which issues involved in conducting longitudinal research had been investigated, I conducted a systematic review of the simulation literature.
\begin{apaFigure}
[landscape]
[samepage]
[0cm]
{Depiction of Monte Carlo Method}
{MonteCarlo-comparison}
{0.7}
{Figures/Monte_Carlo_comparison}
{Comparison of inferential approach with the Monte Carlo approach. The inferential approach begins with a collected sample and then estimates the population parameter using an appropriate statistical model. The difference between the estimated and population value can be conceptualized as error. Because the population value is generally unknown in the inferential approach, it cannot estimate how much error is introduced by any given methodological or statistical deficiency. To estimate how much error is introduced by any given methodological or statistical deficiency, the Monte Carlo method needs to be used, which constitutes four steps. The Monte Carlo method first defines a population by setting parameter values. Second, many samples are generated from the pre-defined population, with some methodological deficiency built in to each data set (in this case, each sample has a specific amount of missing data). Third, each generated sample is then analyzed and the population estimates of each statistical model are averaged and compared to the pre-determined parameter value. Fourth, the difference between the estimate average and the known population value defines the extent to which the missing data manipulation affected parameter estimation (the difference between the population and average estimated population value is the parameter bias).}
\end{apaFigure}
The sections that follow will first present the method I followed in systematically reviewing the literature and then summarize the findings of the review.

\hypertarget{systematic-review-methodology}{%
\subsection{Systematic Review Methodology}\label{systematic-review-methodology}}

I identified the following keywords through citation searching and independent reading: ``growth curve'', ``time-structured analysis'', ``time structure'', ``temporal design'', ``individual measurement occasions'', ``measurement intervals'', ``methods of timing'', ``longitudinal data analysis'', ``individually-varying time points'', ``measurement timing'', ``latent difference score models'', ``parameter bias'', and ``measurement spacing''. I entered these keywords entered into the PsycINFO database (on July 23, 2021) along with the word ``simulation'' in any field and considered any returned paper a viable ppaper (see Figure \ref{fig:prismaDiagram} for a PRISMA diagram illustrating the filtering of the reports). The search returned 165 reports, which I screened by reading the abstracts. Initial screening led to the removal of 60 reports because they did not contain any simulation experiments. Of the remaining 105 papers, I removed 2 more papers because they could not be accessed \autocite{stockdale2007,tiberio2008}. Of the remaining 103 identified simulation studies, I deemed a paper as relevant if it investigated the effects of any design and/or analysis factor related to conducting longitudinal research (i.e., number of measurements, spacing of measurements, and/or time structuredness) and did so using the Monte Carlo simulation method. Of the remaining 103 studies, I removed 89 studies because they did not meet the inclusion criteria, leaving fourteen studies to be included in the review. I also found an additional 3 studies through citation searching, giving a total of 17 studies.

The findings of my systematic review are summarized in Tables \ref{tab:systematicReviewCount}--\ref{tab:systematicReview}. Tables \ref{tab:systematicReviewCount}--\ref{tab:systematicReview} differ in one way: Table \ref{tab:systematicReviewCount} indicates how many studies investigated each effect, whereas Table \ref{tab:systematicReview} provides the reference of each study and detailed information about each study's method. Otherwise, all other details of Tables \ref{tab:systematicReviewCount}--\ref{tab:systematicReview} are identical. The first column lists the longitudinal design factor (alongside with sample size) and the corresponding two- and three-way interactions. The second and third columns list whether each effect has been investigated with linear and nonlinear patterns of change, respectively. Shaded cells indicate effects that have not been investigated, with cells shaded in light grey indicating effects that have not been investigated with linear patterns of change and cells shaded in dark grey indicating effects that have not been investigated with nonlinear patterns of change.\footnote{Table \ref{tab:systematicReview} lists the effects that each study (identified by my systematic review) investigated and notes the following methodological details (using superscript letters and symbols): the type
of model used in each paper, assumption and/or manipulation of complex error structures
(heterogeneous variances and/or correlated residuals), manipulation of missing data,
and/or pseudo-time structuredness manipulation. Across all 17 simulation studies, 5 studies (29\%) assumed complex error structures \parencites{gasimova2014}{liu2021}{liu2015}{miller2017}{murphy2011}, 1 study (6\%) manipulated missing data \parencite{fine2019}, and 2 studies (12\%) contained a pseudo-time structuredness manipulation \parencites{fine2019}{fine2020}. Importantly, the pseudo-time structuredness manipulation used in \textcite{fine2019} and \textcite{fine2020} differed from the manipulation of time structuredness used in the current experiments \parencites[and from previous simulation experiments of][]{coulombe2016}{miller2017} in that it randomly generated longitudinal data such that a given person could provide all their data before another person provided any data.}

\hypertarget{systematic-review-results}{%
\subsection{Systematic Review Results}\label{systematic-review-results}}

Although previous research appeared to sufficiently fill some cells of Table \ref{tab:systematicReviewCount}, two patterns suggest that arguably the most important cells (or effects) have not been investigated. First, it appears that simulation research has invested more effort in investigating the effects of longitudinal design factors with linear patterns than with nonlinear patterns of change. In counting the number of effects that remain unaddressed with linear and nonlinear patterns of change, a total of five cells (or effects) have not been investigated, but a total of seven cells have not been investigated with nonlinear patterns of
\begin{apaFigure}
[landscape]
{PRISMA Diagram Showing Study Filtering Strategy}
{prismaDiagram}
{0.7}
{Figures/prisma_diagram}
{PRISMA diagram for systematic review of simulation research that investigates longitudinal design and analysis factors.}
\end{apaFigure}
\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells are only numbered for effects that have not been investigated. Cells shaded in light and dark grey, respectively indicate effects that have not been investigated with linear and nonlinear  patterns of change.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{5.5cm}>{\centering\arraybackslash}p{8cm}>{\centering\arraybackslash}p{8cm}}
\caption{\label{tab:systematicReviewCount}Number of Simulation Studies That Have Investigated Longitudinal Issues with Linear and Nonlinear Change Patterns (\textit{n} = 17)}\\
\toprule
Effect & Linear pattern & Nonlinear pattern\\
\midrule
\endfirsthead
\caption[]{\label{tab:systematicReviewCount}Number of Simulation Studies That Have Investigated Longitudinal Issues with Linear and Nonlinear Change Patterns (\textit{n} = 17) \textit{(continued)}}\\
\toprule
Effect & Linear pattern & Nonlinear pattern\\
\midrule
\endhead

\endfoot
\bottomrule
\insertTableNotes
\endlastfoot
\textbf{Main effects} & \cellcolor{white}{} & \cellcolor{white}{}\\
\cmidrule{1-3}
Number of measurements (NM) & \cellcolor{white}{11 studies} & \cellcolor{white}{6 studies}\\
 
Spacing of measurements (SM) & \cellcolor{white}{1 study} & \cellcolor{white}{1 study}\\
 
Time structuredness (TS) & \cellcolor{white}{2 studies} & \cellcolor{white}{1 study}\\
 
Sample size (S) & \cellcolor{white}{11 studies} & \cellcolor{white}{7 studies}\\
\cmidrule{1-3}
\textbf{Two-way interactions} & \cellcolor{white}{} & \cellcolor{white}{}\\
\cmidrule{1-3}
NM x SM & \cellcolor{white}{1 study} & \cellcolor{white}{1 study}\\
 
NM x TS & \cellcolor{white}{1 study} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 1 (\hyperref[Exp3]{Exp. 3})}}\\
 
NM x S & \cellcolor{white}{9 studies} & \cellcolor{white}{5 studies}\\
 
SM x TS & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 2}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 3}}\\
 
SM x S & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 4}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 5 (\hyperref[Exp2]{Exp. 2})}}\\
 
TS x S & \cellcolor{white}{1 study} & \cellcolor{white}{2 studies}\\
\cmidrule{1-3}
\textbf{Three-way interactions} & \cellcolor{white}{} & \cellcolor{white}{}\\
\cmidrule{1-3}
NM x SM x TS & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 6}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 7}}\\
 
NM x SM x S & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 8}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 9 (\hyperref[Exp2]{Exp. 2})}}\\
 
NM x TS x S & \cellcolor{white}{1 study} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 10 (\hyperref[Exp3]{Exp. 3})}}\\
 
SM x TS x S & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 11}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 12}}\\*
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells are only numbered for effects that have not been investigated. Cells shaded in light and dark grey indicate effects that have not, respectively, been investigated with linear and nonlinear patterns of change.
\item[a] Latent growth curve model. \textsuperscript{b} Second-order latent growth curve model. \textsuperscript{c} Hierarchical Bayesian model. \textsuperscript{d} Bivariate latent change score model. \textsuperscript{e} Functional mixed-effects model. \textsuperscript{f} Nonlinear mixed-effects model. \textsuperscript{g} Bilinear spline model. \textsuperscript{g} Parallel bilinear spline model.
\item[$\circ$] Manipulated missing data. $^\mho$ Assumed complex error structure (heterogeneous variances and/or correlated residuals). $^\triangledown$ Contained pseudo-time structuredness manipulation.
\end{TableNotes}
\begin{longtable}[l]{l>{\centering\arraybackslash}p{8cm}>{\centering\arraybackslash}p{8cm}}
\caption{\label{tab:systematicReview}Summary of Simulation Studies That Have Investigated Longitudinal Issues with Linear and Nonlinear Change Patterns (\textit{n} = 17)}\\
\toprule
Effect & Linear pattern & Nonlinear pattern\\
\midrule
\endfirsthead
\caption[]{\label{tab:systematicReview}Summary of Simulation Studies That Have Investigated Longitudinal Issues with Linear and Nonlinear Change Patterns (\textit{n} = 17) \textit{(continued)}}\\
\toprule
Effect & Linear pattern & Nonlinear pattern\\
\midrule
\endhead

\endfoot
\bottomrule
\insertTableNotes
\endlastfoot
\textbf{Main effects} & \cellcolor{white}{} & \cellcolor{white}{}\\
\cmidrule{1-3}
Number of measurements (NM) & \cellcolor{white}{\parencites[][\textsuperscript{a}]{timmons2015}[][\textsuperscript{b}$^{\mho}$]{murphy2011}[][\textsuperscript{c}$^{\mho}$]{gasimova2014}[][\textsuperscript{a}]{wu2014}[][\textsuperscript{a}]{coulombe2016b}[][\textsuperscript{a}]{ye2016}[][\textsuperscript{a}]{finch2017}[][\textsuperscript{d}]{orourke2021}[][\textsuperscript{a}]{newsom2020}[][\textsuperscript{a}]{coulombe2016}} & \cellcolor{white}{\parencites[][\textsuperscript{a}]{timmons2015}[][\textsuperscript{a}]{finch2017}[][\textsuperscript{e}$^{\circ\triangledown}$]{fine2019}[][\textsuperscript{e,f}$^{\triangledown}$]{fine2020}[][\textsuperscript{g}]{liu2022}[][\textsuperscript{h}$^{\mho}$]{liu2021}[][\textsuperscript{g}$^{\mho}$]{liu2015}}\\
 
Spacing of measurements (SM) & \cellcolor{white}{\parencite[][\textsuperscript{a}]{timmons2015}} & \cellcolor{white}{\parencite[][\textsuperscript{a}]{timmons2015}}\\
 
Time structuredness (TS) & \cellcolor{white}{\parencites[][\textsuperscript{a}]{aydin2014}[][\textsuperscript{a}]{coulombe2016}} & \cellcolor{white}{\parencites[][\textsuperscript{a}$^{\mho}$]{miller2017}[][\textsuperscript{g}$^{\mho}$]{liu2015}}\\
 
Sample size (S) & \cellcolor{white}{\parencites[][\textsuperscript{b}${\mho}$]{murphy2011}[][\textsuperscript{c}$^{\mho}$]{gasimova2014}[][\textsuperscript{a}]{wu2014}[][\textsuperscript{a}]{coulombe2016b}[][\textsuperscript{a}]{ye2016}[][\textsuperscript{a}]{finch2017}[][\textsuperscript{d}]{orourke2021}[][\textsuperscript{a}]{newsom2020} [][\textsuperscript{a}]{coulombe2016}[][\textsuperscript{a}]{aydin2014}} & \cellcolor{white}{\parencites[][\textsuperscript{a}]{finch2017}[][\textsuperscript{e}$^{\circ\triangledown}$]{fine2019}[][\textsuperscript{e,f}$^{\triangledown}$]{fine2020}[][\textsuperscript{g}]{liu2022}[][\textsuperscript{h}$^{\mho}$]{liu2021}[][\textsuperscript{g}$^{\mho}$]{liu2015}[][\textsuperscript{a}$^{\mho}$]{miller2017}}\\
\cmidrule{1-3}
\textbf{Two-way interactions} & \cellcolor{white}{} & \cellcolor{white}{}\\
\cmidrule{1-3}
NM x SM & \cellcolor{white}{\parencite[][\textsuperscript{a}]{timmons2015}} & \cellcolor{white}{\parencite[][\textsuperscript{a}]{timmons2015}}\\
 
NM x TS & \cellcolor{white}{\parencite[][\textsuperscript{a}]{coulombe2016}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 1 (\hyperref[Exp3]{Exp. 3})}}\\
 
NM x S & \cellcolor{white}{\parencites[][\textsuperscript{b}${\mho}$]{murphy2011}[][\textsuperscript{c}$^{\mho}$]{gasimova2014}[][\textsuperscript{a}]{wu2014}[][\textsuperscript{a}]{coulombe2016b}[][\textsuperscript{a}]{ye2016}[][\textsuperscript{a}]{finch2017}[][\textsuperscript{d}]{orourke2021} [][\textsuperscript{a}]{newsom2020}[][\textsuperscript{a}]{coulombe2016}} & \cellcolor{white}{\parencites[][\textsuperscript{a}]{finch2017}[][\textsuperscript{e}$^{\circ\triangledown}$]{fine2019}[][\textsuperscript{e,f}$^{\triangledown}$]{fine2020}[][\textsuperscript{g}]{liu2022}[][\textsuperscript{h}$^{\mho}$]{liu2021}}\\
 
SM x TS & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 2}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 3}}\\
 
SM x S & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 4}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 5 (\hyperref[Exp2]{Exp. 2})}}\\
 
TS x S & \cellcolor{white}{\parencite[][\textsuperscript{a}]{aydin2014}} & \cellcolor{white}{\parencites[][\textsuperscript{g}$^{\mho}$]{liu2015}[][\textsuperscript{a}$^{\mho}$]{miller2017}}\\
\cmidrule{1-3}
\textbf{Three-way interactions} & \cellcolor{white}{} & \cellcolor{white}{}\\
\cmidrule{1-3}
NM x SM x TS & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 6}} & \cellcolor[HTML]{C7C4C4}{\textbf{\centering{\arraybackslash{Cell 7}}}}\\
 
NM x SM x S & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 8}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 9 (\hyperref[Exp2]{Exp. 2})}}\\
 
NM x TS x S & \cellcolor{white}{\parencite[][\textsuperscript{a}]{coulombe2016}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 10 (\hyperref[Exp3]{Exp. 3})}}\\
 
SM x TS x S & \cellcolor[HTML]{E4E2E2}{\textbf{Cell 11}} & \cellcolor[HTML]{C7C4C4}{\textbf{Cell 12}}\\*
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\noindent change. Given that change over time is more likely to follow a nonlinear than a linear pattern \autocite[for a review, see][]{cudeck2007}, it could be argued that most simulation research has investigated the effect of longitudinal design factors under unrealistic conditions.

Second, all the cells corresponding to the three-way interactions with nonlinear patterns of change have not been investigated (Cells 7, 9, 10, and 12 in Table \ref{tab:systematicReviewCount}), meaning that almost no study has conducted a comprehensive investigation into measurement timing. Given that longitudinal research is needed to understand the temporal dynamics of psychological processes---as suggested by ergodic theory \autocite{molenaar2004}---it is necessary to understand how longitudinal design and analysis factors interact with each other (and with sample size) in affecting the modelling accuracy of temporal dynamics. Given that no simulation study identified in my systematic review conducted a comprehensive investigation into the effects of longitudinal design and analysis factors on modelling nonlinear change, I designed simulation studies to address these gaps.

\hypertarget{modelling-change}{%
\section{Methods of Modelling Nonlinear Patterns of Change Over Time}\label{modelling-change}}

Because my simulation experiments assumed change over time to be nonlinear, it is important to provide an overview of how nonlinear change can be modelled. On this note, I will provide an overview of two commonly employed methods for modelling nonlinear change: 1) the polynomial approach and 2) the nonlinear function approach.\footnote{It should be noted that nonlinear change can be modelled in a variety of ways, with latent change score models \parencite[e.g., ][]{orourke2021} and spline models \parencite[e.g., ][]{fine2020} offering some examples.}\textsuperscript{,}\footnote{The definition of a nonlinear function is mathematical in nature. Specifically, a nonlinear function contains at least one parameter that exists in its corresponding partial derivative (at any order). For example, in the logistic function $\uptheta + \frac{\upalpha - \uptheta}{1 + exp^(\frac{\upbeta - t}{\upgamma}}$ is nonlinear because $\upbeta$ exists in $\frac{\partial y}{\partial \upbeta}$ (in addition to $\upgamma$ existing in its corresponding partial derivative). The $n^{th}$ order polynomial function of $y = a + bx + cx^2 + ... + nx^n$ is linear because the partial derivatives with respect to any of the parameters (i.e., $1, x^2, ..., x^n$) never contain the associated parameter.} Importantly, the simulation experiments in my dissertation will use the nonlinear function approach to model nonlinear change.

Consider an example where an organization introduces a new incentive system with the goal of increasing the motivation of its employees. To assess the effectiveness of the incentive system, employees provide motivation ratings every month over a period of 360 days. Over the 360-day period, the motivation levels of the employees increase following an s-shaped pattern of change over time. One analyst decides to model the observed change using a \emph{polynomial function} shown below in Equation \ref{eq:polynomial}:
\begin{align}
  y = \mathit{a} + \mathit{b}x + \mathit{c}x^2 + \mathit{d}x^3.
  \label{eq:polynomial}
\end{align}
\noindent A second analyst decides to model the observed change using a \emph{logistic function} shown below in Equation \ref{eq:logistic1}:
\begin{align}
  y = \uptheta + \frac{\upalpha - \uptheta}{1 + e^{\frac{\upbeta -time}{\upgamma}}}
  \label{eq:logistic1}
\end{align}
\noindent  Figure \ref{fig:polynomial-vs-logistic}A shows the response pattern predicted by the polynomial function of Equation \ref{eq:polynomial} with the estimated values of each parameter (\(a\), \(b\), \(c\), and \(d\)) and Figure \ref{fig:polynomial-vs-logistic}B shows the response pattern predicted by the logistic function (Equation \ref{eq:logistic1}) along with the values estimated for each parameter (\(\uptheta\), \(\upalpha\), \(\upbeta\), and \(\upgamma\)). Although the logistic and polynomial
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Response Patterns Predicted by Polynomial (Equation \ref{eq:polynomial}) and Logistic (Equation \ref{eq:logistic1}) Functions}
{polynomial-vs-logistic}
{0.26}
{Figures/polynomial_vs_nonlinear_plot}
{Panel A: Response pattern predicted by the polynomial function of Equation \eqref{eq:polynomial}. Panel B: Response pattern predicted by the logistic function of Equation \eqref{eq:logistic1}.}
\end{apaFigure}
\noindent functions predict nearly identical response patterns, the parameters of the logistic function have the following meaningful interpretations (see Figure \ref{fig:combined_plot}):
\begin{itemize}
\tightlist
\item
  \(\uptheta\) specifies the value at the first plateau (i.e., the starting value), and so is called the \emph{baseline} parameter (see Figure \ref{fig:combined_plot}A).
\item
  \(\upalpha\) specifies the value at the second plateau (i.e., the ending value), and so is called the the \emph{maximal elevation} parameter (see Figure \ref{fig:combined_plot}B).
\item
  \(\upbeta\) specifies the number of days required to reach half the difference between the first and second plateau (i.e., the midway point), and so is called the \emph{days-to-halfway-elevation} parameter (see Figure \ref{fig:combined_plot}C).
\item
  \(\upgamma\) specifies the number of days needed to move from the midway point to approximately 73\% of the difference between the starting and ending values (i.e., satiation point), and so is called the \emph{triquarter-halfway delta} parameter (see Figure \ref{fig:combined_plot}D).
\end{itemize}
\begin{apaFigure}
[landscape]
[samepage]
[0cm]
{Description Each Parameters Logistic Function (Equation \ref{eq:logistic1}) Functions}
{combined_plot}
{0.17}
{Figures/parameter_explanation_plot}
{Panel A: The baseline parameter ($\uptheta$) sets the starting value of the of curve, which in the current example has a value of 3.00 ($\uptheta$ = 3.00). Panel B: The maximal elevation parameter ($\upalpha$) sets the ending value of the curve, which in the current example has a value of 3.32 ($\upalpha$ = 3.32). Panel C: The days-to-halfway elevation parameter ($\upbeta$) sets the number of days needed to reach 50\% of the difference between the baseline and maximal elevation values. In the current example, the baseline-maximal elevation difference is 0.32 ($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32), and so the days-to-halfway elevation parameter defines the number of days needed to reach a value of 3.16. Given that the days-to-halfway elevation parameter is set to 180 in the current example ($\upbeta = 180.00$), then 180 days are needed to go from a value of 3.00 to a value of 3.16. Panel D: The triquarter-halfway delta parameter ($\upgamma$) sets the number of days needed to go from halfway elevation to approximately 73\% of the baseline-maximal elevation difference of 0.32 ($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32). Given that 73\% of the baseline-maximal elevation difference is 0.23 and the triquarter-halfway delta is set to 20 days ($\upgamma = 20.00$), then 20 days are needed to go from the halfway point of 3.16 to the triquarter point of approximately 3.23).}
\end{apaFigure}
\noindent Applying the parameter meanings of the logistic function to the parameter values estimated by using the logistic function (Equation \ref{eq:logistic1}), the predicted response pattern begins at a value of 3.00 (baseline) and reaches a value of 3.32 (maximal elevation) by the end of the 360-day period. The midway point of the curve is reached after 180.00 days (days-to-halfway elevation) and the satiation point is reached 20.00 days later (triquarter-halfway delta; or 200.00 days after the beginning of the incentive system is introduced). When looking at the polynomial function, it is almost impossible to meaningfully interpret the values of any of the other parameter values (aside from the `\(a\)' parameter, which indicates the starting value). Therefore, using a nonlinear function such as the logistic function provides a meaningful way to interpret nonlinear change.

\hypertarget{multilevel-and-latent-variable-approach}{%
\section{Multilevel and Latent Variable Approach}\label{multilevel-and-latent-variable-approach}}

In addition to using the logistic function to model nonlinear change, another modelling decision concerns whether to do so using the multilevel or latent growth curve framework. In my dissertation, I opted for the latent growth curve framework for two reasons. First, the latent growth curve framework allows data to be more realistically modelled than the multilevel framework. As some examples, the latent growth curve framework allows the modelling of measurement error, complex error structures, and time-varying covariates \autocite[for a review, see][]{mcneish2018}. Second, and perhaps more important, the likelihood of convergence with multilevel models decreases as the number of random-effect parameters increases due to nonpositive definitive covariance matrices \autocite[for a review, see][]{mcneish2020}. With the model I used in my simulation experiments having four random-effect parameters, it is likely that my simulation experiments would have considerable convergence issues if they use the multilevel framework. Therefore, given the convergence issues of multilevel models and the shortcoming realistically modelling data, I decided, on balance, that the strengths of the multilevel framework (e.g., more options for modelling small samples) were outweighed by its shortcomings, and decided to use a latent growth curve framework in my simulation experiments.

\hypertarget{next-steps}{%
\subsection{Next Steps}\label{next-steps}}

Given that longitudinal research is needed to understand the temporal dynamics of psychological processes, it is necessary to understand how longitudinal design and analysis factors interact with each other (and with sample size) in affecting the accuracy with which nonlinear patterns of change are modelled. With no study to my knowledge having conducted a comprehensive investigation into how longitudinal design and analysis factors affect the modelling of nonlinear change patterns, my simulation experiments are designed to address these gaps in the literature. Specifically, my simulation experiments investigate how measurement number, measurement spacing, and time structuredness affect the accuracy with which a nonlinear change pattern is modelled (see Cells 1, 5, 9, and 10 of Table \ref{tab:systematicReviewCount}/Table \ref{tab:systematicReview}).

\hypertarget{overview-of-simulation-experiments}{%
\section{Overview of Simulation Experiments}\label{overview-of-simulation-experiments}}

To investigate the effects of longitudinal design and analysis factors on modelling accuracy, I conducted three Monte Carlo experiments. Before summarizing the simulation experiments, one point needs to be mentioned regarding the maximum number of independent variables used in each experiment. No simulation experiment manipulated more than three variables because of the difficulty associated with interpreting interactions between four or more variables. Even among academics, the ability to correctly interpret interactions sharply declines when the number of independent variables increases from three to four \autocite{halford2005}. Therefore, none of my simulation experiments manipulated more than three variables so that results could be readily interpreted.

To summarize the three simulation experiments, the independent variables of each simulation experiment are listed below:
\begin{itemize}
\tightlist
\item
  Experiment 1: number of measurements, spacing of measurements, and nature of change.
\item
  Experiment 2: number of measurements, spacing of measurements, and sample size.
\item
  Experiment 3: number of measurements, sample size, and time structuredness.
\end{itemize}
\noindent The sections that follow will present each of the simulation experiments and their corresponding results.

\hypertarget{exp-1}{%
\chapter{Experiment 1}\label{exp-1}}

In Experiment 1, I investigated the number of measurements needed to obtain high model performance for the estimation of each logistic function parameter (i.e., unbiased and precise estimation) under different spacing schedules and natures of change. Before presenting the results of Experiment 1, I present my design and analysis goals. For my design goals, I conducted a 4 (measurement spacing:equal, time-interval increasing, time-interval decreasing, middle-and-extreme) x 4 (number of measurements: 5, 7, 9, 11) x 3 (nature of change: population value for the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]} of 80, 180, or 280) study. For my analysis goals, I was interested in answering two questions. First, I was interested in whether placing measurements near periods of change increases model performance. To answer my first question, I determined whether model performance under each spacing schedule increased when measurements were taken closer to periods of change.

Second, I was interested in how to space measurements when the nature of change is unknown. When the nature of change is unknown, this translates to a situation where a researcher has little to no knowledge of how change unfolds over time, and so any nature of change is a viable candidate for the true change. Therefore, to determine how to space measurements when the nature of change is unknown, I averaged the model performance of each spacing schedule across all possible nature-of-change curves and considered the spacing schedule with the highest model performance to be the best one.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{data-generation}{%
\subsection{Overview of Data Generation}\label{data-generation}}

\hypertarget{function-used-to-generate-each-data-set}{%
\subsubsection{Function Used to Generate Each Data Set}\label{function-used-to-generate-each-data-set}}

Data for each simulation experiment were generated using R \autocite{rstudio}. To run the simulations, I created the \texttt{nonlinSims} package, which is available at the following GitHub repository: \url{https://github.com/sciarraseb/nonlinSims}. The code used to run the simulations and create the data set can be found in Appendix \ref{simulation-code} and the data file (\texttt{exp\_1\_data.csv}) can be found at the following GitHub repository: \url{https://github.com/sciarraseb/dissertation}. To generate the data, the \emph{multilevel logistic function} shown below in Equation \eqref{eq:logFunction-generation} was used:
\begin{align}
  y_{ij} = \uptheta_j + \frac{\upalpha_j - \uptheta_j}{{1 + e^\frac{\upbeta_j - time_i}{\upgamma_j}}} + \upepsilon_{ij}, 
\label{eq:logFunction-generation}
\end{align}
\noindent where \(\uptheta\) represents the baseline parameter, \(\upalpha\) represents the maximal elevation parameter, \(\upbeta\) represents the days-to-halfway elevation parameter, and \(\upgamma\) represents triquarter-halfway delta parameter. Note that, values for \(\uptheta\), \(\upalpha\), \(\upbeta\), and \(\upgamma\) were generated for each \emph{j} person across all \emph{i} time points, with an error value being randomly generated at each \emph{i} time point(\(\upepsilon_{ij}\); see Figure \ref{fig:combined_plot} for a review of each parameter). In other words, unique response patterns were generated for each person in each generated data set. Importantly, 1000 data sets were generated per cell.

The logistic growth function (Equation \ref{eq:logFunction-generation}) was used because it is a common pattern of organizational change \autocite[or institutionalization;][]{lawrence2001}. Institutionalization curves follow an s-shaped pattern (i.e., logistic growth), and so their rates of change can be represented by the days-to-halfway elevation and triquarter-halfway delta parameters (\(\upbeta\), \(\upgamma\), respectively), and the success of the change can be defined by the magnitude of the difference between baseline and maximal elevation parameters (\(\upalpha\) - \(\uptheta\), respectively).

\hypertarget{population-values-used-for-function-parameters}{%
\subsubsection{Population Values Used for Function Parameters}\label{population-values-used-for-function-parameters}}

Table \ref{tab:parameterValues} lists the parameter values that were used for the population parameters. Given that the decisions for setting the values for the baseline, maximal elevation, and residual variance parameters were informed by past research, the discussion that follows highlights how these decisions were made. The difference between the baseline and maximal elevation parameters (\(\uptheta\) and \(\upalpha\), respectively) corresponded to the effect size most commonly observed in organizational research \autocite[i.e., the 50\textsuperscript{th} percentile effect size value;][]{bosco2015}. Because the meta-analysis of \textcite{bosco2015} computed effect sizes as correlations, the 50\textsuperscript{th} percentile effect size value of \(r = .16\) was computed to a standardized effect size using the following conversion function shown in Equation \ref{eq:conversion-effect} \autocite[Chapter 7]{borenstein2009}:
\begin{align}
d = \frac{2r}{\sqrt{1 - r^2}}, 
\label{eq:conversion-effect}
\end{align}
\noindent where \(r\) is the correlation effect size. Using Equation \ref{eq:conversion-effect}, a correlation value of \(r = .16\) becomes a standardized effect size value of \(d = 0.32\). For the value of the residual variance parameter (\(\upepsilon\)), \textcite{coulombe2016} set it to the value used for the intercept variance parameter. In the current context, the intercept of the logistic function (Equation \ref{eq:logFunction-generation}) is the baseline parameter (\(\uptheta\)).\footnote{The definition of an intercept parameter is the value of a curve when no time has elapsed, and this is precisely the definition of the baseline parameter ($\uptheta$). Therefore, the variance of the intercept parameter carries the same meaning as the variance of the baseline parameter ($\uptheta_{random}$).} Given that the value for the variability of the baseline parameter was 0.05 (albeit in standard deviation units), the value used for the residual variance parameter was 0.05 (\(\upepsilon = 0.05\)). Importantly, because \textcite{coulombe2016} set covariances between parameters to zero, all the simulation experiments used zero-value covariances. Because justification for the other parameters could not be found in any of the simulation studies identified in my systematic review, values set for the other parameters were largely arbitrary.

Two last brief points need to be mentioned about how data were generated to facilitate the interpretation of the results. First, data were generated to take on units similar to that of a Likert scale (range of 1--5) by assuming a standard deviation of 1.00. Thus, previously established effect size of \(d = 0.32\) standard deviations implies an effect size of 0.32 units. Second, change was assumed to occur over a period of 360 days because many organizational processes are often governed by annual events (e.g., performance reviews, annual returns, regulations, etc.).

\hypertarget{data-modelling}{%
\subsection{Modelling of Each Generated Data Set}\label{data-modelling}}

Previously, I described how data were generated. Here, I describe how the generated data were modelled.

Each data set generated by the multilevel logistic function (Equation \ref{eq:logFunction-generation}) was analysed using a modified latent growth curve model known as a structure latent growth curve model \autocite{preacher2015}.
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }The difference between $\upalpha$ and $\uptheta$ corresponds to the 50$\mathrm{^{th}}$ percentile Cohen's $d$ value of 0.32 in organizational psychology (Bosco et al., 2015).
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{12 cm}c}
\caption{\label{tab:parameterValues}Values Used for Multilevel Logistic Function Parameters}\\
\toprule
Parameter Means & Value\\
\midrule
\endfirsthead
\caption[]{\label{tab:parameterValues}Values Used for Multilevel Logistic Function Parameters \textit{(continued)}}\\
\toprule
Parameter Means & Value\\
\midrule
\endhead

\endfoot
\bottomrule
\insertTableNotes
\endlastfoot
\hspace{2em}Baseline, $\uptheta$ & 3.00\\
\hspace{2em}Maximal elevation, $\upalpha$ & 3.32\\
\hspace{2em}Days-to-halfway elevation, $\upbeta$ & 180.00\\
\hspace{2em}Triquarter-halfway delta, $\upgamma$ & 20.00\\
\addlinespace\addlinespace\cmidrule{1-2}
Variability and Covariability Parameters (in Standard Deviations) & \\
\cmidrule{1-2}
\hspace{2em}Baseline standard deviation, $\uppsi_{\uptheta}$ & 0.05\\
\hspace{2em}Maximal elevation standard deviation, $\uppsi_{\upalpha}$ & 0.05\\
\hspace{2em}Days-to-halfway elevation standard deviation, $\uppsi_{\upbeta}$ & 10.00\\
\hspace{2em}Triquarter-halfway delta standard deviation, $\uppsi_{\upgamma}$ & 4.00\\
\hspace{2em}Baseline-maximal elevation covariability, $\uppsi_{\uptheta\upalpha}$ & 0.00\\
\hspace{2em}Baseline-days-to-halfway elevation covariability, $\uppsi_{\uptheta\upbeta}$ & 0.00\\
\hspace{2em}Baseline-triquarter-halfway delta covariability, $\uppsi_{\uptheta\upgamma}$ & 0.00\\
\hspace{2em}Maximal elevation-days-to-halfway elevation covariability, $\uppsi_{\upalpha\upbeta}$ & 0.00\\
\hspace{2em}Maximal elevation-triquarter-halfway delta covariability, $\uppsi_{\upalpha\upgamma}$ & 0.00\\
\hspace{2em}Days-to-halfway elevation-triquarter-halfway delta covariability, $\uppsi_{\upbeta\upgamma}$ & 0.00\\
\hspace{2em}Residual standard deviation, $\uppsi_{\upepsilon}$ & 0.05\\*
\end{longtable}
\end{ThreePartTable}
\noindent Importantly, the model fit to each generated data set estimated nine parameters: A fixed-effect parameter for each of the four logistic function parameters, a random-effect parameter for each of the four logistic function parameters, and an error parameter. As with a multilevel model, a fixed-effect parameter has a constant value across all individuals, whereas a random-effect parameter represents the variability of values across all modelled people.\footnote{Estimating a random-effect for a parameter allows person- or data-point-specific values to be computed for the parameter.} To fit the logistic function to a given data set (Equation \ref{eq:logFunction-generation}), a linear approximation of the logistic function was needed so that it could fit within the linear nature of structural equation modelling framework.\footnote{The logistic function (Equation \ref{eq:logFunction-generation}) is a nonlinear function and so cannot be directly inserted into the structural equation modelling framework because this framework only allows linear computations of matrix-matrix, matrix-vector, and vector-vector operations. Unfortunately, the algebraic operations permitted in a linear framework cannot directly reproduce the operations in the logistic function (Equation \ref{eq:logFunction-generation}) and so a linear approximation of the logistic function must be constructed so that the logistic function can be inserted into the structural equation modelling framework.} To construct a linear approximation of the logistic function, a first-order Taylor series was constructed for the logistic function. For a detailed explanation of how the logistic function was fit into the structural equation modelling framework, see Appendix \ref{structured-lgc} for an explanation of the model and Appendix \ref{structured-lgc-code} for the code used to create the model.

\hypertarget{variables-used-in-simulation-experiment}{%
\subsection{Variables Used in Simulation Experiment}\label{variables-used-in-simulation-experiment}}

\hypertarget{independent-variables}{%
\subsubsection{Independent Variables}\label{independent-variables}}

To build on current research, Experiment 1 used independent variable manipulations from a select number of previous studies. In looking at the summary of the simulation literature in Table \ref{tab:systematicReview}, the study by \textcite{coulombe2016} was the only one to investigate three longitudinal issues of interest to my dissertation, and so represented the most comprehensive investigation. Because I was also interested in investigating measurement spacing, manipulations were inspired from the only other simulation study identified by my systematic review to manipulate measurement spacing \autocite[the study by][]{timmons2015}. The sections that follow will discuss each of the variables manipulated in Experiment 1.

\hypertarget{spacing-measurements}{%
\paragraph{Spacing of Measurements}\label{spacing-measurements}}

The only simulation study identified by my systematic review that manipulated measurement spacing was \textcite{timmons2015}. Measurement spacing in \textcite{timmons2015} was manipulated in the following four ways:
\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \emph{Equal spacing}: measurements are divided by intervals of equivalent lengths.
\item
  \emph{Time-interval increasing spacing}: intervals that divide measurements increase in length over time.
\item
  \emph{Time-interval decreasing spacing}: intervals that divide measurements decrease in length over time.
\item
  \emph{Middle-and-extreme spacing}: measurements are clustered near the beginning, middle, and end of the data collection period.
\end{enumerate}
\noindent To maintain consistency with the established literature, I manipulated measurement spacing in the same way as \textcite{timmons2015} presented above. Importantly, because \textcite{timmons2015} did not create their measurement spacing schedules with any systematicity, I developed a novel and replicable procedure for generating measurement schedules for each of the four measurement spacing conditions, which is described in Appendix \ref{measurement-schedules}. I also automated the generation of measurement schedules by creating a set of functions in R \autocite{rstudio}.

Table \ref{tab:measurementDays} lists the measurement days that were used for all measurement spacing-measurement number cells. The first column lists the type of measurement spacing (i.e., equal, time-interval increasing, time-interval decreasing, or middle-and-extreme); the second column lists the number of measurements (5, 7, 9, or 11); the third column lists the measurement days that correspond to each measurement number-measurement spacing condition; and the fourth column lists the interval lengths between the measurements. Note that the interval lengths are equal for equal spacing, increase over time for time-interval increasing spacing, and decrease over time for time-interval decreasing spacing. For cells with middle-and-extreme spacing, the measurement days and interval lengths in the middle of the measurement window have been emboldened.

\hypertarget{number-measurements}{%
\paragraph{Number of Measurements}\label{number-measurements}}

The smallest measurement number value in \textcite{coulombe2016} of three measurements could not be used in Experiment 1 (or any other simulation experiment that manipulated measurement number in my dissertation) because doing so would have created non-identified models The model used in my simulations estimated 9 parameters (\emph{p} = 9; 4 fixed-effects + 4 random-effects + 1 error)\footnote{Degrees of freedom is calculated by multiplying the number of observed variables (\textit{p}) by \textit{p} + 1 and dividing it by 2 \parencite[$\frac{p [p+1]}{2}$;][]{loehlin2017}.} and so the minimum number of measurements (or observed variables) required for model identification (and to allow model comparison) was 4. Although a measurement number of three could not be used in my manipulation of measurement number, the next highest measurement number values in \textcite{coulombe2016} of 5, 7, and 9 were used. Importantly, a larger value of 11 was

\newgeometry{margin=2.54cm}
\begin{landscape}\begingroup\fontsize{10}{12}\selectfont
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }For middle-and-extreme spacing levels, the measurement days and and interval lengths corresponding to the middle of measurement windows have been emboldened.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{4.5cm}>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{6.5cm}>{\raggedright\arraybackslash}p{6cm}}
\caption{\label{tab:measurementDays}Measurement Days Used for All Measurement Number-Measurement Spacing Conditions }\\
\toprule
Spacing Schedule & Number of Measurements & Measurement Days & Interval Lengths\\
\midrule
\endfirsthead
\caption[]{\label{tab:measurementDays}Measurement Days Used for All Measurement Number-Measurement Spacing Conditions  \textit{(continued)}}\\
\toprule
Spacing Schedule & Number of Measurements & Measurement Days & Interval Lengths\\
\midrule
\endhead

\endfoot
\bottomrule
\insertTableNotes
\endlastfoot
Equal & 5 & 0, 90, 180, 270, 360 & 90, 90, 90, 90\\
 & 7 & 0, 60, 120, 180, 240, 300, 360 & 60, 60, 60, 60, 60, 60\\
 & 9 & 0, 45, 90, 135, 180, 225, 270, 315, 360 & 45, 45, 45, 45, 45, 45, 45, 45\\
 & 11 & 0, 36, 72, 108, 144, 180, 216, 252, 288, 324, 360 & 36, 36, 36, 36, 36, 36, 36, 36, 36, 36\\
\cmidrule{1-4}\addlinespace
Time-interval increasing & 5 & 0, 30, 100, 210, 360 & 30, 70, 110, 150\\
 & 7 & 0, 30, 72, 126, 192, 270, 360 & 30, 42, 54, 66, 78, 90\\
 & 9 & 0, 30, 64.29, 102.86, 145.71, 192.86, 244.29, 300, 360 & 30, 34.29, 38.57, 42.86, 47.14, 51.43, 55.71, 60\\
 & 11 & 0, 30, 61.33, 94, 128, 163.33, 200, 238, 277.33, 318, 360 & 30, 31.33, 32.67, 34, 35.33, 36.67, 38, 39.33, 40.67, 42\\
\cmidrule{1-4}\addlinespace
Time-interval decreasing & 5 & 0, 150, 260, 330, 360 & 150, 110, 70, 30\\
 & 7 & 0, 90, 168, 234, 288, 330, 360 & 90, 78, 66, 54, 42, 30\\
 & 9 & 0, 60, 115.71, 167.14, 214.29, 257.14, 295.71, 330, 360 & 60, 55.71, 51.43, 47.14, 42.86, 38.57, 34.29, 30\\
 & 11 & 0, 42, 82.67, 122, 160, 196.67, 232, 266, 298.67, 330, 360 & 42, 40.67, 39.33, 38, 36.67, 35.33, 34, 32.67, 31.33, 30\\
\cmidrule{1-4}\addlinespace
Middle-and-extreme & 5 & 1, \textbf{150, 180, 210}, 360 & 150, \textbf{30, 30}, 150\\
 & 7 & 1, 30, \textbf{150, 180, 210}, 330, 360 & 30, 120, \textbf{30, 30}, 120, 30\\
 & 9 & 1, 30, 60, \textbf{150, 180, 210}, 300, 330, 360 & 30, 30, 90, \textbf{30, 30}, 90, 30, 30\\
 & 11 & 1, 30, 60, \textbf{120, 150, 180, 210, 240,} 300, 330, 360 & 30, 30, 60, \textbf{30, 30, 30, 30}, 60, 30, 30\\*
\end{longtable}
\end{ThreePartTable}
\endgroup{}
\end{landscape}
\restoregeometry

added to test for a possible effect of a high measurement number. Therefore, my simulation experiments used the following values in manipulating the number of measurements: 5, 7, 9, and 11.

\hypertarget{population-values-set-for-the-fixed-effect-days-to-halfway-elevation-parameter-upbeta_fixed-nature-of-change}{%
\paragraph{\texorpdfstring{Population Values Set for The Fixed-Effect Days-to-Halfway Elevation Parameter \(\upbeta_{fixed}\) (Nature of Change)}{Population Values Set for The Fixed-Effect Days-to-Halfway Elevation Parameter \textbackslash upbeta\_\{fixed\} (Nature of Change)}}\label{population-values-set-for-the-fixed-effect-days-to-halfway-elevation-parameter-upbeta_fixed-nature-of-change}}

The nature of change was manipulated by setting the days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) to a value of either 80, 180, or 280 days (see Figure \ref{fig:combined_plot}A). Note that no other study in my systematic review manipulated nature of change using logistic curves and so its manipulation in Experiment 1 is, to the best of my knowledge, unique. Importantly, nature of change was manipulated to simulate situations where uncertainty exists in how change unfolds over time.

\hypertarget{constants}{%
\subsubsection{Constants}\label{constants}}

Given that each simulation experiment manipulated no more than three independent variables so that results could be readily interpreted \autocite{halford2005}, other variables had to be set to constant values. In Experiment 1, two important variables were set to constant values: sample size and time structuredness. For sample size, I set the value across all cells to the average sample size used in organizational research \autocite[\emph{n} = 225;][]{bosco2015}. For time structuredness, data across all cells were generated to be time structured (i.e., all participants provide data according to one response pattern; that is, at each time point, participants provide their data at the exact same moment).

\hypertarget{dependent-variables}{%
\subsubsection{Dependent Variables}\label{dependent-variables}}

\hypertarget{convergence}{%
\paragraph{Convergence Success Rate}\label{convergence}}

The proportion of iterations in a cell where models converged defined the \emph{convergence success rate}.\footnote{Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.} Equation \eqref{eq:convergence} below shows the calculation used to compute the convergence success rate:
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged in a cell}}{n},
  \label{eq:convergence} 
\end{align}
\noindent where \emph{n} represents the total number of models run in a cell.

\hypertarget{model-performance}{%
\paragraph{Model Performance}\label{model-performance}}

Model performance was the combination of two metrics: bias and precision. More specifically, two questions were of importance in the estimation of a given logistic function parameter: 1) How well was the parameter estimated on average (bias) and 2) what was a range of values that could be expected for an estimate from the output of a single model (precision). In the two sections that follow, I will discuss each metric of model performance and the cutoffs used to determine whether estimation was unbiased and precise.

\hypertarget{bias-comp}{%
\subparagraph{Bias}\label{bias-comp}}

Bias was calculated to evaluate the accuracy with which each logistic function parameter was estimated in each experimental cell. As shown below in Equation \eqref{eq:bias}, \emph{bias} was obtained by summing the differences between the population value set for a parameter and the value estimated for the parameter by each \(i\) converged model and then dividing the sum by the number of \(N\) converged models.
\begin{align}
  \text{Bias} = \frac{\sum_i^N\text{(Population value for parameter} - \text{Average estimated value}_i)}{N}
  \label{eq:bias} 
\end{align}
\noindent Bias was calculated for the fixed- and random-effect parameters of the baseline (\(\uptheta_{fixed}\), \(\uptheta_{random}\)), maximal elevation (\(\upalpha_{fixed}\), \(\upalpha_{random}\)), days-to-halfway elevation (\(\upbeta_{fixed}\), \(\upbeta_{random}\)), and the triquarter-halfway delta parameters (\(\upgamma_{fixed}\), \(\upgamma_{random}\)) and the error parameter (\(\upepsilon\)).

\hypertarget{pres-precision}{%
\subparagraph{Precision}\label{pres-precision}}

In addition to computing bias, precision was calculated to evaluate the variability with which each parameter was estimated. Importantly, metrics used to evaluate precision in previous studies aoften ssume estimates are normally distributed (e.g., mean-squared error and empirical standard error). Because some parameters in my simulations had skewed distributions, using a metric that assumed a normal distribution would likely yield inaccurate results. Correspondingly, I used a distribution-independent definition of precision. In my simulations, \emph{precision} was defined as the range of values covered by the middle 95\% of values estimated for a logistic parameter.

\hypertarget{analysis-visualization}{%
\subsection{Analysis of Data Modelling Output and Accompanying Visualizations}\label{analysis-visualization}}

To analyse and visualize modelling performance, I calculated values for convergence success rate, bias, and precision in each experimental cell (see \protect\hyperlink{dependent-variables}{dependent variables}). The sections that follow provide details on how I analysed each dependent variable and constructed plots to visualize bias and precision.

\hypertarget{convergence-analysis}{%
\subsubsection{Analysis of Convergence Success Rate}\label{convergence-analysis}}

For the analysis of convergence success rate, the mean convergence success rate was computed for each cell in each experiment (see section on \protect\hyperlink{convergence}{convergence success rate}). Because convergence rates exhibited little variability across cells due to the nearly unanimous high rates (almost all cells across all experiments had convergence success rates above 90\%), examining the effects of any independent variable on these values would have provided little information. Therefore, I only reported the average convergence success rate for each cell (see Appendix \ref{convergence-tables}).

\hypertarget{bias-analysis}{%
\subsubsection{Analysis and Visualization of Bias}\label{bias-analysis}}

In accordance with several simulation studies, an estimate with a bias value within a \(\pm10\%\) margin of error of the parameter's population value was deemed unbiased \autocite{muthen1997}. To visualize bias, I constructed bias/precision plots. Figure \ref{fig:param-estimation-ex} shows a bias/precision plot for the fixed-effect triquarter-halfway parameter (\(\upgamma_{fixed}\)) for each measurement number and nature of change. The dots (squares, circles, triangles, diamonds) indicate the average estimated value (see \protect\hyperlink{bias-comp}{bias}). The horizontal blue line indicates the population value (\(\upgamma_{fixed}\) = 4.00) and the gray band indicates the acceptable margin of error of \(\pm10\%\) of the parameter's population value. Dots that lie within the gray margin of error are filled and dots that lie outside of the margin remain unfilled. In the current example, the average value estimated for the fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)) is only biased (i.e., lies outside the margin of error) with five measurements with a nature-of-change value of 80 (\(\upbeta_{fixed}\) = 80). Therefore, estimates are unbiased in almost all cells.

\hypertarget{precision-analysis}{%
\subsubsection{Analysis and Visualization of Precision}\label{precision-analysis}}

As discussed previously, precision was defined as the range of values covered by the middle 95\% of estimated values for a given parameter (see \protect\hyperlink{precision-mid-ext-exp1}{precision}). The cutoff value used to estimate precision directly followed from the cutoff value used for bias. Given that bias values within a \(\pm10\%\) of a parameter's population value were deemed acceptable, an acceptable value for precision should not allow any bias value above the \(\pm10\%\) cutoff. That is, the range covered by the middle 95\% of estimated values should not contain a bias value outside the \(\pm10\%\) cutoff. If the range of values covered by the middle 95\% of estimate values is conceptualized as an error bar centered on the population value, then an acceptable value for precision implies that neither the lower nor upper whiskers have a length greater than 10\% of the parameter's population value. In summary, I deemed precision acceptable if no estimate within the range of values covered by the middle 95\% of estimated values had a bias value greater than 10\% of the population value, which also means that neither the lower nor upper whiskers of the error bar have a length greater than 10\% of the population value.

Like bias, I also depicted precision in bias/precision plots using error bars. Each error bar in the bias/precision plot of Figure \ref{fig:param-estimation-ex} indicates the range of values covered by the middle 95\% of estimated values in the given cell for the fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)). Importantly, if estimation is not precise, then at least one of the lower and/or upper whisker lengths exceeds 10\% of the parameter's population value. When estimation is not precise, the error bar is light blue. When estimation is precise (i.e., neither of the lower or upper whisker lengths exceed 10\% of the parameter's population value), the corresponding error bar is black. In the current example, all error bars are light blue and so precision is low in all cells.
\begin{apaFigure}
[portrait]
[0cm]
{Bias/Precision Plot for the Fixed-Effect Days-to-Halfway Elevation Parameter ($\upgamma_{fixed}$)}
{param-estimation-ex}
{0.9}
{Figures/param_estimation_ex}
{Dots (squares, circles, triangles, diamonds) indicate the average estimated value and error bars show the range of values covered by the middle 95\% of the estimated values (see \nameref{pres-precision}). The horizontal blue line indicates the population value ($\upgamma_{fixed}$ = 4.00) and the gray band indicates the acceptable margin of error (i.e., $\pm$10\% of the population value) for bias. Dots that lie outside of the margin of error are unfilled and are considered biased estimates. Dots that lie inside the margin of error are filled and considered unbiased estimates. Error bars whose upper and/or lower whisker lengths exceed 10\% of the parameter's population value are light blue and indicate parameter estimation that is not precise. Error bars whose upper and/or lower whisker lengths do not excced 10\% of the parameter's population value are black and indicate parameter estimation that is precise.}
\end{apaFigure}
\hypertarget{effect-size-computation-for-precision}{%
\paragraph{Effect Size Computation for Precision}\label{effect-size-computation-for-precision}}

One last statistic I calculated was an effect size value to estimate the variance in parameter estimates accounted for by each effect. Among the several effect size metrics---at a broad level, effect size metrics can represent standardized differences or variance-accounted-for measures that are corrected or uncorrected for sampling error---the corrected variance-accounted-for effect size metric of partial \(\upomega^2\) was chosen because of three desirable properties. First, partial \(\upomega^2\) provides a less biased estimate of effect size than other variance-accounted-for measures \autocite{okada2013}. Second, partial \(\upomega^2\) is more robust to assumption violations of normality and homogeneity of variance \autocite{yigit2018}. Given that parameter estimates were often non-normally distributed across cells, effect size values computed with partial \(\upomega^2\) should be relatively less biased than other variance-accounted-for effect size metrics (e.g., \(\eta^2\)). Third, partial \(\upomega^2\) provides an effect size estimate that is not diluted by the inclusion of unaccountable variance in the denominator. To compute partial \(\upomega^2\) value for each experimental effect, Equation \ref{eq:partial-omega} shown below was used:
\begin{align}
\text{partial} \upomega^2 = \frac{\sigma^2_{effect}}{\sigma^2_{effect} + MSE} 
\label{eq:partial-omega}
\end{align}
\noindent where \(\sigma^2_{effect}\) represents the variance accounted by an effect and \(MSE\) is the mean squared error. Importantly, \(\sigma^2_{effect}\) values were corrected values obtained by using the following formula in Equation \ref{eq:var-effect} for a two-way factorial design with fixed variables \autocite{howell2009}:
\begin{align}
 \sigma^2_{effect} = \frac{(a - 1)(MS_{effect} - MS_{error})}{nab},
\label{eq:var-effect}
\end{align}
\noindent where \(a\) is the number of levels in the effect, \(b\) is the number of levels in the second effect, and \(n\) is the cell size. The variance accounted by the interaction was computed using the following formula in Equation \ref{eq:var-interac}:
\begin{align}
 \sigma^2_{A x B} = \frac{(a - 1)(b-1)(MS_{AxB} - MS_{error})}{nab}. 
\label{eq:var-interac}
\end{align}
To compute partial \(\upomega^2\) values for effects, a Brown-Forsythe test was computed and the appropriate sum-of-squares terms were used to compute partial \(\upomega^2\) values. A Brown-Forsythe test was used to protect against the biasing effects of skewed distributions \autocite{brown1974}, which were observed in the parameter estimate distributions in the current simulation experiments. To compute the Brown-Forsythe test, median absolute deviations in each cell were computed by calculating the absolute difference between each \(i\) estimate and the median estimated value in the given experimental cell as shown in Equation \ref{eq:brown-forsythe} below:
\begin{align}
\text{Median absolute deviation}_i = \lvert \text{Parameter estimate}_i - \text{Median parameter estimate}_{cell} \rvert.
\label{eq:brown-forsythe}
\end{align}
\noindent An ANOVA was then computed on the median absolute deviation values (using the independent variables of the experiment and the associated interactions as predictors), with the terms in Equation \ref{eq:partial-omega} extracted from the ANOVA output to compute partial \(\upomega^2\) values.

\hypertarget{results-and-discussion}{%
\section{Results and Discussion}\label{results-and-discussion}}

In the sections that follow, I organize the results by presenting them for each spacing schedule (equal, time-interval increasing, time-interval decreasing, middle-and-extreme). The results are presented for each spacing schedule because answering my research questions first requires knowledge of these results. To answer my first question of whether model performance increases from placing measurements during periods of change, I need to determine whether model performance under each spacing schedule increases when measurements are placed near periods of change. To answer my second question of how to space measurements when the nature of change is unknown, model performance across all manipulated nature-of-change values must first be calculated for each spacing schedule. The spacing schedule that obtains the highest model performance across all nature-of-change values can then be determined as the best schedule to use.

For each spacing schedule, I will first present a concise summary table of the results and then provide a detailed report for each column of the summary table. Because the detailed reports are of considerable length, I provide concise summaries before the detailed reports to establish a framework to help interpret the detailed reports. The detailed report of each spacing schedule presents the results of each day-unit's bias/precision plot, model performance under each nature-of-change value, and then provides a qualitative summary. After providing the results for each spacing schedule, I then use the results to answer my research questions.

\hypertarget{framework-for-interpreting-results}{%
\subsection{Framework for Interpreting Results}\label{framework-for-interpreting-results}}

To conduct Experiment 1, the three variables of number of measurements (4 levels), measurement spacing (4 levels), and nature of change (3 levels) were manipulated, which yielded a total of 48 cells. Importantly, within each cell, bias and precision values were also computed for each of the nine parameters estimated by the structured latent growth curve model (for a review, see \protect\hyperlink{modelling-data-sets}{modelling of each generated data set}). Thus, because the analysis of Experiment 1 computed values for many dependent variables, interpreting the results can become overwhelming. Therefore, I will provide a framework to help the reader efficiently navigate the results section.

Because I will present the results of Experiment 1 by each level of measurement spacing, the framework I will describe in Figure \ref{fig:results-plot-primer} shows a template for the bias/precision plots that I will present for each spacing schedule. The results of each spacing schedule contain a bias/precision plot for each of the nine estimated parameters. Each bias/precision plot shows the bias and precision for the estimation of one parameter across all measurement number and nature-of change levels. Within each bias/precision plot, dots indicate the average estimated value (which indicates bias bias) and error bars represent the middle 95\% range of estimated values (which indicates precision). Bias/precision plots with black outlines show the results for day-unit parameters and plots with gray outlines show the results for Likert-unit parameters. Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and triquarter-halfway delta parameters {[}\(\upbeta_{fixed}\), \(\upbeta_{random}\), \(\upgamma_{fixed}\), \(\upgamma_{random}\), respectively{]}). The results for the Likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters {[}\(\uptheta_{fixed}\), \(\uptheta_{random}\), \(\upalpha_{fixed}\), \(\upalpha_{random}\), respectively{]}) were largely trivial and so are presented in Appendix \ref{complete-versions}. Therefore, the results of each spacing schedule will only present the bias/precision plots for four parameters (i.e., the day-unit parameters).
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Set of Bias/Precision Plots Constructed for Each Spacing Schedule in Experiment 1}
{results-plot-primer}
{.95}
{Figures/logistic_results_plot_exp1}
{A bias/precision plot is constructed for each parameter of the logistic function (see Equation \ref{eq:logFunction-generation}). Bias/precision plots with black borders show the results for day-unit parameters and plots with gray border show the results for Likert-unit parameters. For each parameter, bias and precision are shown across each combination of measurement number and nature of change.}\end{apaFigure}

\hypertarget{pre-processing-of-data-and-model-convergence}{%
\subsection{Pre-Processing of Data and Model Convergence}\label{pre-processing-of-data-and-model-convergence}}

After collecting the output from the simulations, non-converged models (and their corresponding parameter estimates) were removed from subsequent analyses. Table \ref{tab:conv-exp-1} in Appendix \ref{convergence-tables} provides the convergence success rates for each cell in Experiment 1. Model convergence was almost always above 90\% and convergence rates, with rates only going below 90\% in two cells (or instances) with five measurements.

\hypertarget{concise-tab}{%
\subsection{Equal Spacing}\label{concise-tab}}

For equal spacing, Table \ref{tab:summary-table-equal-spacing-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_equal} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-equal-spacing-exp1} and provide elaboration when necessary.

Before presenting the results for equal spacing, I provide a brief description of the concise summary table created for each spacing schedule and shown for equal spacing below in Table \ref{tab:summary-table-equal-spacing-exp1}. Text within the `Highest Model Performance' column indicates the nature-of-change value that resulted in the highest model performance for each day-unit parameter. Text within the `Unbiased' and `Precise' columns indicates the number of measurements that were needed to, respectively, obtain unbiased and precise parameter estimation across all manipulated nature-of-change values. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters and manipulated nature-of-change values. The `Error Bar Length' column indicates the average error bar length across all manipulated nature-of-change values that resulted from using the measurement number listed in the

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \hyperref[nature-change-equal-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-equal-spacing-exp1}Concise Summary of Results for Equal Spacing in Experiment 1}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{2}{c}{Summary} \\
\cmidrule(l{3pt}r{3pt}){5-6}
Parameter & Highest Model Performance & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp1_plot_equal}A)} & $\upbeta_{fixed}$ = 180 & All cells & All cells & Largest improvements in precision with \textbf{NM = 7} & 5.64\\
\cmidrule{1-6}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp1_plot_equal}B)} & $\upbeta_{fixed}$ = 180 & All cells & No cells & Largest improvements in precision with \textbf{NM = 7} & 4.37\\
\cmidrule{1-6}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp1_plot_equal}C)} & $\upbeta_{fixed}$ = 180 & All cells & No cells & Largest improvements in precision with \textbf{NM = 7} & 7.74\\
\cmidrule{1-6}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp1_plot_equal}D)} & $\upbeta_{fixed}$ = 180 & \textbf{NM $\boldsymbol{\ge}$ 9} & No cells & Largest improvements in bias and precision with \textbf{NM = 7} & 7.02\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\noindent `Qualitative Description' column.

\hypertarget{nature-change-equal-exp1}{%
\subsubsection{Nature of Change That Leads to Highest Model Performance}\label{nature-change-equal-exp1}}

For equal spacing, Table \ref{tab:errorbar-equal-nc} lists the precision values (i.e., error bar lengths) for each day-unit parameter across each nature-of-change value. The `Total' column indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Total' indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\in$ \{5, 7, 9, 11\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.
\item[a] Error bar length is longest in this case because of the existence of high-value outliers (see Figure \ref{fig:density_gamma_equal}).
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}ccc>{}c>{}c>{}cccc}
\caption{\label{tab:errorbar-equal-nc}Error Bar Lengths Across Nature-of-Change Values Under Equal Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{9}{c}{Population Value of $\upbeta_{fixed}$} \\
\cmidrule(l{3pt}r{3pt}){2-10}
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{80} & \multicolumn{3}{c}{180} & \multicolumn{3}{c}{280} \\
\cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7} \cmidrule(l{3pt}r{3pt}){8-10}
Parameter & Lower & Upper & Total & Lower & Upper & Total & Lower & Upper & Total\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp1_plot_equal}A)} & 4.42 & 4.12 & 8.54 & \cellcolor[HTML]{DFDEDE}{2.46} & \cellcolor[HTML]{DFDEDE}{2.32} & \cellcolor[HTML]{DFDEDE}{4.78} & 4.09 & 4.16 & 8.25\\
\thead[lt]{$\upgamma_{fixed}$ \\ (Figure \ref{fig:exp1_plot_equal}B)} & 4.84 & 4.69 & 9.53 & \cellcolor[HTML]{DFDEDE}{4.95} & \cellcolor[HTML]{DFDEDE}{3.7} & \cellcolor[HTML]{DFDEDE}{8.65} & 4.79 & 4.65 & 9.44\\
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp1_plot_equal}C)} & 4.74 & 3.88 & 8.62 & \cellcolor[HTML]{DFDEDE}{3.96} & \cellcolor[HTML]{DFDEDE}{3.55} & \cellcolor[HTML]{DFDEDE}{7.51} & 4.77 & 4.05 & 8.82\\
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp1_plot_equal}D)} & 3.00 & 5.52 & 8.52 & \cellcolor[HTML]{DFDEDE}{3.00} & \cellcolor[HTML]{DFDEDE}{13.05\textsuperscript{a}} & \cellcolor[HTML]{DFDEDE}{16.05} & 3.00 & 5.78 & 8.78\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\noindent parameter, they were largely redundant and so were not reported for equal spacing. Although model performance was determined by bias and precision, results for bias were not reported because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated number of measurements. The column shaded in gray indicates the nature of change where precision was highest (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 180 across all day-unit parameters under equal spacing with one exception (see the `Highest Model Performance' in Table \ref{tab:summary-table-equal-spacing-exp1}). Importantly, with a nature-of-change value of 180, measurements were taken closer to periods of change under equal spacing than with other nature-of-change values (see Figure \ref{fig:equal-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with equal spacing.

To understand why precision for the random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\)) was lower with a nature-of-change value of 180, I looked at the distribution of estimated values. Figure \ref{fig:density_gamma_equal} shows the distribution of values (i.e., density plots) estimated for the random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\)) for each nature-of-change level with five measurements. Importantly, the error bars in the bias/precision plot of Figure \ref{fig:exp1_plot_equal}D with five measurements are created from the density plots shown in Figure \ref{fig:density_gamma_equal}. Panel A shows the density plot with a nature-of-change value of 80 (\(\upbeta_{fixed}\) = 80). Panel B shows the density plot with a with a nature-of-change value of 180 (\(\upbeta_{fixed}\) = 180). Panel C shows the density plot with a with a nature-of-change value of 280 (\(\upbeta_{fixed}\) = 280). Regions shaded in gray represent the middle 95\% of estimated
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Equal Spacing}
{equal-spacing-nc}
{0.25}
{Figures/midpoint_180_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 180 with equal spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-equal-nc}).}
\end{apaFigure}
\noindent values and the width of the shaded regions is indicated by the length of the horizontal error bars. As originally confirmed by Table \ref{tab:errorbar-equal-nc}, Figure \ref{fig:density_gamma_equal}B shows that precision was indeed lowest (i.e., longer error bars) with a nature of change of 180. In looking across the density plots in Figure \ref{fig:density_gamma_equal}, precision was lowest (i.e., longest error bars) for the random-effect triquarter-halfway parameter (\(\upgamma_{random}\)) with a nature-of-change value of 180 because of the existence of high-value outliers.

In summary, under equal spacing, model performance for all the day-unit parameters was greatest when the nature-of-change value set by the fixed-effect days-to-halfway
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Density Plots of the Random-Effect Triquarter-Halfway Delta ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D) With Equal Spacing in Experiment 1 (95\% Error Bars)}
{density_gamma_equal}
{0.16}
{Figures/density_plots_equal_gamma_exp1}
{Regions shaded in in gray represent the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. The error bar length if longest when the nature-of-change value is 180. $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter, with population value of 4.00, NM = number of measurements.}
\end{apaFigure}
\noindent elevation parameter (\(\upbeta_{fixed}\)) had a value of 180. The one exception to this result was that model performance (as indicated by precision) was lower for the random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\)) with a nature-of-change value of 180 because of high-value outliers.

\hypertarget{bias-equal-exp1}{%
\subsubsection{Bias}\label{bias-equal-exp1}}

Before presenting the results for bias, I provide a description of the set of bias/precision plots shown in Figure \ref{fig:exp1_plot_equal} and in the results sections for the other spacing schedules in Experiment 1. Figure \ref{fig:exp1_plot_equal} shows the bias/precision plots for each day-unit parameter and Table \ref{tab:omega-exp1-equal} provides the partial \(\upomega^2\) values for each independent variable of each day-unit parameter. In Figure \ref{fig:exp1_plot_equal}, blue horizontal lines indicate the population values for each parameter (with population values of \(\upbeta_{fixed} \in\) \{80, 180, 280\}, \(\upbeta_{random}\) = 10.00, \(\upgamma_{fixed}\) = 20.00, and \(\upgamma_{random}\) = 4.00). Gray bands indicate the \(\pm 10\%\) margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Panels A--B show the bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters (\(\upbeta_{fixed}\) and \(\upbeta_{random}\), respectively). Panels C--D show the bias/precision plots for the fixed- and random-effect triquarter-halfway delta parameters (\(\upgamma_{fixed}\) and \(\upgamma_{random}\), respectively). Note that random-effect parameter units are in standard deviation units. Importantly, across all population values used for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)), the acceptable amount of bias and
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day-Unit Parameters With Equal Spacing in Experiment 1}
{exp1_plot_equal}
{0.16}
{Figures/exp1_plot_days_equal spacing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-equal} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements $\in$ \{5, 7, 9, 11\}, NC = nature of change (population value set for $\upbeta_{fixed}$ $\in$ \{80, 180, 280\}), NM x NC = interaction between number of measurements and population value set for $\upbeta_{fixed}$. $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp1-equal}Partial $\upomega^2$ Values for Manipulated Variables With Equal Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & NC & NM x NC\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp1_plot_equal}A) & 0.02 & 0.00 & 0.01\\
$\upbeta_{random}$ (Figure \ref{fig:exp1_plot_equal}B) & 0.29 & 0.02 & 0.02\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp1_plot_equal}C) & 0.36 & 0.01 & 0.03\\
$\upgamma_{random}$ (Figure \ref{fig:exp1_plot_equal}D) & 0.21 & 0.03 & 0.04\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\noindent precision was based on a population value of 180.

With respect to bias for equal spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_equal}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_equal}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_equal}C): no cells.
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp1_plot_equal}D): five measurements with all manipulated nature-of-change values and seven measurements with nature-of-change values of 180 and 280.
\end{itemize}
In summary, with equal spacing, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using nine or more measurements, which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-equal-spacing-exp1}.

\hypertarget{precision-equal-exp1}{%
\subsubsection{Precision}\label{precision-equal-exp1}}

With respect to precision for equal spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_equal}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_equal}B): all cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_equal}C): all cells.
\item
  random-effect triquarter-halfway delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp1_plot_equal}D): all cells.
\end{itemize}
In summary, with equal spacing, estimation across all manipulated nature-of-change values was only precise for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) with five or more measurements. No manipulated measurement number resulted in precise estimation of the fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)) or the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-equal-spacing-exp1}).

\hypertarget{qualitative-equal-exp1}{%
\subsubsection{Qualitative Description}\label{qualitative-equal-exp1}}

Although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurements numbers. With respect to bias under equal spacing, the largest improvements in bias across all manipulated nature-of-change values resulted from using the following measurement numbers for the following day-unit parameters (note that only the random-effect triquarter halfway delta parameter {[}\(\upgamma_{random}\){]} had instances of high bias):
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): seven measurements.
\end{itemize}
\noindent With respect to precision under equal spacing, the largest improvements precision in the estimation of all day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) were obtained with following measurement numbers:
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements, which resulted in a maximum error bar length of 4.37 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements, which resulted in a maximum error bar length of 7.74 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements, which resulted in a maximum error bar length of 7.02 days.
\end{itemize}
\noindent Therefore, for equal spacing, seven measurements led to the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-equal-spacing-exp1}).

\hypertarget{summary-of-results-with-equal-spacing}{%
\subsubsection{Summary of Results With Equal Spacing}\label{summary-of-results-with-equal-spacing}}

In summarizing the results for equal spacing, model performance was highest across all day-unit parameters (with the random-effect days-to-halfway elevation parameter (\(\upgamma_{random}\)) being an exception) when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 180 (see \protect\hyperlink{nature-change-equal-exp1}{highest model performance}). Unbiased estimation of all the day-unit parameters across all manipulated nature-of-change values resulted from using nine or more measurements (see \protect\hyperlink{bias-equal-exp1}{bias}). Precise estimation of all the day-unit parameters was never obtained with any manipulated measurement number (see \protect\hyperlink{precision-equal-exp1}{precision}). Although it may be discouraging that no manipulated measurement number under equal spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With equal spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values were obtained using seven measurements (see \protect\hyperlink{qualitative-equal-exp1}{Qualitative Description}).

\hypertarget{time-interval-increasing-spacing}{%
\subsection{Time-Interval Increasing Spacing}\label{time-interval-increasing-spacing}}

For time-interval increasing spacing, Table \ref{tab:summary-table-time-inc-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_inc} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-inc-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-inc-exp1}, see \protect\hyperlink{concise-tab}{concise summary table}).

\hypertarget{nature-change-time-inc-exp1}{%
\subsubsection{Nature of Change That Leads to Highest Model Performance}\label{nature-change-time-inc-exp1}}

For time-interval increasing spacing, Table \ref{tab:errorbar-time-inc-nc} lists the precision values (i.e., error bar lengths) for each day-unit parameter across each nature-of-change value. The `Total' column indicates the total error bar length, which is a sum of the the lower (`Lower') and upper (`Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for the remainder of the results for time-interval increasing spacing. Although model performance was determined by bias and precision, results for bias were not reported because the differences in bias across the nature-of-change values were negligible.

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \hyperref[nature-change-time-inc-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with time-interval increasing spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-time-inc-exp1}Concise Summary of Results for Time-Interval Increasing Spacing in Experiment 1}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){5-6}
Parameter & Highest Model Performance & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_inc}A)} & $\upbeta_{fixed}$ = 80 & All cells & NM $\ge$ 7 & Largest improvement in precision with NM = 7 & 8.38\\
\cmidrule{1-6}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_inc}B)} & $\upbeta_{fixed}$ = 80 & All cells & No cells & Largest improvement in precision with \textbf{NM = 9} & 3.45\\
\cmidrule{1-6}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp1_plot_time_inc}C)} & $\upbeta_{fixed}$ = 80 & NM $\ge$ 7 & No cells & Largest improvement in bias and precision with NM = 7 & 9.47\\
\cmidrule{1-6}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp1_plot_time_inc}D)} & $\upbeta_{fixed}$ = 80 & \textbf{NM $\ge$ 9} & No cells & Largest improvements in bias and precision with \textbf{NM = 9} & 5.97\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\noindent Note that error bar lengths were obtained by computing the average length across all manipulated number of measurements. The column shaded in gray indicates the nature of change where precision was highest (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 80 across all day-unit parameters under time-interval increasing spacing (see the `Highest Model Performance' in Table \ref{tab:summary-table-time-inc-exp1}). Importantly, with a nature-of-change value of 80, measurements were taken closer to periods of change under time-interval increasing spacing than with other nature-of-change values (see Figure \ref{fig:time-inc-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with time-interval increasing spacing.
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Total' indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\in$ \{5, 7, 9, 11\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{}c>{}c>{}ccccccc}
\caption{\label{tab:errorbar-time-inc-nc}Error Bar Lengths Across Nature-of-Change Values Under Time-Interval Increasing Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{9}{c}{Population Value of $\upbeta_{fixed}$} \\
\cmidrule(l{3pt}r{3pt}){2-10}
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{80} & \multicolumn{3}{c}{180} & \multicolumn{3}{c}{280} \\
\cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7} \cmidrule(l{3pt}r{3pt}){8-10}
Parameter & Lower & Upper & Total & Lower & Upper & Total & Lower & Upper & Total\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_inc}A)} & \cellcolor[HTML]{DFDEDE}{3.04} & \cellcolor[HTML]{DFDEDE}{2.76} & \cellcolor[HTML]{DFDEDE}{5.80} & 3.90 & 6.72 & 10.62 & 17.87 & 14.84 & 32.71\\
\thead[lt]{$\upgamma_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_inc}B)} & \cellcolor[HTML]{DFDEDE}{1.59} & \cellcolor[HTML]{DFDEDE}{2.81} & \cellcolor[HTML]{DFDEDE}{4.40} & 4.39 & 3.21 & 7.60 & 9.00 & 6.38 & 15.38\\
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp1_plot_time_inc}C)} & \cellcolor[HTML]{DFDEDE}{3.55} & \cellcolor[HTML]{DFDEDE}{3.25} & \cellcolor[HTML]{DFDEDE}{6.80} & 4.41 & 4.18 & 8.59 & 6.20 & 9.60 & 15.81\\
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp1_plot_time_inc}D)} & \cellcolor[HTML]{DFDEDE}{3.00} & \cellcolor[HTML]{DFDEDE}{3.34} & \cellcolor[HTML]{DFDEDE}{6.34} & 3.00 & 4.10 & 7.10 & 3.00 & 7.09 & 10.09\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Time-Interval Increasing Spacing}
{time-inc-spacing-nc}
{0.25}
{Figures/midpoint_80_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 80 with equal spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-time-inc-nc}).}
\end{apaFigure}
\hypertarget{bias-time-inc-exp1}{%
\subsubsection{Bias}\label{bias-time-inc-exp1}}

With respect to bias for time-interval increasing spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_time_inc}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_time_inc}B): no cells
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_inc}C): five measurements with a nature-of-change value of 280.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_inc}C): five measurements with all nature-of-change values and seven measurements with nature-of-change values of 180 and 280.
\end{itemize}
In summary, with time-interval increasing spacing, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using nine or more measurements, which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-time-inc-exp1}.

\hypertarget{precision-time-inc-exp1}{%
\subsubsection{Precision}\label{precision-time-inc-exp1}}

With respect to precision for time-interval increasing spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_time_inc}A): five measurements with nature-of-change values of 180 and 280.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_time_inc}B): all cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_inc}C): all cells.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\); Figure \ref{fig:exp1_plot_time_inc}D): all cells.
\end{itemize}
In summary, with time-interval increasing spacing, estimation across all manipulated nature-of-change values was only precise for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) with seven or more measurements. No manipulated measurement number resulted in precise estimation of the fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)) or the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-time-inc-exp1}).
\begin{apaFigure}
[portrait] %orientation (portrait or landscape)
[samepage] 
[-0.2cm] %spacing between bottom of figure and footnote
{Bias/Precision Plots for Day-Unit Parameters With Time-Interval Increasing Spacing in Experiment 1} %figure title 
{exp1_plot_time_inc} %figure label 
{0.16} %scaling factor: modifying height and width together 
{Figures/exp1_plot_days_time-interval increasing} %location of where to get figure 
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80.00, 180.00, 280.00}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-inc} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements $\in$ \{5, 7, 9, 11\}, NC = nature of change (population value set for $\upbeta_{fixed}$ $\in$ \{80, 180, 280\}), NM x NC = interaction between number of measurements and population value set for $\upbeta_{fixed}$. $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp1-time-inc}Partial $\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & NC & NM x NC\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp1_plot_time_inc}A) & 0.43 & 0.30 & 0.50\\
$\upbeta_{random}$ (Figure \ref{fig:exp1_plot_time_inc}B) & 0.12 & 0.04 & 0.05\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp1_plot_time_inc}C) & 0.26 & 0.21 & 0.22\\
$\upgamma_{random}$ (Figure \ref{fig:exp1_plot_time_inc}D) & 0.12 & 0.05 & 0.04\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\hypertarget{qualitative-time-inc-exp1}{%
\subsubsection{Qualitative Description}\label{qualitative-time-inc-exp1}}

For time-interval increasing spacing in Figure \ref{fig:exp1_plot_time_inc}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurements numbers. With respect to bias under time-interval increasing spacing, the largest improvements across all manipulated nature-of-change values in bias occurred with the following measurement numbers for the random-effect day-unit parameters:
\begin{itemize}
\tightlist
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements.
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): nine measurements.
\end{itemize}
\noindent With respect to precision under time-interval increasing spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values resulted with the following measurement numbers:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)): seven measurements, which results in an average error bar length of 8.38 days.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): nine measurements, which results in an average error bar length of 3.45 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): nine measurements, which results in an average error bar length of 9.47 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): nine measurements, which results in an average error bar length of 5.97 days.
\end{itemize}
\noindent Therefore, for time-interval increasing spacing, nine measurements resulted in the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the 'Qualitative Description` column in Table \ref{tab:summary-table-time-inc-exp1}).

\hypertarget{summary-of-results-with-time-interval-increasing-spacing}{%
\subsubsection{Summary of Results With Time-Interval Increasing Spacing}\label{summary-of-results-with-time-interval-increasing-spacing}}

In summarizing the results for time-interval increasing spacing, model performance was highest across all day-unit parameters when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 80 (\(\upbeta_{fixed}\) = 80; see \protect\hyperlink{nature-change-time-inc-exp1}{highest model performance}). Estimation of all day-unit parameters was unbiased across all manipulated nature-of-change values using nine or more measurements (see \protect\hyperlink{bias-time-inc-exp1}{bias}). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement (see \protect\hyperlink{precision-time-inc-exp1}{precision}). Although it may be discouraging that no manipulated measurement number under time-interval increasing spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With time-interval increasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values resulted from using nine measurements (see \protect\hyperlink{qualitative-time-inc-exp1}{qualitative description}).

\hypertarget{time-interval-decreasing-spacing}{%
\subsection{Time-Interval Decreasing Spacing}\label{time-interval-decreasing-spacing}}

For time-interval decreasing spacing, Table \ref{tab:summary-table-time-dec-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_dec} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-dec-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-dec-exp1}, see \protect\hyperlink{concise-tab}{concise summary table}).

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \hyperref[nature-change-time-dec-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with time-interval decreasing spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-time-dec-exp1}Concise Summary of Results for Time-Interval Decreasing Spacing in Experiment 1}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){5-6}
Parameter & Highest Model Performance & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_dec}A)} & $\upbeta_{fixed}$ = 280 & All cells & NM $\ge$ 9 & Largest improvements in precision with \textbf{NM = 9} & 4.88\\
\cmidrule{1-6}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_dec}B)} & $\upbeta_{fixed}$ = 280 & NM $\ge$ 7 & No cells & Largest improvement in precision with \textbf{NM = 9} & 3.40\\
\cmidrule{1-6}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp1_plot_time_dec}C)} & $\upbeta_{fixed}$ = 280 & NM $\ge$ 7 & No cells & Largest improvement in bias and precision with \textbf{NM = 9} & 6.15\\
\cmidrule{1-6}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp1_plot_time_dec}D)} & $\upbeta_{fixed}$ = 280 & \textbf{NM $\boldsymbol{\ge}$ 9} & No cells & Largest improvements in bias and precision with \textbf{NM = 9} & 5.96\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\hypertarget{nature-change-time-dec-exp1}{%
\subsubsection{Nature of Change That Leads to Highest Model Performance}\label{nature-change-time-dec-exp1}}

For time-interval decreasing spacing, Table \ref{tab:errorbar-time-dec-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. The `Total' column indicates the total error bar length, which is a sum of the the lower (`Lower') and upper (`Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for the remainder of the results for time-interval decreasing spacing. Although model performance was determined by bias and precision, results for bias were not computed because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated measurement number values. The column shaded in gray indicates the nature of change where precision was highest (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 280 across all day-unit parameters under time-interval decreasing spacing (see the `Highest Model Performance' in Table \ref{tab:summary-table-time-dec-exp1}). Importantly, with a nature-of-change value of 280, measurements were taken closer to periods of change under time-interval decreasing spacing than with other nature-of-change values (see Figure \ref{fig:time-dec-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with time-interval decreasing spacing.

\hypertarget{bias-time-dec-exp1}{%
\subsubsection{Bias}\label{bias-time-dec-exp1}}

With respect to bias for time-interval decreasing spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_time_dec}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_time_dec}B): five
\end{itemize}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\in$ \{5, 7, 9, 11\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3.5cm}cccccc>{}c>{}c>{}c}
\caption{\label{tab:errorbar-time-dec-nc}Error Bar Lengths Across Nature-of-Change Values Under Time-Interval Decreasing Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{9}{c}{Population Value of $\upbeta_{fixed}$} \\
\cmidrule(l{3pt}r{3pt}){2-10}
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{80} & \multicolumn{3}{c}{180} & \multicolumn{3}{c}{280} \\
\cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7} \cmidrule(l{3pt}r{3pt}){8-10}
Parameter & Lower & Upper & Total & Lower & Upper & Total & Lower & Upper & Total\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp1_plot_time_dec}A) & 30.51 & 15.73 & 46.24 & 7.64 & 3.67 & 11.31 & \cellcolor[HTML]{DFDEDE}{3.28} & \cellcolor[HTML]{DFDEDE}{2.56} & \cellcolor[HTML]{DFDEDE}{5.84}\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp1_plot_time_dec}B) & 9.70 & 6.11 & 15.81 & 4.88 & 3.14 & 8.02 & \cellcolor[HTML]{DFDEDE}{1.79} & \cellcolor[HTML]{DFDEDE}{2.69} & \cellcolor[HTML]{DFDEDE}{4.48}\\
$\upbeta_{random}$ (Figure \ref{fig:exp1_plot_time_dec}C) & 6.09 & 11.26 & 17.35 & 4.70 & 3.90 & 8.60 & \cellcolor[HTML]{DFDEDE}{3.60} & \cellcolor[HTML]{DFDEDE}{3.13} & \cellcolor[HTML]{DFDEDE}{6.73}\\
$\upgamma_{random}$ (Figure \ref{fig:exp1_plot_time_dec}D) & 3.00 & 6.57 & 9.57 & 3.00 & 4.20 & 7.20 & \cellcolor[HTML]{DFDEDE}{3.00} & \cellcolor[HTML]{DFDEDE}{3.24} & \cellcolor[HTML]{DFDEDE}{6.24}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
measurements with a nature-of-change value of 80.
\begin{itemize}
\tightlist
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_dec}C): five measurements with a nature-of-change value of 80.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\); Figure \ref{fig:exp1_plot_time_dec}D): five measurements across all manipulated nature-of-change values and seven measurements with nature-of-change values of 80 and 180.
\end{itemize}
In summary, with time-interval decreasing spacing, unbiased estimation was obtained for all day-unit parameters across all manipulated nature-of-change values using nine or more measurements, which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-time-dec-exp1}.
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Time-Interval Decreasing Spacing}
{time-dec-spacing-nc}
{0.25}
{Figures/midpoint_80_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 280 with equal spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-time-dec-nc}).}
\end{apaFigure}
\hypertarget{precision-time-dec-exp1}{%
\subsubsection{Precision}\label{precision-time-dec-exp1}}

With respect to precision for time-interval decreasing spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_time_dec}A): five measurements with nature-of-change values of 80 and 180 an seven measurements with a nature-of-change value of 80.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_time_dec}B): all cells.
\end{itemize}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm] %distance between bottom of figure and beggining of the note 
{Bias/Precision Plots for Day-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 1} 
{exp1_plot_time_dec}
{0.16} %scaling factor 
{Figures/exp1_plot_days_time-interval decreasing} %path to figure 
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80.00, 180.00, 280.00}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-dec} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements $\in$ \{5, 7, 9, 11\}, NC = nature of change (population value set for $\upbeta_{fixed}$ $\in$ \{80, 180, 280\}), NM x NC = interaction between number of measurements and population value set for $\upbeta_{fixed}$. $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp1-time-dec}Partial $\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & NC & NM x NC\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp1_plot_time_dec}A) & 0.20 & 0.10 & 0.22\\
$\upbeta_{random}$ (Figure \ref{fig:exp1_plot_time_dec}B) & 0.13 & 0.04 & 0.05\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp1_plot_time_dec}C) & 0.27 & 0.19 & 0.21\\
$\upgamma_{random}$ (Figure \ref{fig:exp1_plot_time_dec}D) & 0.11 & 0.03 & 0.03\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{itemize}
\tightlist
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_dec}C): all cells.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\); Figure \ref{fig:exp1_plot_time_dec}D): all cells.
\end{itemize}
In summary, with time-interval increasing spacing, estimation across all manipulated nature-of-change values was only precise for the estimation of the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) with nine or more measurements. No manipulated measurement number resulted in precise estimation of the fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)) or the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-time-dec-exp1}).

\hypertarget{qualitative-time-dec-exp1}{%
\subsubsection{Qualitative Description}\label{qualitative-time-dec-exp1}}

For time-interval decreasing spacing in Figure \ref{fig:exp1_plot_time_dec}, although no manipulated measurement number resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) were obtained using moderate measurements numbers. With respect to bias under time-interval decreasing spacing, the largest improvements across all manipulated nature-of-change values in bias occurred with the following measurement numbers for the random-effect day-unit parameters:
\begin{itemize}
\tightlist
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): nine measurements
\end{itemize}
\noindent With respect to precision under time-interval decreasing spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values were obtained with the following measurement numbers:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)): seven measurements, which results in a maximum error bar length of 20.42 days.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): nine measurements, which results in a maximum error bar length of 3.4 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): nine measurements, which results in a maximum error bar length of 9.45 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): nine measurements, which results in a maximum bar length of 5.96 days.
\end{itemize}
\noindent Therefore, for time-interval decreasing spacing, nine measurements resulted in the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the emboldened text in the `Qualitative Description' column in Table \ref{tab:summary-table-time-dec-exp1}).

\hypertarget{summary-of-results-time-interval-decreasing-spacing}{%
\subsubsection{Summary of Results Time-Interval Decreasing Spacing}\label{summary-of-results-time-interval-decreasing-spacing}}

In summarizing the results for time-interval decreasing spacing, model performance was highest across all day-unit parameters when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 280 (\(\upbeta_{fixed}\) = 280; see \protect\hyperlink{nature-change-time-dec-exp1}{highest model performance}). Unbiased estimation of the day-unit parameters across all manipulated nature-of-change values resulted from using nine or more measurements (see \protect\hyperlink{bias-time-dec-exp1}{bias}). Precise estimation of all the day-unit parameters was never obtained using any of the manipulated measurement numbers (see \protect\hyperlink{precision-time-dec-exp1}{precision}). Although it may be discouraging that no manipulated measurement number under time-interval decreasing spacing resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values were obtained using nine measurements (see \protect\hyperlink{qualitative-time-inc-exp1}{qualitative description}).

\hypertarget{middle-and-extreme-spacing}{%
\subsection{Middle-and-Extreme Spacing}\label{middle-and-extreme-spacing}}

For middle-and-extreme spacing, Table \ref{tab:summary-table-mid-ext-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_mid_ext} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-mid-ext-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-mid-ext-exp1}, see \protect\hyperlink{concise-tab}{concise summary table}).

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \hyperref[nature-change-mid-ext-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with middle-and-extreme spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{2cm}>{\centering\arraybackslash}p{5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-mid-ext-exp1}Concise Summary of Results for Middle-and-Extreme Spacing in Experiment 1}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){5-6}
Parameter & Highest Model Performance & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_mid_ext}A)} & $\upbeta_{fixed}$ = 180 & All cells & NM $\ge$ 7 & Largest improvements in precision with NM = 7 & 14.10\\
\cmidrule{1-6}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp1_plot_time_mid_ext}B)} & $\upbeta_{fixed}$ = 180 & NM $\ge$ 7 & No cells & Largest improvements in bias and precision with NM = 7 & 6.27\\
\cmidrule{1-6}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp1_plot_time_mid_ext}C)} & $\upbeta_{fixed}$ = 180 & NM $\ge$ 9 & No cells & Largest improvements in bias and precision with \textbf{NM = 9} & 9.02\\
\cmidrule{1-6}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp1_plot_time_mid_ext}D)} & $\upbeta_{fixed}$ = 180 & \textbf{NM = 11} & No cells & Largest improvements in bias and precision with NM = 7 & 7.92\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\hypertarget{nature-change-mid-ext-exp1}{%
\subsubsection{Nature of Change That Leads to Highest Model Performance}\label{nature-change-mid-ext-exp1}}

For middle-and-extreme spacing, Table \ref{tab:errorbar-mid-ext-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. The `Total' column indicates the total error bar length, which is a sum of the the lower (`Lower') and upper (`Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for the remainder of the results for middle-and-extreme spacing. Although model performance was determined by bias and precision, results for bias were not reported because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated number-of-measurement values. The column shaded in gray indicates the nature of change where precision was highest (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 180 across all day-unit parameters under middle-and-extreme spacing (see the `Highest Model Performance' in Table \ref{tab:summary-table-mid-ext-exp1}). Importantly, with a nature-of-change value of 180, measurements were taken closer to periods of change under middle-and-extreme spacing than with other nature-of-change values (see Figure \ref{fig:equal-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with middle-and-extreme spacing.

\hypertarget{bias-mid-ext-exp1}{%
\subsubsection{Bias}\label{bias-mid-ext-exp1}}

With respect to bias for middle-and-extreme spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_time_dec}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_time_mid_ext}B): five measurements with nature-of-change values of 80 and 280.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_mid_ext}C): five and seven measurements with nature-of-change values of 80 and 280.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\); Figure \ref{fig:exp1_plot_time_mid_ext}D): five, seven, and nine measurements with nature-of-change values of 80 and 280.
\end{itemize}
In summary, with middle-and-extreme spacing, estimation of all the day-unit parameters across all manipulated nature-of-change values were unbiased using 11 measurements, which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-mid-ext-exp1}.
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = {80, 180, 280}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\in$ \{5, 7, 9, 11\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3.5cm}ccc>{}c>{}c>{}cccc}
\caption{\label{tab:errorbar-mid-ext-nc}Error Bar Lengths Across Nature-of-Change Values Under Middle-and-Extreme Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{9}{c}{Population Value of $\upbeta_{fixed}$} \\
\cmidrule(l{3pt}r{3pt}){2-10}
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{80} & \multicolumn{3}{c}{180} & \multicolumn{3}{c}{280} \\
\cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7} \cmidrule(l{3pt}r{3pt}){8-10}
Parameter & Lower & Upper & Total & Lower & Upper & Total & Lower & Upper & Total\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp1_plot_time_mid_ext}A) & 22.13 & 19.89 & 42.02 & \cellcolor[HTML]{DFDEDE}{2.25} & \cellcolor[HTML]{DFDEDE}{2.21} & \cellcolor[HTML]{DFDEDE}{4.46} & 20.32 & 21.74 & 42.06\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp1_plot_time_mid_ext}B) & 6.50 & 5.77 & 12.27 & \cellcolor[HTML]{DFDEDE}{0.87} & \cellcolor[HTML]{DFDEDE}{2.22} & \cellcolor[HTML]{DFDEDE}{3.09} & 6.73 & 6.11 & 12.84\\
$\upbeta_{random}$ (Figure \ref{fig:exp1_plot_time_mid_ext}C) & 7.14 & 16.84 & 23.97 & \cellcolor[HTML]{DFDEDE}{2.28} & \cellcolor[HTML]{DFDEDE}{2.48} & \cellcolor[HTML]{DFDEDE}{4.76} & 7.27 & 15.69 & 22.96\\
$\upgamma_{random}$ (Figure \ref{fig:exp1_plot_time_mid_ext}D) & 3.00 & 6.20 & 9.20 & \cellcolor[HTML]{DFDEDE}{3.00} & \cellcolor[HTML]{DFDEDE}{2.73} & \cellcolor[HTML]{DFDEDE}{5.73} & 3.00 & 6.77 & 9.77\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Middle-and-Extreme Spacing}
{equal-spacing-nc}
{0.25}
{Figures/midpoint_180_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 180 with middle-and-extreme spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-mid-ext-nc}).}
\end{apaFigure}
\hypertarget{precision-mid-ext-exp1}{%
\subsubsection{Precision}\label{precision-mid-ext-exp1}}

With respect to precision for middle-and-extreme spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp1_plot_time_mid_ext}A): five measurements with nature-of-change values of 80 and 280.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp1_plot_time_mid_ext}B): five and seven, an nine measurements with nature-of-change values of 80 and 280 (shown on x-axis).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp1_plot_time_mid_ext}C): all cells.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\); Figure \ref{fig:exp1_plot_time_mid_ext}D): all cells.
\end{itemize}
\noindent In summary, with middle-and-extreme spacing, precise estimation of the fixed-effect day-unit parameters across all manipulated nature-of-change values was obtained with 11 measurements, but no manipulated measurement number resulted in precise estimation of the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-mid-ext-exp1}).
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Middle-and-Extreme Spacing in Experiment 1}
{exp1_plot_time_mid_ext}
{0.16}
{Figures/exp1_plot_days_middle-and-extreme spacing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80.00, 180.00, 280.00}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-mid-ext} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements $\in$ \{5, 7, 9, 11\}, NC = nature of change (population value set for $\upbeta_{fixed}$ $\in$ \{80, 180, 280\}), NM x NC = interaction between number of measurements and population value set for $\upbeta_{fixed}$. $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp1-mid-ext}Partial $\upomega^2$ Values for Manipulated Variables With Middle-and-Extreme Spacing in Experiment 1}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & NC & NM x NC\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp1_plot_time_mid_ext}A) & 0.32 & 0.09 & 0.19\\
$\upbeta_{random}$ (Figure \ref{fig:exp1_plot_time_mid_ext}B) & 0.12 & 0.09 & 0.06\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp1_plot_time_mid_ext}C) & 0.49 & 0.20 & 0.32\\
$\upgamma_{random}$ (Figure \ref{fig:exp1_plot_time_mid_ext}D) & 0.07 & 0.05 & 0.03\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\hypertarget{qualitative-mid-ext-exp1}{%
\subsubsection{Qualitative Description}\label{qualitative-mid-ext-exp1}}

For middle-and-extreme spacing in Figure \ref{fig:exp1_plot_time_mid_ext}, although no manipulated measurement number resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) were obtained using moderate measurements numbers. With respect to bias under middle-and-extreme spacing, the largest improvements across all manipulated nature-of-change values in bias occurred with the following measurement numbers for the following day-unit parameters:
\begin{itemize}
\tightlist
\item
  random-effect days-to-halfway elevation parameter (\(\upgamma_{fixed}\)): seven measurements
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): nine measurements
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): 11 measurements
\end{itemize}
\noindent With respect to precision under middle-and-extreme spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values result with the following measurement numbers:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)): seven measurements, which results in a maximum error bar length of 14.1 days.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements, which results in a maximum error bar length of 5.55 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): nine measurements, which results in a maximum error bar length of 20.49 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements, which results in a maximum error bar length of 7.2 days.
\end{itemize}
\noindent Therefore, for middle-and-extreme spacing, nine measurements resulted in the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the emboldened text in the `Qualitative Description' column in Table \ref{tab:summary-table-mid-ext-exp1}).

\hypertarget{summary-of-results-with-middle-and-extreme-spacing}{%
\subsubsection{Summary of Results With Middle-and-Extreme Spacing}\label{summary-of-results-with-middle-and-extreme-spacing}}

In summarizing the results for middle-and-extreme spacing, model performance was highest across all day-unit parameters when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 180 (\(\upbeta_{fixed}\) = 180); see \protect\hyperlink{nature-change-mid-ext-exp1}{highest model performance}). Unbiased estimation of the day-unit parameters across all manipulated nature-of-change values resulted from using nine or more measurements (see \protect\hyperlink{bias-time-dec-exp1}{bias}). Precise estimation of all the day-unit parameters was never obtained using any of the manipulated measurement numbers (see \protect\hyperlink{precision-time-dec-exp1}{precision}). Although it may be discouraging that no manipulated measurement number under time-interval decreasing spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values resulted from using nine measurements (see \protect\hyperlink{qualitative-time-inc-exp1}{qualitative description}).

\hypertarget{addressing-my-research-questions}{%
\subsection{Addressing My Research Questions}\label{addressing-my-research-questions}}

\hypertarget{meas-placing}{%
\subsubsection{Does Placing Measurements Near Periods of Change Increase Model Performance?}\label{meas-placing}}

In Experiment 1, one question I had was whether placing measurements near periods of change increases model performance. To answer this question, I have recorded the nature of change values that result in the highest model performance for each spacing schedule in Table \ref{tab:summary-table-exp1-nc}. Text in the `Highest Model Performance' column indicates the

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Highest Model Performance' indicates the curve that results in the highest model performance. `Error Bar Summary' columns lists error bar lengths for each day-unit parameter such that error bar lengths are computed by taking the average error bar length value across all the number-of-measurement (NM) values (NM $\in$ \{5, 7, 9, 11\}). Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\in$ \{80, 180, 280\}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{4.86cm}>{\centering\arraybackslash}p{6cm}>{\centering\arraybackslash}p{1.5cm}>{\centering\arraybackslash}p{1.5cm}>{\centering\arraybackslash}p{1.5cm}>{\raggedright\arraybackslash}p{1.5cm}}
\caption{\label{tab:summary-table-exp1-nc}Nature-of-Change Values That Lead to the Highest Model Performance for Each Spacing Schedule in Experiment 1}\\
\toprule
\multicolumn{2}{c}{ } & \multicolumn{4}{c}{Error Bar Summary} \\
\cmidrule(l{3pt}r{3pt}){3-6}
Spacing Schedule & Highest Model Performance & $\upbeta_{fixed}$ & $\upgamma_{fixed}$ & $\upbeta_{random}$ & $\upgamma_{random}$\\
\midrule
\thead[lt]{Equal \\ 
                                                   (see Figure \ref{fig:exp1_plot_equal} and Table \ref{tab:errorbar-equal-nc})} & $\upbeta_{fixed}$ = 180 & 4.78 & 8.65 & 7.51 & 16.05\\
\cmidrule{1-6}
\thead[lt]{Time-interval increasing \\ 
                                                   (see Figure \ref{fig:exp1_plot_time_inc} and Table \ref{tab:errorbar-time-inc-nc})} & $\upbeta_{fixed}$ = 80 & 5.80 & 4.40 & 6.80 & 6.34\\
\cmidrule{1-6}
\thead[lt]{Time-interval decreasing \\ 
                                                   (see Figure \ref{fig:exp1_plot_time_dec} and Table \ref{tab:errorbar-time-dec-nc})} & $\upbeta_{fixed}$ = 280 & 5.84 & 4.48 & 6.73 & 6.24\\
\cmidrule{1-6}
\thead[lt]{Middle-and-extreme \\ 
                                                   (see Figure \ref{fig:exp1_plot_time_mid_ext} and Table \ref{tab:errorbar-mid-ext-nc})} & $\upbeta_{fixed}$ = 180 & 4.46 & 3.09 & 4.76 & 5.73\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\noindent nature-of-change with which each spacing schedule obtains its highest model performance. The `Error Bar Summary' columns list the error bar lengths obtained for each day-unit parameter using the nature-of-change value listed in the `Highest Model Performance' column.\footnote{Bias values are not presented because the differences across the schedules are negligible.} Note that the error bar lengths are obtained by computing the average error bar length across all manipulated measurement numbers for the optimal nature-of-change value. Model performance for each spacing schedule is highest with the following nature-of-change values:
\begin{itemize}
\tightlist
\item
  equal spacing: \(\upbeta_{fixed}\) = 180
\item
  time-interval increasing spacing: \(\upbeta_{fixed}\) = 80
\item
  time-interval decreasing spacing: \(\upbeta_{fixed}\) = 280
\item
  middle-and-extreme spacing: \(\upbeta_{fixed}\) = 180
\end{itemize}
To understand why the model performance of each spacing schedule is highest with a specific nature of change, it is important to consider the locations on the curve where each schedule samples data. Figure \ref{fig:midpoint_plot} shows the measurement locations (indicated by dots) where each spacing schedule samples data for each manipulated nature of change (\(\upbeta_{fixed} \in\) \{80, 180, 180\}). In Figure \ref{fig:midpoint_plot}A, data are sampled according to the equal spacing schedule. In Figure \ref{fig:midpoint_plot}B, data are sampled according to the time-interval increasing spacing schedule. In Figure \ref{fig:midpoint_plot}C, data are sampled according to the time-interval decreasing spacing schedule. In Figure \ref{fig:midpoint_plot}D, data are sampled according to the middle-and-extreme spacing schedule. Black curves indicate curves for which model performance is highest and gray curves indicating curves where model performance is not at its highest. Error bar lengths (i.e., precision) for the estimation of each day-unit parameter are copied
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Nature-of-Change Curves for Each Spacing Schedule Have Highest Model Performance When Measurements are Taken Near Periods of Change}
{midpoint_plot}
{0.16}
{Figures/midpoint_plot}
{Panel A: Measurement sampling locations on each manipulated nature-of-change curve under equal spacing. Panel B: Measurement sampling locations on each manipulated nature-of-change curve under time-interval increasing spacing. Panel C: Measurement sampling locations on each manipulated nature-of-change curve under time-interval decreasing spacing. Panel D: Measurement sampling locations on each manipulated nature-of-change curve under middle-and-extreme spacing. Black curves indicate the natures of change that lead to the highest model performance for each spacing schedule, and so are optimal. Gray curves indicate the natures of change that lead to suboptimal model performance for each spacing schedule, and so are not optimal. Text on each panel indicates the error bar lengths when model performance is highest (see Table \ref{tab:summary-table-exp1-nc}).}
\end{apaFigure}
\noindent over from Table \ref{tab:summary-table-exp1-nc} to provide a reference with which to compare model performance between the spacing schedules with the optimal nature of change.

To investigate whether placing measurements near periods of change increases model performance, it is first important to define change. For the purpose of this discussion, change occurs when the first derivative of the logistic function has a nonzero value, with a larger (absolute) first derivative value implying greater change. Figure \ref{fig:logistic_function_first_dev} shows each nature of change used in Experiment 1 (solid line) along with its corresponding first derivative curve (dotted line). For each nature of change, the first derivative value reaches its peak at the value set for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)). In Figure \ref{fig:logistic_function_first_dev}A, the first derivative is greatest at day 80. In Figure \ref{fig:logistic_function_first_dev}B, the first derivative is greatest at day 180. In Figure \ref{fig:logistic_function_first_dev}C, the first derivative is greatest at day 280. Therefore, for each manipulated nature of change, change is greatest at the value set for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)).

Revisiting the question of whether placing measurements near periods of change increases model performance, I believe there are reasons to support this idea, and each reason is depicted in Figure \ref{fig:midpoint_plot}. Figure \ref{fig:midpoint_plot} shows the measurement locations where each spacing schedules samples its measurements. Black curves indicate the curve that leads to the highest model performance for each spacing schedule and gray curves indicate the curves that lead to suboptimal model performance. In looking at the black curves (i.e., curves that lead to the highest model performance) for each spacing schedule, more measurements lie closer to the period of greatest change on the black curves than on
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Rate of Change (First Derivative Curve) for Each Nature of Change Curve Manipulated in Experiment 1}
{logistic_function_first_dev}
{0.16}
{Figures/deriv_plot}
{Panel A: Logistic curve defined by $\upbeta_{fixed}$ = 80, with first-derivative curve peaking at day 80. Panel B: Logistic curve defined by $\upbeta_{fixed}$ = 180, with first-derivative curve peaking at day 180. Panel C: Logistic curve defined by $\upbeta_{fixed}$ = 280, with first-derivative curve peaking at day 280.}
\end{apaFigure}
\noindent the respective gray curves the gray curves that result in lower model performance. One clear example can be observed for the measurement locations under middle-and-extreme spacing (see Figure \ref{fig:midpoint_plot}D). In looking across the nature-of-change curves, only the measurement locations of the middle three measurements on each curve are different. For the optimal black nature of change, the middle three measurements are centered on the period of greatest change. For the gray suboptimal nature-of-change curves, the middle three measurements are taken near regions of little change (near-zero first derivative value). Therefore, model performance is highest when spacing schedules place measurement near periods of greatest change.

Second, model performance under time-interval increasing and decreasing spacing is nearly identical because each spacing schedule samples data at the exact same regions of change. In looking at Table \ref{tab:summary-table-exp1-nc}, it is important to realize that the precision (i.e., error bar lengths) obtained with time-interval increasing and decreasing spacing are nearly identical when model performance is highest. As an example of the precision obtained when model performance is highest, the average error bar length obtained for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) is 5.80 days with time-interval increasing spacing and 5.84 days with time-interval decreasing spacing. The nearly equivalent precision obtained with time-interval increasing and decreasing spacing occurs because the rates of change (i.e., first derivative values) at the sampled locations are the exact same. As an example with five measurements, Table \ref{tab:first-deriv} lists the curve values and measurement days when the time-interval increasing and decreasing spacing schedules sample the each of five unique first-derivative values. Note that the time-interval increasing and decreasing spacing schedules sample the first-derivative values in opposite orders. In summary, although the time-interval increasing and decreasing spacing schedules sample data on different days on their respective optimal curves, they result in (nearly) identical model performance because they place measurements at the same periods of change.
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{ } 
\item  
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{4cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}}
\caption{\label{tab:first-deriv}Identical First-Derivative Sampling of Time-Interval Increasing and Decreasing Spacing Schedules}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Time-Interval Increasing} & \multicolumn{2}{c}{ Time-Interval Decreasing} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5}
First Derivative Value & Curve Value & Measurement Day & Curve Value & Measurement Day\\
\midrule
2.00e-06 & 3.00 & 0 & 3.32 & 360\\
8.80e-06 & 3.00 & 30 & 3.32 & 330\\
2.83e-04 & 3.01 & 100 & 3.31 & 260\\
2.39e-03 & 3.26 & 210 & 3.06 & 150\\
2.00e-06 & 3.32 & 360 & 3.00 & 0\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
Third, middle-and-extreme spacing obtains higher model performance than equal spacing by sampling data at periods of greater change. Importantly, both equal and middle-and-extreme spacing obtain their highest model performance with a with a nature-of-change value of 180 (\(\upbeta_{fixed}\) = 180), with middle-and-extreme spacing obtaining higher precision (i.e., shorter error bars) than equal spacing (see Figure \ref{fig:midpoint_plot} and Table \ref{tab:summary-table-exp1-nc}). An inspection of Figures \ref{fig:midpoint_plot}A and \ref{fig:midpoint_plot}D reveals that middle-and-extreme spacing samples measurements at moments of greater change. As an example, consider the measurement locations of equal and middle-and-extreme spacing with five measurements, where only second and fourth measurement locations differ between the schedules. For equal spacing, the second and fourth measurements are respectively sampled on days 90 and 270. For middle-and-extreme spacing, the second and fourth measurements are respectively taken on days 150 and 210. By consulting the first-derivative curve in Figure \ref{fig:logistic_function_first_dev}, change is greater on days 150 and 210 than on days 90 and 270. Therefore, precision across all manipulated measurement numbers is greater (i.e., shorter error bars) with middle-and-extreme spacing than with equal spacing because middle-and-extreme spacing takes measurements closer to periods of change than equal spacing (see Figures \ref{fig:midpoint_plot}A and \ref{fig:midpoint_plot}D and Table \ref{tab:summary-table-exp1-nc}).

The idea that model performance increases when data are sampled during periods of greater change has received considerable discussion and preliminary support. Over the past 20 years, researchers have recommended that measurements be sampled during periods of greater change \autocite{siegler2006,ployhart2010}, with one recent simulation study finding evidence to support this idea \autocite{timmons2015}. Unfortunately, the evidence from \textcite{timmons2015} is preliminary for two reasons. First, the model used to estimate nonlinear change only ever included one random-effect parameter. Given that multilevel models often include several random-effect parameter in practice, the model employed in \textcite{timmons2015} may not necessary be realistic. Second, the estimates were obtained by using an impractical starting value procedure: Population values were used as starting values. Because practitioners never know the population value, it is not known whether the results of \textcite{timmons2015} replicate with a realistic starting value procedure.

My simulations in Experiment 1 replicated the finding that model performance increases from measuring change near periods of change under more realistic conditions. In contrast to the one-random-effect-parameter models used in \textcite{timmons2015}, my simulations used a four-parameter model where each parameter was modelled as a fixed and random effect. For the starting value procedure, my simulations did not use the population values as starting values, but used the starting value procedure available in OpenMx, which uses an unweighted lease squares model to compute starting values.

Therefore, three results in Experiment 1 suggest that sampling data closer to periods of change leads to higher model performance. First, for each spacing schedule, model performance is highest when measurements are taken closer to periods of change. Second, the time-interval increasing and decreasing spacing schedules obtain nearly identical modelling accuracies for different curves because the sampled locations have the exact same rates of change. Third, middle-and-extreme spacing results in higher model performance than equal spacing by sampling measurements at periods of greater change. Although several researchers have posited model performance increases by sampling data closer to periods of change, with one simulation study (to my knowledege) having found support for this idea under unrealistic modelling conditions, my simulations in Experiment 1 support it under realistic modelling conditions.

\hypertarget{unknown}{%
\subsubsection{When the Nature of Change is Unknown, How Should Measurements be Spaced?}\label{unknown}}

A second question I had in Experiment 1 was how to space measurements when the nature of change is unknown. To answer this question, I first recorded the number of measurements needed to obtain the greatest improvements in model performance for each spacing schedule in Table \ref{tab:summary-table-exp1}. Text within the `Qualitative Description' column indicates the number of measurements needed to obtain the largest improvements in bias and precision across all manipulated nature-of-change values for each spacing schedule. The `Error Bar Summary' columns list the error bar lengths obtained for each day-unit parameter using the measurement number listed in the `Qualitative Description' column. Note that the error bar lengths in the `Error Bar Summary' column are obtained by computing the average length across all manipulated nature-of-change values for the measurement number listed Qualitative Description' column. For comprehensiveness, I also recorded the number of measurements needed to obtain unbiased and precise estimation of all the day-unit parameters across all manipulated nature-of-change values in the `Unbiased' and `Precise' columns.

The following number of measurements are needed to obtain unbiased estimation and the greatest improvements in bias and precision across all manipulated nature-of-change values for all day-unit parameters under each spacing schedule:
\begin{itemize}
\tightlist
\item
  equal spacing: nine or more measurements to obtain unbiased estimation and seven measurements to obtain the greatest improvements in bias and precision.
\item
  time-interval increasing spacing: nine or more measurements to obtain unbiased estimation and nine measurements to obtain the greatest improvements in bias and precision.
\item
  time-interval decreasing spacing: nine or more measurements to obtain unbiased estimation and nine measurements to obtain the greatest improvements in bias and precision.
\item
  middle-and-extreme spacing: 11 measurements to obtain unbiased estimation and nine measurements to obtain the greatest improvements in bias and precision.
\end{itemize}
\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Row shaded in gray indicates the spacing schedules that results in the highest modelling accurac across all manipulated nature-of-change curves. `Qualitative Description' column indicates the number of measurements that obtains the greatest improvements in bias and precision across all day-unit parameters and manipulated nature-of-change values. `Error Bar Summary' columns list the error bar lengths that result for each day-unit parameter using the measurement number listed in the `Qualitative Description' column. Note that error bar lengths were calculated by computing the average length across all manipulated measurement numbers for the nature-of-change value listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\in$ \{80, 180, 280\}; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{5cm}>{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{4cm}>{\raggedright\arraybackslash}p{6cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}}
\caption{\label{tab:summary-table-exp1}Concise Summary of Results Across All Spacing Schedule Levels in Experiment 1}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{4}{c}{Error Bar Summary} \\
\cmidrule(l{3pt}r{3pt}){5-8}
Spacing Schedule & Unbiased & Precise & Qualitative Description & $\upbeta_{fixed}$ & $\upgamma_{fixed}$ & $\upbeta_{random}$ & $\upgamma_{random}$\\
\midrule
\cellcolor[HTML]{DFDEDE}{\thead[lt]{Equal \\ (see Figure \ref{fig:exp1_plot_equal} and Table \ref{tab:summary-table-equal-spacing-exp1})}} & \cellcolor[HTML]{DFDEDE}{NM $\ge$ 9} & \cellcolor[HTML]{DFDEDE}{No cells} & \cellcolor[HTML]{DFDEDE}{Largest improvements in bias and precision with NM = 7} & \cellcolor[HTML]{DFDEDE}{5.64} & \cellcolor[HTML]{DFDEDE}{4.37} & \cellcolor[HTML]{DFDEDE}{7.74} & \cellcolor[HTML]{DFDEDE}{7.02}\\
\cmidrule{1-8}
\thead[lt]{Time-interval increasing \\
                                                   (see Figure \ref{fig:exp1_plot_time_inc} and Table \ref{tab:summary-table-time-inc-exp1})} & NM $\ge$ 9 & No cells & Largest improvements in bias and precision with NM = 9 & 4.97 & 3.45 & 6.31 & 5.97\\
\cmidrule{1-8}
\thead[lt]{Time-interval decreasing \\ 
                                                   (see Figure \ref{fig:exp1_plot_time_dec} and Table \ref{tab:summary-table-time-dec-exp1})} & NM $\ge$ 9 & No cells & Largest improvements in bias and precision with NM = 9 & 4.88 & 3.40 & 6.15 & 5.96\\
\cmidrule{1-8}
\thead[lt]{Middle-and-extreme \\ 
                                                   (see Figure \ref{fig:exp1_plot_time_mid_ext} and Table \ref{tab:summary-table-time-dec-exp1})} & NM = 11 & No cells & Largest improvements in bias and precision with NM = 9 & 6.51 & 5.55 & 9.02 & 7.20\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

An important point to mention is that the error bar lengths for each day-unit parameter across each spacing schedule are comparable. That is, each spacing schedule obtains similar model performance when using the number of measurements listed in the `Qualitative Description' column. Because model performance is similar across the spacing schedules, then the schedule that requires the fewest number of measurements to obtain the greatest improvements in bias and precision can be said to model change most accurately when the nature of change is unknown. With equal spacing using fewer measurements than all the other manipulated spacing schedules to obtain similar model performance---using seven measurements instead of the nine measurements use by all other spacing schedules---equal spacing is the most effective schedule to use when the nature of change is unknown.

The finding that equal spacing results in the highest model performance when the nature of change is unknown is not unexpected. Given the previous finding that model performance increases by sampling data closer to periods of change, then, if the nature of change is unknown, change may occur at any point in time, and so it is prudent to space measurements equally over time so maximize the probability of sample measurements during a period of change.

\hypertarget{summary-of-experiment-1}{%
\section{Summary of Experiment 1}\label{summary-of-experiment-1}}

I designed Experiment 1 to investigate two questions. The first question was whether placing measurements near periods of change increases model performance. For each spacing schedule, model performance was highest when measurements were sampled at periods of greater change. Therefore, when a researcher has some knowledge of the nature of change, measurements should be placed near periods of change to increase model performance.

The second question was how to space measurements when the nature of change is unknown. Although no manipulated measurement number under any spacing schedule resulted in accurate estimation of all parameters, the improvements in model performance began to diminish under each spacing schedule at a specific measurement number and plateaued at similar level of model performance. With each spacing schedule plateauing at a similar level of model performance at a specific measurement number, I concluded that the spacing schedule that used the fewest number of measurements to arrive at this plateau was most the effective schedule to use when the nature of change was unknown. With equal spacing using the fewest number of measurements to obtain the greatest improvements in model performance and reach its plateau, I concluded that equal spacing was the most effective schedule to use when the nature of change was unknown.

\hypertarget{Exp2}{%
\chapter{Experiment 2}\label{Exp2}}

In Experiment 2, I investigated the measurement number and sample size combinations needed to obtain high model performance (i.e., unbiased and precise parameter estimation) under different spacing schedules. Before presenting the results of Experiment 2, I present my design and and analysis goals. For my design goals, I conducted a 4 (spacing schedule: equal, time-interval increasing, time-interval decreasing, middle-and-extreme) x 4(number of measurements: 5, 7, 9, 11) x 6(sample size: 30, 50, 100, 200, 500, 1000) study. For my analysis goals, I was interested in determining, for each spacing schedule, the measurement number and sample size combinations needed to obtain high model performance (i.e., unbiased and precise parameter estimation). For parsimony, I present model performance across all manipulated combinations of measurement number and sample size for each spacing schedule.

\hypertarget{methods-1}{%
\section{Methods}\label{methods-1}}

\hypertarget{overview-of-data-generation}{%
\subsection{Overview of Data Generation}\label{overview-of-data-generation}}

Data generation was computed the same way as in Experiment 1 (see \protect\hyperlink{data-generation}{data generation}). Note that the code used to run the simulations and create the data set can be found in Appendix \ref{simulation-code} and the data file (\texttt{exp\_2\_data.csv}) can be found in the following GitHub repository: \url{https://github.com/sciarraseb/dissertation}.

\hypertarget{data-modelling-exp2}{%
\subsection{Modelling of Each Generated Data Set}\label{data-modelling-exp2}}

Each generated data set was modelled using the structured latent growth curve model outlined in Experiment 1 (see \protect\hyperlink{data-modelling}{data modelling} and explicated in Appendix \ref{structured-lgc}.

\hypertarget{variables-used-in-simulation-experiment-1}{%
\subsection{Variables Used in Simulation Experiment}\label{variables-used-in-simulation-experiment-1}}

\hypertarget{independent-variables-1}{%
\subsubsection{Independent Variables}\label{independent-variables-1}}

\hypertarget{spacing-of-measurements-1}{%
\paragraph{Spacing of Measurements}\label{spacing-of-measurements-1}}

For the spacing of measurements, I used the same measurement days as in Experiment 1 for equal, time-interval increasing, time-interval decreasing, and middle-and-extreme spacing (see \protect\hyperlink{spacing-measurements}{spacing of measurements} for more discussion).

\hypertarget{number-of-measurements-1}{%
\paragraph{Number of Measurements}\label{number-of-measurements-1}}

For the number of measurements, I used the same values as in Experiment 1 of 5, 7, 9, and 11 measurements (see \protect\hyperlink{number-measurements}{number of measurements}\} for more discussion).

\hypertarget{sample-size}{%
\paragraph{Sample Size}\label{sample-size}}

Sample size values were adopted from \textcite{coulombe2016} with one difference.
Because my experiments investigated the effects of measurement timing
factors on the ability to model nonlinear patterns, which are inherently
more complex than linear patterns of change, a sample size value of \emph{N}
= 1000 was added as the largest sample size. Therefore, the following
values were used for my sample size manipulation: 30, 50, 100, 200, 500,
and 1000.

\hypertarget{constants-exp2}{%
\subsubsection{Constants}\label{constants-exp2}}

Given that each simulation experiment manipulated no more than three independent variables so that results could be readily interpreted \autocite{halford2005}, other variables had to be set to constant values. In Experiment 2, two important variables were set to constant values: nature of change and time structuredness. For nature of change, I set the value for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) across all cells to 180. For time structuredness, data across all cells were generated to be time structured (i.e., all participants provide data according to one response pattern; that is, at each time point, participants provide their data at the exact same moment).

\hypertarget{dependent-variables-1}{%
\subsubsection{Dependent Variables}\label{dependent-variables-1}}

\hypertarget{convergence-success-rate}{%
\paragraph{Convergence Success Rate}\label{convergence-success-rate}}

The proportion of iterations in a cell where models converged defined
the \emph{convergence success rate}.\footnote{Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.} Equation \eqref{eq:convergence} below shows the calculation used to compute the convergence success rate:
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged in a cell}}{n},
  \label{eq:convergence} 
\end{align}
\noindent where \emph{n} represents the total number of models run in a cell.

\hypertarget{model-performance-1}{%
\paragraph{Model Performance}\label{model-performance-1}}

Model performance was the combination of two metrics: bias and precision. More specifically, two questions were of importance in the estimation of a given logistic function parameter: 1) How well was the parameter estimated on average (bias) and 2) what was a range of values that could be expected for an estimate from the output of a single model (precision). In the two sections that follow, I will discuss each metric of model performance and the cutoffs used to determine whether estimation was unbiased and precise.

\hypertarget{bias}{%
\subparagraph{Bias}\label{bias}}

Bias was calculated to evaluate the accuracy with which each logistic
function parameter was estimated in each experimental cell. As shown below in Equation
\eqref{eq:bias-2}, \emph{bias} was obtained by summing the differences
between the population value set for a parameter and the value estimated for the parameter by each \(i\) converged model and then dividing the sum by the number of \(N\) converged models.
\begin{align}
  \text{Bias} = \frac{\sum_i^N\text{(Population value for parameter} - \text{Average estimated value}_i)}{N}
  \label{eq:bias-2} 
\end{align}
\noindent Bias was calculated for the fixed- and random-effect parameters of the baseline (\(\uptheta_{fixed}\), \(\uptheta_{random}\)), maximal elevation (\(\upalpha_{fixed}\), \(\upalpha_{random}\)), days-to-halfway elevation (\(\upbeta_{fixed}\), \(\upbeta_{random}\)), and the triquarter-halfway delta parameters (\(\upgamma_{fixed}\), \(\upgamma_{random}\)) and the error parameter (\(\upepsilon\)).

\hypertarget{precision}{%
\subparagraph{Precision}\label{precision}}

In addition to computing bias, precision was calculated to evaluate the variability with which each parameter was estimated. Importantly, metrics used to evaluate precision in previous studies aoften ssume estimates are normally distributed (e.g., mean-squared error and empirical standard error). Because some parameters in my simulations had skewed distributions, using a metric that assumed a normal distribution would likely yield inaccurate results. Correspondingly, I used a distribution-independent definition of precision. In my simulations, \emph{precision} was defined as the range of values covered by the middle 95\% of values estimated for a logistic parameter.

\hypertarget{analysis-of-data-modelling-output-and-accompanying-visualizations}{%
\subsection{Analysis of Data Modelling Output and Accompanying Visualizations}\label{analysis-of-data-modelling-output-and-accompanying-visualizations}}

Analysis and visualization was conducted as outlined in Experiment 1 (see \protect\hyperlink{analysis-visualizationux5cux257D}{analysis and visualization}).

\hypertarget{results-and-discussion-1}{%
\section{Results and Discussion}\label{results-and-discussion-1}}

In the sections that follow, I organize the results by presenting them for each spacing schedule (equal, time-interval increasing, time-interval decreasing, middle-and-extreme). Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and triquarter-halfway delta parameters {[}\(\upbeta_{fixed}\), \(\upbeta_{random}\), \(\upgamma_{fixed}\), \(\upgamma_{random}\), respectively{]}). The results for the likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters {[}\(\uptheta_{fixed}\), \(\uptheta_{random}\), \(\upalpha_{fixed}\), \(\upalpha_{random}\), respectively{]}) were largely trivial and so are presented in Appendix \ref{complete-versions}.

\hypertarget{framework-for-interpreting-results-1}{%
\subsection{Framework for Interpreting Results}\label{framework-for-interpreting-results-1}}

To conduct Experiment 2, the three variables of number of measurements (4 levels), spacing of measurements (4 levels), and sample size (9 levels) were manipulated, which yielded a total of 96 cells. Importantly, within each cell, bias and precision values were also computed for each of the nine parameters estimated by the structured latent growth curve models (for a review, see \protect\hyperlink{modelling-data-sets}{modelling of each generated data set}). Thus, because the analysis of Experiment 2 computed values for many dependent variables, interpreting the results can become overwhelming. Therefore, I will provide a framework to help the reader efficiently navigate the results section.

Because I will present the results of Experiment 2 by each level of measurement spacing, the framework I will describe in Figure \ref{fig:results-plot-primer-exp2} shows a template for the bias/precision plots that I will present for each spacing schedule. The results of each spacing schedule contain a bias/precision plot for each of the nine estimated parameters. Each bias/precision plot shows the bias and precision for the estimation of one parameter across all measurement number and sample size levels. Within each bias/precision plot, dots indicate the average estimated value (which indicates bias) and error bars represent the middle 95\% range of estimated values (which indicates precision). Bias/precision plots with black borders show the results for day-unit parameters and plots with gray border show the results for Likert-unit parameters. Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and triquarter-halfway delta parameters {[}\(\upbeta_{fixed}\), \(\upbeta_{random}\), \(\upgamma_{fixed}\), \(\upgamma_{random}\), respectively{]}). The results for the Likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters {[}\(\uptheta_{fixed}\), \(\uptheta_{random}\), \(\upalpha_{fixed}\), \(\upalpha_{random}\), respectively{]}) were largely trivial and so are presented in Appendix \ref{complete-versions}. Therefore, the results of each spacing schedule will only present the bias/precision plots for four parameters (i.e., the day-unit parameters).
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Set of Bias/Precision Plots Constructed for Each Spacing Schedule in Experiment 2}
{results-plot-primer-exp2}
{.77}
{Figures/logistic_results_plot_exp2}
{A bias/precision plot is constructed for each parameter of the logistic function (see Equation \ref{eq:logFunction-generation}). Bias/precision plots with black borders show the results for day-unit parameters and plots with gray border show the results for Likert-unit parameters. For each parameter, bias and precision are shown across each combination of measurement number and sample size.}
\end{apaFigure}
\hypertarget{pre-processing-of-data-and-model-convergence-1}{%
\subsection{Pre-Processing of Data and Model Convergence}\label{pre-processing-of-data-and-model-convergence-1}}

After collecting the output from the simulations, non-converged models
(and their corresponding parameter estimates) were removed from
subsequent analyses. Table \ref{tab:conv-exp-2} in Appendix \ref{convergence-tables} provides the convergence
success rates for each cell in Experiment 2. Model convergence was almost always above 90\% and convergence rates, with rates only going below 90\% in two cells (or instances) with five measurements.

\hypertarget{concise-example}{%
\subsection{Equal Spacing}\label{concise-example}}

For equal spacing, Table \ref{tab:summary-table-equal-spacing-exp2} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp2_plot_equal} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-equal-spacing-exp2} and provide elaboration when necessary.

Before presenting the results for equal spacing, I provide a brief description of the concise summary table created for each spacing schedule and shown for equal spacing below in Table \ref{tab:summary-table-equal-spacing-exp2}. Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number/sample size pairing that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with equal spacing). The `Error Bar Length' column indicates the error bar length that resulted from using the lower-bounding measurement number/sample size pairing listed in the `Qualitative Description' column (i.e., the maximum error bar

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased estimates and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-equal-spacing-exp2}Concise Summary of Results for Equal Spacing in Experiment 2}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp2_plot_equal}A)} & All cells & All cells & Unbiased and precise estimation in all cells & 15.13\\
\cmidrule{1-5}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp2_plot_equal}B)} & All cells & \thead[lt]{NM $\ge$ 9 with $N \ge 500$} & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\boldsymbol{\ge}$ 200} or \\
                                                      \textbf{NM = 9 with \textit{N} $\boldsymbol{\le}$ 100}} & 9.79\\
\cmidrule{1-5}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp2_plot_equal}C)} & All cells & No cells & Largest improvements in precision with NM = 7 & 17.22\\
\cmidrule{1-5}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp2_plot_equal}D)} & \thead[lt]{\textbf{NM $\boldsymbol{\ge}$ 7 with \textit{N} = 1000} or \\ 
                                           \textbf{NM $\boldsymbol{\ge}$ 9 with \textit{N} $\boldsymbol{\ge}$ 200} 
                                           or \\  \textbf{NM = 11 with \textit{N} = 100}} & No cells & \thead[lt]{Largest improvements in bias and \\
                                                      precision using NM = 7 with \textit{N} $\ge$ 100 \\
                                                      or NM = 9 with \textit{N} $\le$ 50} & 10.08\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\noindent length).

\hypertarget{bias-equal-exp2}{%
\subsubsection{Bias}\label{bias-equal-exp2}}

Before presenting the results for bias, I provide a description of the set of bias/precision plots shown in Figure \ref{fig:exp2_plot_equal} and in the results sections for the other spacing schedules in Experiment 2. Figure \ref{fig:exp2_plot_equal} shows the bias/precision plots for each day-unit parameter and Table \ref{tab:omega-exp2-equal} provides the partial \(\upomega^2\) values for each independent variable of each day-unit parameter. In Figure \ref{fig:exp2_plot_equal}, blue horizontal lines indicate the population values for each parameter (with population values of \(\upbeta_{fixed}\) = 180.00, \(\upbeta_{random}\) = 10.00, \(\upgamma_{fixed}\) = 20.00, and \(\upgamma_{random}\) = 4.00). Gray bands indicate the \(\pm 10\%\) margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Panels A--B show the bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters (\(\upbeta_{fixed}\) and \(\upbeta_{random}\), respectively). Panels C--D show the bias/precision plots for the fixed- and random-effect triquarter-halfway delta parameters (\(\upgamma_{fixed}\) and \(\upgamma_{random}\), respectively). Note that random-effect parameter units are in standard deviation units.

With respect to bias for equal spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_equal}A): no cells.
\end{itemize}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Equal Spacing in Experiment 2}
{exp2_plot_equal}
{0.165}
{Figures/exp2_plot_days_equal spacing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-equal} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note .}NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size, $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp2-equal}Partial $\upomega^2$ Values for Independent Variables With Equal Spacing in Experiment 2}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp2_plot_equal}A) & 0.00 & 0.03 & 0.00\\
$\upbeta_{random}$ (Figure \ref{fig:exp2_plot_equal}B) & 0.15 & 0.28 & 0.03\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp2_plot_equal}C) & 0.31 & 0.15 & 0.09\\
$\upgamma_{random}$ (Figure \ref{fig:exp2_plot_equal}D) & 0.18 & 0.03 & 0.01\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_equal}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_equal}C): no cells.
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp2_plot_equal}D): five measurements across all sample sizes, seven measurements with \(N \le 500\), nine measurements with \(N \le 100\), and 11 measurements with \(N \le 50\).
\end{itemize}
In summary, with equal spacing, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using nine measurements with \(N \ge 200\) or 11 measurements with \(N = 100\), which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-equal-spacing-exp2}.

\hypertarget{precision-equal-exp2}{%
\subsubsection{Precision}\label{precision-equal-exp2}}

With respect to precision for equal spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_equal}A): all cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_equal}B): five and seven measurements across all sample sizes and nine and 11 measurements with \(N \le 200\).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_equal}C): all cells.
\item
  random-effect triquarter-halfway delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp2_plot_equal}D): all cells.
\end{itemize}
In summary, with equal spacing, precise estimation was obtained for the fixed-effect day-unit parameters using at least nine measurements with \(N \ge 500\), but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-equal-spacing-exp2}).

\hypertarget{qualitative-equal-exp2}{%
\subsubsection{Qualitative Description}\label{qualitative-equal-exp2}}

For equal spacing in Figure \ref{fig:exp2_plot_equal}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under equal spacing, the largest improvements resulted with the following measurement number/sample size pairings for the fixed- and random-effect triquarter-halfway delta parameters (\(\upgamma_{fixed}\) and \(\upgamma_{random}\), respectively):
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameters (\(\upgamma_{fixed}\)): seven measurements with \(N = 30\).
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): seven measurements with \(N \ge 100\) or nine measurements with \(N \le 50\).
\end{itemize}
\noindent With respect to precision under equal spacing, the largest improvements in the estimation of all day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 9.79 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements across all manipulated sample sizes, which which resulted in a error bar length of 17.22 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 100\) or nine measurements with \(N \le 50\), which resulted in a maximum error bar length of 10.08 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that the greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-equal-spacing-exp2}).

\hypertarget{summary-of-results-with-equal-spacing-1}{%
\subsubsection{Summary of Results With Equal Spacing}\label{summary-of-results-with-equal-spacing-1}}

In summarizing the results for equal spacing, estimation of all day-unit parameters was unbiased using nine measurements with \(N \ge 200\) or 11 measurements with \(N = 1000\) (see the emboldened text in in the `Unbiased' column of Table \ref{tab:summary-table-equal-spacing-exp2}). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-time-inc-exp2}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing under equal spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters resulted with moderate measurement number/sample size pairings. With equal spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-equal-spacing-exp2}).

\hypertarget{time-interval-increasing-spacing-1}{%
\subsection{Time-Interval Increasing Spacing}\label{time-interval-increasing-spacing-1}}

For time-interval increasing spacing, Table \ref{tab:summary-table-time-inc-exp2} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp2_plot_time_inc} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-inc-exp2} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-inc-exp2}, see \protect\hyperlink{concise-example}{concise summary table}).

\hypertarget{bias-time-inc-exp2}{%
\subsubsection{Bias}\label{bias-time-inc-exp2}}

With respect to bias for time-interval increasing spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_time_inc}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_time_inc}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_time_inc}C): NM = 5 with \(N = 30\).
\end{itemize}
\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased estimates and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-interval increasing spacing). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-time-inc-exp2}Concise Summary of Results for Time-Interval Increasing Spacing in Experiment 2}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp2_plot_time_inc}A)} & All cells & All cells except NM = 5 with \textit{N} $\le$ 200 & \thead[lt]{Largest improvements in precision \\
                                                      using NM = 7 across all sample sizes } & 16.77\\
\cmidrule{1-5}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp2_plot_time_inc}B)} & All cells & \thead[lt]{NM $\ge$ 7 with \textit{N} = 1000 or \\ 
                                            NM $\ge$ 9 with \textit{N} = 1000} & \thead[lt]{Largest improvements in precision \\
                                                        using \textbf{NM = 7 with} \textbf{\textit{N} $\boldsymbol{\ge}$ 200} or \\ NM = 9 with \textit{N} $\boldsymbol{\le}$ 100} & 9.69\\
\cmidrule{1-5}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp2_plot_time_inc}C)} & All cells except & No cells & \thead[lt]{Largest improvements in precision \\
                                                      using NM = 7 across all sample sizes} & 17.85\\
\cmidrule{1-5}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp2_plot_time_inc}D)} & \thead[lt]{\textbf{NM $\mathbf{\ge}$ 9 with \textit{N} $\boldsymbol{\ge}$ 200} or \\ \textbf{NM = 11 with \textit{N} = 1000}} & No cells & \thead[lt]{Largest improvements in bias and \\
                                                       precision using \textbf{NM = 5 with} 
                                                      \textbf{\textit{N} $\boldsymbol{\ge}$ 500} or \\
                                                      \textbf{NM = 9 with \textit{N} $\boldsymbol{\le}$ 200}} & 10.15\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Interval Increasing Spacing in Experiment 2}
{exp2_plot_time_inc}
{0.16}
{Figures/exp2_plot_days_time-interval increasing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-time-inc} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size, $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter. \phantom{ indicate conditions where}
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp2-time-inc}Partial $\upomega^2$ Values for Independent Variables With Time-Interval Increasing Spacing in Experiment 2}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp2_plot_time_inc}A) & 0.23 & 0.15 & 0.09\\
$\upbeta_{random}$ (Figure \ref{fig:exp2_plot_time_inc}B) & 0.15 & 0.16 & 0.02\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp2_plot_time_inc}C) & 0.17 & 0.16 & 0.07\\
$\upgamma_{random}$ (Figure \ref{fig:exp2_plot_time_inc}D) & 0.07 & 0.12 & 0.01\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp2_plot_time_inc}D): five and seven measurements across all sample sizes, nine measurements with \(N \le 100\), and 11 measurements with \(N \le 50\).
\end{itemize}
In summary, with time-interval increasing spacing, estimation of all the day-unit parameters was unbiased using nine measurements with \(N \ge 200\) or 11 measurements with \(N = 100\), which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-time-inc-exp2}.

\hypertarget{precision-time-inc-exp2}{%
\subsubsection{Precision}\label{precision-time-inc-exp2}}

With respect to precision for time-interval increasing spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_time_inc}A): five measurements with \(N \le 100\).
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_time_inc}B): five measurements across all sample sizes, seven measurements with \(N \le 500\), nine and 11 measurements with \(N \le 200\).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_time_inc}C): all cells.
\item
  random-effect triquarter-halfway delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp2_plot_time_inc}D): all cells.
\end{itemize}
In summary, with time-interval increasing spacing, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with \(N \ge 500\), but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-time-inc-exp2}).

\hypertarget{qualitative-time-inc-exp2}{%
\subsubsection{Qualitative Description}\label{qualitative-time-inc-exp2}}

For time-interval increasing spacing in Figure \ref{fig:exp2_plot_time_inc}, although no manipulated measurement number/sample size pairing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-interval increasing spacing, the largest improvements resulted with the following measurement number/sample size pairings for random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)):
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): five measurements with \(N \ge 100\) or nine measurements with \(N \le 50\).
\end{itemize}
\noindent With respect to precision under time-interval increasing spacing, the largest improvements in the estimation of each day-unit parameter resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  days-to-halfway elevation parameter (\(\upbeta_{fixed}\)): seven measurements with \(N \ge 30\), which resulted in a maximum error bar length of 9.69 days.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 9.69 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements across all manipulated sample sizes, which resulted in a maximum error bar length of 17.85 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): five measurements with \(N \ge 500\) or nine measurements with \(N \le 200\), which resulted in a maximum error bar length of 10.15 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters when using time-interval increasing spacing. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-interval increasing spacing resulted from using five measurements with \(N \ge 500\) or nine measurements with \(N \le 200\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-time-inc-exp2}).

\hypertarget{summary-of-results-with-time-interval-increasing-spacing-1}{%
\subsubsection{Summary of Results With Time-Interval Increasing Spacing}\label{summary-of-results-with-time-interval-increasing-spacing-1}}

In summarizing the results for time-interval increasing spacing, estimation of all day-unit parameters was unbiased using nine measurements with \(N \ge 200\) or 11 measurements with \(N = 100\) (see \protect\hyperlink{bias-time-inc-exp2}{bias}). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-time-inc-exp2}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing under time-interval increasing spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all the day-unit parameters were obtained with moderate measurement number/sample size pairings. With time-interval increasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using five measurements with \(N \ge 500\) or nine measurements with \(N \le 200\) (see \protect\hyperlink{qualitative-time-inc-exp2}{qualitative description}).

\hypertarget{time-interval-decreasing-spacing-1}{%
\subsection{Time-Interval Decreasing Spacing}\label{time-interval-decreasing-spacing-1}}

For time-interval decreasing spacing, Table \ref{tab:summary-table-time-dec-exp2} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp2_plot_time_dec} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-dec-exp2} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-dec-exp2}, see \protect\hyperlink{concise-example}{concise summary table}).

\hypertarget{bias-time-dec-exp2}{%
\subsubsection{Bias}\label{bias-time-dec-exp2}}

With respect to bias for time-interval decreasing spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased estimates and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-interval decreasing spacing). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-time-dec-exp2}Concise Summary of Results for Time-Interval Decreasing Spacing in Experiment 2}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp2_plot_time_dec}A)} & All cells & All cells except NM = 5 with \textit{N} $\le$ 500 & \thead[lt]{Largest improvements in precision \\
                                                      using NM = 7 across all sample sizes} & 17.42\\
\cmidrule{1-5}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp2_plot_time_dec}B)} & All cells & \thead[lt]{ NM = 7 with \textit{N} = 1000 or \\ 
                                            NM $\ge$ 9 with \textit{N} $\ge$ 500} & \thead[lt]{Largest improvements in precision \\
                                                        using \textbf{NM = 7 with} \textbf{\textit{N} $\boldsymbol{\ge}$ 200} or \\ NM = 9 with \textit{N} $\boldsymbol{\le}$ 100} & 9.62\\
\cmidrule{1-5}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp2_plot_time_dec}C)} & All cells except NM = 5 with \textit{N} = 50 & No cells & \thead[lt]{Largest improvements in precision \\
                                                      using NM = 7 across all sample sizes} & 17.44\\
\cmidrule{1-5}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp2_plot_time_dec}D)} & \thead[lt]{\textbf{NM = 11 with \textit{N} $\boldsymbol{\ge}$ 100}} & No cells & \thead[lt]{Largest improvements in bias and \\
                                                       precision using \textbf{NM = 5 with} 
                                                      \textbf{\textit{N} $\boldsymbol{\ge}$ 500} \\
                                                      or \textbf{NM = 9 with \textit{N} $\boldsymbol{\le}$ 200}} & 10.32\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 2}
{exp2_plot_time_dec}
{0.16}
{Figures/exp2_plot_days_time-interval decreasing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-time-dec} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size, $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter. \phantom{ indicate conditions where}
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp2-time-dec}Partial $\upomega^2$ Values for Independent Variables With Time-Interval Decreasing Spacing in Experiment 2}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp2_plot_time_dec}A) & 0.05 & 0.03 & 0.01\\
$\upbeta_{random}$ (Figure \ref{fig:exp2_plot_time_dec}B) & 0.14 & 0.12 & 0.01\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp2_plot_time_dec}C) & 0.07 & 0.04 & 0.01\\
$\upgamma_{random}$ (Figure \ref{fig:exp2_plot_time_dec}D) & 0.05 & 0.09 & 0.00\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_time_dec}C): NM = 5 with \(N = 30\).
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp2_plot_time_dec}D): five, seven, and nine measurements across all sample sizes an 11 measurements with \(N \le 50\), and 11 measurements with \(N \le 50\).
\end{itemize}
In summary, with time-interval decreasing spacing, estimation of all the day-unit parameters was unbiased using 11 measurements with \(N \ge 100\), which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-time-dec-exp2}.

\hypertarget{precision-time-dec-exp2}{%
\subsubsection{Precision}\label{precision-time-dec-exp2}}

With respect to precision for time-interval decreasing spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}A): five measurements with \(N \le 500\).
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}B): five measurements across all sample sizes, seven measurements with \(N \le 500\), and nine and 11 measurements with \(N \le 200\).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_time_dec}C): all cells.
\item
  random-effect triquarter-halfway delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp2_plot_time_dec}D): all cells.
\end{itemize}
In summary, with time-interval decreasing spacing, precise estimation for the fixed-effect day-unit parameters resulted from using at least seven measurements with \(N = 1000\) or nine measurements \(N \le 500\). For the random-effect day-unit parameters, no manipulated measurement number/sample size pairing resulted in precise estimation (see the `Precise' column of Table \ref{tab:summary-table-time-dec-exp2}).

\hypertarget{qualitative-time-dec-exp2}{%
\subsubsection{Qualitative Description}\label{qualitative-time-dec-exp2}}

For time-interval decreasing spacing in Figure \ref{fig:exp2_plot_time_dec}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-interval decreasing spacing, the largest improvements resulted with the following measurement number/sample size pairings for the random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)):
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway delta parameters (\(\upgamma_{random}\)): five measurements with \(N \ge 100\) or nine measurements with \(N \le 50\).
\end{itemize}
\noindent With respect to precision under time-interval decreasing spacing, the largest improvements in the estimation of all day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  days-to-halfway elevation parameter (\(\upbeta_{fixed}\)): seven measurements with \(N \ge 30\), which resulted in a maximum error bar length of 9.62 days.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 9.62 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements across all manipulated sample sizes, which which resulted in a error bar length of 17.44 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): five measurements with \(N \ge 500\) or nine measurements with \(N \le 200\), which resulted in a maximum error bar length of 10.32 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-interval decreasing spacing. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that greatest improvements in bias and precision in the estimation of all day-unit parameters with time-interval decreasing spacing resulted with five measurements with \(N \ge 500\), seven measurements with \(N \ge 200\), or nine measurements with \(N \le 200\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-time-dec-exp2}).

\hypertarget{summary-of-results-time-interval-decreasing-spacing-1}{%
\subsubsection{Summary of Results Time-Interval Decreasing Spacing}\label{summary-of-results-time-interval-decreasing-spacing-1}}

In summarizing the results for time-interval decreasing spacing, estimation of all day-unit parameters was unbiased using 11 measurements with \(N \ge 10\) (see \protect\hyperlink{bias-time-dec-exp2}{bias}). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-time-inc-exp2}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing under time-interval decreasing spacing resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement number/sample size pairings. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using five measurements with \(N \ge 500\) or nine measurements with \(N \le 200\) (see \protect\hyperlink{qualitative-time-inc-exp2}{qualitative description}).

\hypertarget{middle-and-extreme-spacing-1}{%
\subsection{Middle-and-Extreme Spacing}\label{middle-and-extreme-spacing-1}}

For middle-and-extreme spacing, Table \ref{tab:summary-table-mid-ext-exp2} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp2_plot_mid_ext} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-mid-ext-exp2} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-mid-ext-exp2}, see \protect\hyperlink{concise-example}{concise summary table}).

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased estimates and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with middle-and-extreme spacing). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\centering\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-mid-ext-exp2}Concise Summary of Results for Middle-and-Extreme Spacing in Experiment 2}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp2_plot_mid_ext}A)} & All cells & All cells & Largest improvements in precision using
                                                      using \textbf{NM = 5} & 14.96\\
\cmidrule{1-5}
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp2_plot_mid_ext}B)} & All cells & All number of measurements with \textit{N} $\ge$ 500 & Largest improvements in precision using
                                                      \textbf{NM = 5} & 9.92\\
\cmidrule{1-5}
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp2_plot_mid_ext}C)} & All cells & No cells & Largest improvements in precision using
                                                      \textbf{NM = 5} & 15.94\\
\cmidrule{1-5}
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp2_plot_mid_ext}D)} & \thead[lt]{\textbf{NM $\boldsymbol{\in}$ \{5, 9\} with
                                           \textit{N} $\boldsymbol{\ge}$ 100} or \\
                                           \textbf{NM  $\boldsymbol{\in}$ \{7, 11\} with \textit{N} $\boldsymbol{\le}$ 50}} & No cells & Largest improvements in precision using
                                                      \textbf{NM = 5} & 10.13\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\hypertarget{bias-mid-ext-exp2}{%
\subsubsection{Bias}\label{bias-mid-ext-exp2}}

With respect to bias for middle-and-extreme spacing, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_time_dec}C): no cells.
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp2_plot_time_dec}D): five and nine measurements with \(N \le 100\) and seven an 11 with \(N \le 50\).
\end{itemize}
In summary, with middle-and-extreme spacing, estimation of all the day-unit parameters was unbiased using five and nine measurements with \(N \le 100\) and seven an 11 with \(N \le 50\), which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-mid-ext-exp2}.

\hypertarget{precision-mid-ext-exp2}{%
\subsubsection{Precision}\label{precision-mid-ext-exp2}}

With respect to precision for middle-and-extreme spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}A): no cells.
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp2_plot_time_dec}B): all measurements numbers with \(N \ge 200\).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp2_plot_time_dec}C): all cells.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\); Figure \ref{fig:exp2_plot_time_dec}D): all cells.
\end{itemize}
In summary, with middle-and-extreme spacing, precise estimation for the fixed-effect day-unit parameters resulted from using at least five measurements with \(N \ge 500\).
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Middle-and-Extreme Spacing in Experiment 2}
{exp2_plot_mid_ext}
{0.16}
{Figures/exp2_plot_days_middle-and-extreme spacing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-mid-ext} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size, $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter. \phantom{ indicate conditions where}
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp2-mid-ext}Partial $\upomega^2$ Values for Independent Variables With Middle-and-Extreme Spacing in Experiment 2}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp2_plot_mid_ext}A) & 0.05 & 0.03 & 0.01\\
$\upbeta_{random}$ (Figure \ref{fig:exp2_plot_mid_ext}B) & 0.14 & 0.12 & 0.01\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp2_plot_mid_ext}C) & 0.07 & 0.04 & 0.01\\
$\upgamma_{random}$ (Figure \ref{fig:exp2_plot_mid_ext}D) & 0.05 & 0.09 & 0.00\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\noindent For the random-effect day-unit parameters, no manipulated measurement number/sample size pairing resulted in precise estimation (see the `Precise' column of Table \ref{tab:summary-table-mid-ext-exp2}).

\hypertarget{qualitative-mid-ext-exp2}{%
\subsubsection{Qualitative Description}\label{qualitative-mid-ext-exp2}}

For middle-and-extreme spacing in Figure \ref{fig:exp2_plot_mid_ext}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under middle-and-extreme spacing, it was negligible under all manipulated measurement number/sample size pairings, and so there was little value in listing the pairings that resulted in the greatest improvements. With respect to precision under middle-and-extreme spacing, the largest improvements in the estimation of all day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): five measurements across all sample sizes, which resulted in a maximum error bar length of 9.92 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): five measurements across all sample sizes, which resulted in a maximum error bar length of 15.94 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): five measurements across all sample sizes, which resulted in a maximum error bar length of 10.13 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with middle-and-extreme spacing. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that greatest improvements in bias and precision in the estimation of all day-unit parameters with middle-and-extreme spacing resulted from using five measurments with any sample size (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-mid-ext-exp2}).

\hypertarget{summary-of-results-with-middle-and-extreme-spacing-1}{%
\subsubsection{Summary of Results with Middle-and-Extreme Spacing}\label{summary-of-results-with-middle-and-extreme-spacing-1}}

In summarizing the results for middle-and-extreme spacing, estimation of all day-unit parameters was unbiased using five or nine measurements with \(N \le 100\) and seven or 11 with \(N \le 50\) (see \protect\hyperlink{bias-mid-ext-exp2}{bias}). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-mid-ext-exp2}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing under time-interval decreasing spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters resulted with moderate measurement number/sample size pairings. With middle-and-extreme spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using five measurements with any sample size (see \protect\hyperlink{qualitative-mid-ext-exp2}{qualitative description}).

\hypertarget{what-measurement-numbersample-size-pairings-should-be-used-with-each-spacing-schedule}{%
\section{What Measurement Number/Sample Size Pairings Should be Used With Each Spacing Schedule?}\label{what-measurement-numbersample-size-pairings-should-be-used-with-each-spacing-schedule}}

In Experiment 2, I was interested in determining the measurement number/sample size pairings that resulted in high model performance (unbiased and precise parameter estimation) for each spacing schedule. Table \ref{tab:summary-table-exp2} summarizes the results for each spacing schedule in Experiment 2. Text within the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairing needed to, respectively, obtain unbiased an precise estimation of all the day-unit parameters. The `Error Bar Length' column indicates maximum error bar length that results in the estimation of each day-unit parameter from using the measurement number/sample size pairings listed in the `Qualitative Description' column. Although no measurement number/sample size pairing results in high model performance for any spacing schedule, the greatest improvements in model performance result from using the following measurement number/sample size pairings for each spacing schedule (see Table \ref{tab:summary-table-exp2}):
\begin{itemize}
\tightlist
\item
  equal: seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 100.
\end{itemize}
\newgeometry{margin=2.47cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Qualitative Description' column indicates the number of measurements that result in the greatest improvements in bias and precision across all day-unit parameters. `Error Bar Summary' columns list the longest error bar lengths that result for each day-unit parameter using the measurement number/sample size pairing listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. \textit{N} = sample size, NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{5.5cm}>{\raggedright\arraybackslash}p{4.5cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{5.5cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}}
\caption{\label{tab:summary-table-exp2}Concise Summary of Results Across All Spacing Schedule Levels in Experiment 2}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{4}{c}{Error Bar Summary} \\
\cmidrule(l{3pt}r{3pt}){5-8}
Spacing Schedule & Unbiased & Precise & Qualitative Description & $\upbeta_{fixed}$ & $\upgamma_{fixed}$ & $\upbeta_{random}$ & $\upgamma_{random}$\\
\midrule
\thead[lt]{Equal \\(see Figure \ref{fig:exp2_plot_equal} and 
                                                   Table \ref{tab:summary-table-equal-spacing-exp2})} & \thead[lt]{NM $\ge$ 7 with \textit{N} = 1000 or \\
                                           NM $\ge$ 9 with \textit{N} $\ge$ 100} & No cells & Largest improvements in bias and
                                                      precision using NM = 7 with \textit{N} $\ge$ 200 or
                                                      NM = 9 with \textit{N} $\le$ 100 & 12.67 & 9.79 & 16.02 & 10.08\\
\cmidrule{1-8}
\thead[lt]{Time-interval increasing  \\ 
                                                   (see Figure \ref{fig:exp2_plot_time_inc} and 
                                                   Table \ref{tab:summary-table-time-inc-exp2})} & \thead[lt]{NM $\ge$ 9 with \textit{N} $\ge$ 200 or \\
                                           NM = 11 with \textit{N} = 1000} & No cells & Largest improvements in bias and
                                                      precision using NM = 7 with \textit{N} $\ge$ 200 or
                                                      NM = 9 with \textit{N} $\le$ 100 & 13.27 & 9.69 & 16.28 & 10.15\\
\cmidrule{1-8}
\thead[lt]{Time-interval decreasing \\ 
                                                   (see Figure \ref{fig:exp2_plot_time_dec} and 
                                                   Table \ref{tab:summary-table-time-dec-exp2})} & \thead[lt]{NM = 11 with \textit{N} $\ge$ 1000} & No cells & Largest improvements in bias and
                                                      precision using NM = 7 with \textit{N} $\ge$ 200 or
                                                      NM = 9 with \textit{N} $\le$ 100 & 13.41 & 9.62 & 16.16 & 10.32\\
\cmidrule{1-8}
\thead[lt]{Middle and extreme \\ 
                                                   (see Figure \ref{fig:exp2_plot_mid_ext} and 
                                                   Table \ref{tab:summary-table-mid-ext-exp2})} & \thead[lt]{\textbf{NM $\boldsymbol{\ge}$ 5 with
                                           \textit{N} $\boldsymbol{\ge}$ 200} or \\
                                           \textbf{NM  $\boldsymbol{\in}$ \{5, 7\} with \textit{N} = 100}} & No cells & Largest improvements in bias and precision with NM = 5 & 14.96 & 9.92 & 15.94 & 10.13\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry
\begin{itemize}
\tightlist
\item
  time-interval increasing: five measurements with \emph{N} \(\ge\) 500, seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 200.
\item
  time-interval decreasing: five measurements with \emph{N} \(\ge\) 500, seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 200.
\item
  middle-and-extreme: five measurements with any manipulated sample size.
\end{itemize}
\noindent Because each spacing schedule obtains comparable model performance as indicated by the similar error bar lengths, two statements can be made. First, using either seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 100 with any spacing schedule except middle-and-extreme spacing results in similar model performance. Second, given that only five measurements are needed with middle-and-extreme spacing to obtain model performance levels that the other spacing schedules obtained with at least seven measurements, middle-and-extreme spacing results in the highest model performance. Importantly, given that middle-and-extreme spacing results in the highest model performance in Experiment 1 with a midway halfway point (see section discussing \protect\hyperlink{meas-placing}{measurement spacing}), the result here that middle-and-extreme spacing leads to the highest model performance is an expected outcome because the nature-of-change was fixed to 180 (see \protect\hyperlink{constants-exp2}{constants}).

The results of Experiment 2 are the first (to my knowledge) to provide measurement number and sample size guidelines for researchers interested in using nonlinear functions to model nonlinear change. Although previous simulation studies have investigated how to accurately model nonlinear change, three characteristics limit these results. First, some studies investigated the issue with fixed-effects models \autocite[e.g.,][]{finch2017}. Given that researchers often model effects as random, findings with fixed-effects effects models are limited in their application. Second, some studies used linear functions to model nonlinear change \autocites[e.g.,][]{fine2019,liu2022}. Given that the parameters of linear functions become uninterpretable when modelling nonlinear change (with the intercept parameter being an exception), these models are less useful to practitioners. Third, some studies implemented unrealistic model fitting procedures by dropping a random-effect parameter from the model each time convergence failed \autocite{finch2017}. By dropping random-effect parameters when model convergence failed, estimation accuracy could not meaningfully evaluated for parameters because values could have been obtained with reduced or simplified models.

In summary, the results of Experiment 2 provide measurement number/sample size guidelines for researchers interested in modelling nonlinear change. Importantly, because no measurement number-sample pairing results in unbiased and precise estimation of all the day-unit parameters, the guidelines provided by this study are only suggestions to obtain the greatest improvements in model performance. Although researchers are encouraged to use larger measurement numbers and sample sizes than suggested in the current guidelines, the improvements in model performance are likely to be incommensurate with the efforts needed to increase measurement number and sample size.

\hypertarget{summary-of-experiment-2}{%
\section{Summary of Experiment 2}\label{summary-of-experiment-2}}

I designed Experiment 2 to investigate the measurement number and sample size combinations needed to obtain high model performance (i.e., unbiased and precise parameter estimation) under different spacing schedules. Although no measurement number/sample size pairing result in high model performance under any spacing schedule, the greatest improvements in model performance result from using modest measurement number/sample size pairings. Specifically, the greatest improvements in model performance can be obtained using either seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 100.

\hypertarget{Exp3}{%
\chapter{Experiment 3}\label{Exp3}}

In Experiment 3, I was interested in examining how time structuredness affected model performance. Before presenting the results of Experiment 3, I present my design and analysis goals. For my design goals, I conducted a 3 (time structuredness: time-structured data, time-unstructured data resulting from a fast response rate, time-unstructured data resulting from a slow response rate) x 4 (number of measurements: 5, 7, 9, 11) x 6 (sample size: 30, 50, 100, 200, 500, 1000) study. For my analysis goals, I examined whether the number of measurements and sample sizes needed to obtain high model performance (i.e., low bias, high precision) increased as time structuredness decreased.

\hypertarget{methods-2}{%
\section{Methods}\label{methods-2}}

\hypertarget{variables-used-in-simulation-experiment-2}{%
\subsection{Variables Used in Simulation Experiment}\label{variables-used-in-simulation-experiment-2}}

\hypertarget{independent-variables-2}{%
\subsubsection{Independent Variables}\label{independent-variables-2}}

\hypertarget{number-of-measurements-2}{%
\paragraph{Number of Measurements}\label{number-of-measurements-2}}

For the number of measurements, I used the same values as in Experiment 1 of 5, 7, 9, and 11 measurements (see \protect\hyperlink{number-measurements}{number of measurements} for more discussion).

\hypertarget{sample-size-1}{%
\paragraph{Sample Size}\label{sample-size-1}}

For sample size, I used the same values as in Experiment 2 of 30, 50, 100, 200, 500, and 1000 (see \protect\hyperlink{sample-size}{sample size} for more discussion).

\hypertarget{time-structuredness-1}{%
\paragraph{Time Structuredness}\label{time-structuredness-1}}

\emph{Time structuredness} describes the extent to which participants provide data over time with the same response pattern. That is, at each time point, do participants provide their data at the exact same time point. If one response pattern characterizes the way in which participants provide their data, then participants always provide data at the exact same moment, and the resulting data are \emph{time structured}. If response patterns differ between participants, the resulting data lose their time structuredness and become \emph{time unstructured}, with the extent of the time unstructuredness depending on the extent to which response patterns differ between participants. The manipulation of time structuredness was adopted from the manipulation used in \textcite{coulombe2016} with a slight modification. Below, I describe the original procedure used in \textcite{coulombe2016} and, following this explanation, I describe my improved procedure.

In \textcite{coulombe2016}, time-unstructured data were generated according to an exponential pattern such that most data were obtained at the beginning of the response window, with a smaller amount of data being obtained towards the end of the response window. Importantly, \textcite{coulombe2016} employed a non-continuous function for generating time-unstructured data: A binning method was employed such that 80\% of the data were obtained within a time period equivalent to 12\% (fast response rate) or 30\% (slow response rate) of the entire response window. Using a response window length of 10 days with a fast response rate, the procedure employed by \textcite{coulombe2016} for generating time-unstructured data would have generated the following percentages of data in each of the four bins (note that, using the data generation procedure for \textcite{coulombe2016}, the effective response window length for a fast response rate would be 4 days in the current example instead of 10 days):\footnote{The data generation procedure in \textcite{coulombe2016} for a fast response rate assumed that all of the data were collected within the initial 40\% length of the nominal response window length (i.e., 4 days in the current example).}
\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Bin 1: 60\% of the data would be generated in the initial 10\% length of the response window (0--0.40 day).
\item
  Bin 2: 20\% of the data would be generated in the next 20\% length of the response response window (0.40--1.20 days).
\item
  Bin 3: 10\% of the data would be generated in the next 30\% length of the response window (1.20--2.40 days).
\item
  Bin 4: the remaining 10\% of the data would be generated in the remaining 40\% length of the response window (2.40--4.00 days).
\end{enumerate}
\noindent Note that, summing the data percentages and time durations from the first two bins yields an 80\% cumulative response rate that is obtained in the initial 12\% length of the full-length response window of 10 days (i.e., \((\frac{1.2}{10})100\% = 12\%\)). Also note that, in \textcite{coulombe2016}, a data point in each bin was randomly assigned a measurement time within the bin's time range. In the current example where the full-length response window had a length of 10 days, a data point obtained in the first bin would be randomly assigned a measurement time between 0--0.40. Although \textcite{coulombe2016} generated time-unstructured data to resemble data collection conditions---response rates have been shown to follow an exponential pattern \autocite{dillman2014,pan2010}---the use of a pseudo-continuous binning function for generating time-unstructured data lacked ecological validity because response patterns are more likely to follow a continuous function.

To improve on the time structuredness manipulation of \textcite{coulombe2016}, I developed a more ecologically valid manipulation by using a continuous function. Specifically, I used the exponential function shown below in Equation \ref{eq:exp-function} to generate time-unstructured data:
\begin{align}
y = M(1 - e^{-ax}),
\label{eq:exp-function} 
\end{align}
\noindent where \(x\) stores the time delay for a measurement at a particular time point, \(y\) represents the cumulative response percentage achieved at a given \(x\) time delay, \(a\) sets the rate of growth of the cumulative response percentage over time, and \(M\) sets the range of possible \(y\) values. Two important points need to be made with respect to the \(M\) parameter (range of possible \(y\) values) and the response window length used in the current simulations. First, because the range of possible values for the cumulative response percentage (\(y\)) is 0--1 (data can be collected from a 0\% to a maximum of 100\% of respondents; \(\{y : 0 \le y \le 1\}\)), the M parameter had a value of 1 (M = 1). Second, the response window length in the current simulations was 36 days, and so the range of possible time delay values was between 0--36 (\(\{x:0\le x \le36\}\)).\footnote{A value of 36 days was used because the generation of time-unstructured data had to remain independent of the manipulation of measurement number (i.e., the response window lengths used in generating time-unstructured data could not vary with the number of measurements). To ensure the manipulations of measurement number and time structuredness remained independent, the response window length had to remain constant for all measurement number conditions with equal spacing. Looking at Table \ref{tab:measurementDays}, the longest possible response window that fit within all measurement number conditions with equal spacing was the interval length of the 11-measurement condition (i.e., 36 days).}

To replicate the time structuredness manipulation in \textcite{coulombe2016} using the continuous exponential function of Equation \ref{eq:exp-function}, the growth rate parameter (\(a\)) had to be calibrated to achieve a cumulative response rate of 80\% after either 12\% or 30\% of the response window length of 36 days. The derivation below solves for \(a\), with Equation \ref{eq:growth-rate} showing the equation for computing \(a\).
\begin{align}
y  &= M(1 - e^{-ax}) \nonumber \\
y &= M - Me^{-ax} \nonumber \\
y &= 1 -e^{-ax} \nonumber \\
e^{-ax} &= 1-y \nonumber \\
-ax\log(e) &= \log(1 - y) \nonumber \\
a &= \frac{\log(1 - y)}{-x}
\label{eq:growth-rate}
\end{align}
\noindent Because the target response rate was 80\%, \(y\) took on a value of .80 (\(y = .80\)). Given that the response window length in the current simulations was 36 days, \(x\) took on a value of 4.32 (12\% of 36) when time-unstructured data were defined by a fast response rate and 10.80 (30\% of 36) when time-unstructured data were defined by a slow response rate. Using Equation \ref{eq:growth-rate} yielded the following growth rate parameter values for fast and slow response rates (\(a_{fast}\), \(a_{slow}\)):
\begin{align}
a_{fast} &= \frac{\log(1 - .80)}{-4.32} = 0.37 \nonumber \\
a_{slow} &= \frac{\log(1 - .80)}{-10.80} = 0.15 \nonumber
\end{align}
\noindent Therefore, to obtain 80\% of the data with a fast response rate (i.e., in 4.32 days), the growth parameter (\(a\)) needed to have a value of 0.37 (\(a_{fast}\) = 0.37) and, to obtain 80\% of the data with a slow response rate (i.e., in 10.80 days), the growth parameter (\(a\)) needed to have a value of 0.15 (\(a_{slow}\) = 0.15). Using the above growth rate values derived for the fast and slow response growth rate parameters (\(a_{fast}\), \(a_{slow}\)), the following functions were generated for fast and slow response rates:
\begin{align}
f_{fast}(x) = M(1 - e^{a_{fast}x}) = M(1 - e^{-0.37x}) \text{ and} \label{eq:cdf-fast}\\
f_{slow}(x) = M(1 - e^{a_{slow}x}) = M(1 - e^{-0.15x}).\label{eq:cdf-slow}
\end{align}
\noindent Using Equations \ref{eq:cdf-fast}--\ref{eq:cdf-slow}, Figure \ref{fig:cdf-plots} shows the resulting cumulative distribution functions (CDF) for time-unstructured data that show the cumulative response percentages as a function of time. Figure \ref{fig:cdf-plots}A shows the cumulative distribution function for a fast response rate (Equation \ref{eq:cdf-fast}), where an 80\% response rate was obtained in 4.32 days. Figure \ref{fig:cdf-plots}B shows the cumulative distribution function for a slow response rate (Equation \ref{eq:cdf-slow}), where an 80\% response rate was obtained in 10.80 days.
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Cumulative Distribution Functions (CDF) With Fast and Slow Response Rates}
{cdf-plots}
{.20}
{Figures/cdf_plot}
{Panel A: Cumulative distribution function for a fast response rate (Equation \ref{eq:cdf-fast}), where an 80\% response rate is obtained in 4.32 days. Panel B: Cumulative distribution function for a slow response rate (Equation \ref{eq:cdf-slow}), where an 80\% response rate is obtained in 10.80 days.}
\end{apaFigure}
\hypertarget{constants-1}{%
\subsubsection{Constants}\label{constants-1}}

Given that each simulation experiment manipulated no more than three independent variables so that results could be readily interpreted \autocite{halford2005}, other variables had to be set to constant values. In Experiment 3, two important variables were set to constant values: nature of change and measurement spacing. For nature of change, I set the value for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) across all cells to have a value of 180. For measurement spacing, I set the value across all cells to have equal spacing.

\hypertarget{dependent-variables-2}{%
\subsubsection{Dependent Variables}\label{dependent-variables-2}}

\hypertarget{convergence-success-rate-1}{%
\paragraph{Convergence Success Rate}\label{convergence-success-rate-1}}

The proportion of iterations in a cell where models converged defined
the \emph{convergence success rate}.\footnote{Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.} Equation \eqref{eq:convergence} below shows the calculation used to compute the convergence success rate:
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged in a cell}}{n},
  \label{eq:convergence} 
\end{align}
\noindent where \emph{n} represents the total number of models run in a cell.

\hypertarget{model-performance-2}{%
\paragraph{Model Performance}\label{model-performance-2}}

Model performance was the combination of two metrics: bias and precision. More specifically, two questions were of importance in the estimation of a given logistic function parameter: 1) How well was the parameter estimated on average (bias) and 2) what was a range of values that could be expected for an estimate from the output of a single model (precision). In the two sections that follow, I will discuss each metric of model performance and the cutoffs used to determine whether estimation was unbiased and precise.

\hypertarget{bias-1}{%
\subparagraph{Bias}\label{bias-1}}

Bias was calculated to evaluate the accuracy with which each logistic
function parameter was estimated in each experimental cell. As shown below in Equation
\eqref{eq:bias-3}, \emph{bias} was obtained by summing the differences
between the population value set for a parameter and the value estimated for the parameter by each \(i\) converged model and then dividing the sum by the number of \(N\) converged models.
\begin{align}
  \text{Bias} = \frac{\sum_i^N\text{(Population value for parameter} - \text{Average estimated value}_i)}{N}
  \label{eq:bias-3} 
\end{align}
\noindent Bias was calculated for the fixed- and random-effect parameters of the baseline (\(\uptheta_{fixed}\), \(\uptheta_{random}\)), maximal elevation (\(\upalpha_{fixed}\), \(\upalpha_{random}\)), days-to-halfway elevation (\(\upbeta_{fixed}\), \(\upbeta_{random}\)), and the halfway-triquarter delta parameters (\(\upgamma_{fixed}\), \(\upgamma_{random}\)) and the error parameter (\(\upepsilon\)).

\hypertarget{precision-1}{%
\subparagraph{Precision}\label{precision-1}}

In addition to computing bias, precision was calculated to evaluate the variability with which each parameter was estimated. Importantly, metrics used to evaluate precision in previous studies assume estimates are normally distributed (e.g., mean-squared error and empirical standard error). Because some parameters in my simulations had skewed distributions, using a metric that assumed a normal distribution would likely yield inaccurate results. Correspondingly, I used a distribution-independent definition of precision. In my simulations, \emph{precision} was defined as the range of values covered by the middle 95\% of values estimated for a logistic parameter.

\hypertarget{overview-of-data-generation-1}{%
\subsection{Overview of Data Generation}\label{overview-of-data-generation-1}}

Data generation was computed the same way as in Experiment 1 (see \protect\hyperlink{data-generation}{data generation}) with one addition to the procedure needed for time structuredness. The section that follows details how time structuredness was simulated. Note that the code used to run the simulations and create the data set can be found in Appendix \ref{simulation-code} and the data file (\texttt{exp\_3\_data.csv}) can be found in the following GitHub repository: \url{https://github.com/sciarraseb/dissertation}.

\hypertarget{simulating-time-struc}{%
\paragraph{Simulation Procedure for Time Structuredness}\label{simulating-time-struc}}

To simulate time-unstructured data, response rates at each collection
point followed an exponential pattern described by either a fast or slow
response rate (for a review, see \protect\hyperlink{time-structuredness}{time structuredness}). Importantly, data generated
for each person at each time point had to be sampled according to a
probability density function defined by either the fast or slow response
rate cumulative distribution function (respectively, see Equations \ref{eq:cdf-fast}--\{eq:cdf-slow\}). In the current context, a
\emph{probability density function} describes the probability of sampling
any given time delay value \(x\) where the range of time delay values is
0--36 (\(\{x : 0 \le x \le 36 \}\)). To obtain the probability density functions
for fast and slow response rates, the response rate function shown in
Equation \eqref{eq:exp-function} was differentiated with respect to \(x\) to
obtain the function shown below in Equation \ref{eq:pdf-function}:\footnote{Euler's notation for differentiation is used to represent derivatives. In words, $\frac{\partial f(x)}{\partial x}$ means that the derivative of the function $f(x)$ is taken with respect to $x$.}
\begin{align}
f^\prime = \frac{\partial f(x)}{\partial x} &= \frac{\partial}{\partial x}M(1 - e^{-ax}). \nonumber \\
&= M (e^{-ax}a)
\label{eq:pdf-function}
\end {align}

\noindent To compute the probability density function for the fast
response rate cumulative distribution function, the growth rate
parameter \(a\) was set to 0.37 in Equation \ref{eq:pdf-function} to
obtain the following function in Equation \ref{eq:fast-pdf-function}:
\begin{align}
f^\prime_{fast}(x) = M (e^{-a_{fast}x}a_{fast}) = M (e^{-0.37x}0.37). 
\label{eq:fast-pdf-function}
\end {align}

\noindent To compute the probability density function for the slow
response rate cumulative distribution function, the growth rate
parameter \(a\) was set to 0.15 in Equation \ref{eq:pdf-function} to
obtain the following function in Equation \ref{eq:slow-pdf-function}:
\begin{align}
f^\prime_{slow}(x) = M (e^{-0.15}a_{slow}) = M (e^{-0.15}0.15). 
\label{eq:slow-pdf-function}
\end {align}

Figure \ref{fig:cdf-pdf-plots} shows the fast and slow response
cumulative distribution functions (CDF) and their corresponding
probability density functions (PDF). Panel A shows the cumulative
distribution function for the fast response rate (with a growth
parameter value \(a\) set to 0.37; see Equation \ref{eq:cdf-fast}) and
Panel B shows the probability density function that results from
computing the derivative of the fast response rate cumulative
distribution function
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Cumulative Distribution Functions (CDF) and Probability Density Functions (PDF) for Fast and Slow Response Rates}
{cdf-pdf-plots}
{.38}
{Figures/cdf_pdf_plots}
{Panel A: Cumulative distribution function for the fast response rate (with a growth parameter value $a$ set to 0.37; see Equation \ref{eq:cdf-fast}). Panel B: Probability density function that results from computing the derivative of the fast response rate cumulative distribution function with respect to $x$ (see Equation \ref{eq:fast-pdf-function}). Panel C: Cumulative distribution function for the slow response rate (with a growth parameter value $a$ set to 0.15; see Equation \ref{eq:cdf-slow}). Panel D: Probability density function that results from computing the derivative of the slow response rate cumulative distribution function with respect to $x$ (see Equation \ref{eq:slow-pdf-function} and \nameref{time-structuredness} for more discussion on time structuredness). For the fast response rate functions, an 80\% response rate is obtained after 4.32 days or, equivalently, 80\% of the area underneath the probability density function is obtained at 4.32 days ($\int^{4.32}_{0} f_{fast}^\prime (x) = 0.80$). For the slow response rate functions, an 80\% response rate is obtained after 10.80 days or, equivalently, 80\% of the area underneath the probability density function is obtained at 10.80 days ($\int^{10.80}_{0} f_{slow}^\prime (x) = 0.80$).}
\end{apaFigure}
\noindent with respect to \(x\) (see Equation
\ref{eq:fast-pdf-function}). Panel C shows the cumulative distribution
function for the slow response rate (with a growth parameter value \(a\)
set to 0.15; see Equation \ref{eq:cdf-slow})) and Panel D shows the
probability density function that results from computing the derivative
of the slow response rate cumulative distribution function with respect
to \(x\) (see Equation \ref{eq:slow-pdf-function} and section on \protect\hyperlink{sec:time-structuredness}{time
structuredness} for more discussion). For the
fast response rate functions, an 80\% response rate is obtained after
4.32 days or, equivalently, 80\% of the area underneath the probability
density function is obtained at 4.32 days
(\(\int^{4.32}_{0} f_{fast}^\prime (x) = 0.80\); the integral from 0 to 4.32 of the probability density function for a fast response rate \(f^\prime(x)_{fast}\) is 0.80). For the slow response
rate functions, an 80\% response rate is obtained after 10.80 days or,
equivalently, 80\% of the area underneath the probability density
function is obtained at 10.80 days
(\(\int^{10.80}_{0} f_{slow}^\prime (x) = 0.80\); the integral from 0 to 10.80 of the probability density function for a slow response rate \(f^\prime(x)_{slow}\) is 0.80).

Having computed probability density functions for fast and slow response rates, time delays could be generated to create time-unstructured data. To generate time-unstructured data, a time delay was first
generated by sampling values according to the probability density function defined by either a fast or slow response rate (Equations \ref{eq:fast-pdf-function}--\ref{eq:slow-pdf-function}). The sampled time delay was then added to the value of the current measurement day for a person at a given time point. That is, if the collection window opened on day 60 and the generated time delay for a given person was 4.50 days, then their data would be generated by inserting a value of 64.50 for the \(time_i\) parameter of the logistic function (Equation \ref{eq:logFunction-generation}; along with the fixed-effect parameter values and the person-specific parameter values {[}or random-effects{]}).

\hypertarget{data-modelling-exp3}{%
\subsection{Modelling of Each Generated Data Set}\label{data-modelling-exp3}}

Each generated data set was modelled using the structured latent growth curve model outlined in Experiment 1 (see \protect\hyperlink{data-modelling}{data modelling} and explicated in Appendix \ref{structured-lgc}.

\hypertarget{analysis-of-data-modelling-output-and-accompanying-visualizations-1}{%
\subsection{Analysis of Data Modelling Output and Accompanying Visualizations}\label{analysis-of-data-modelling-output-and-accompanying-visualizations-1}}

Analysis and visualization was conducted as outlined in Experiment 1 (see \protect\hyperlink{analysis-visualization}{analysis and visualization}).

\hypertarget{results-and-discussion-2}{%
\section{Results and Discussion}\label{results-and-discussion-2}}

In the sections that follow, I organize the results by presenting them for each level of time structuredness (time-structured data, time-unstructured data resulting from a fast response rate, time-unstructured data resulting from a slow response rate). Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and halfway-triquarter delta parameters {[}\(\upbeta_{fixed}\), \(\upbeta_{random}\), \(\upgamma_{fixed}\), \(\upgamma_{random}\), respectively{]}). The results for the likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters {[}\(\uptheta_{fixed}\), \(\uptheta_{random}\), \(\upalpha_{fixed}\), \(\upalpha_{random}\), respectively{]}) were largely trivial and so are presented in Appendix \ref{complete-versions}.

For each level of time structuredness, I first provide a concise summary of the results and then provide a detailed report of the estimation accuracy of each day-unit parameter of the logistic function. Because the lengths of the detailed reports are considerable, I first provide concise summaries to establish a framework to interpret the detailed reports. The detailed report for the results of each time structuredness level will summarize the results of each (day-unit) parameter's bias/precision plot, report partial \(\upomega^2\) values, and then provide a qualitative summary.

\hypertarget{framework-for-interpreting-results-2}{%
\subsection{Framework for Interpreting Results}\label{framework-for-interpreting-results-2}}

To conduct Experiment 3, the three variables of number of measurements (4 levels), sample size (6 levels), and time structuredness (3 levels) were manipulated, which yielded a total of 72 cells. Importantly, within each cell, bias and precision values were also computed for each of the nine parameters estimated by the structured latent growth curve model (for a review, see \protect\hyperlink{modelling-data-sets}{modelling of each generated data set}). Thus, because the analysis of Experiment 3 computed values for many dependent variables, interpreting the results can become overwhelming. Therefore, I will provide a framework to help the reader efficiently navigate the results section.

Because I will present the results of Experiment 3 by each level of time structuredness, the framework I will describe in Figure \ref{fig:results-plot-primer} shows a template for the bias/precision plots that I will present for each level of time structuredness. The results presented for each time structuredness level contain a bias/precision plot for each of the nine estimated parameters. Each bias/precision plot shows the bias and precision for the estimation of one parameter across all measurement number and nature-of change levels. Within each bias/precision plot, dots indicate the average estimated value (which indicates bias) and error bars represent the middle 95\% range of estimated values (which indicates precision). Bias/precision plots with black border show the results for day-unit parameters and plots with gray borders show the results for Likert-unit parameters. Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and halfway-triquarter delta parameters {[}\(\upbeta_{fixed}\), \(\upbeta_{random}\), \(\upgamma_{fixed}\), \(\upgamma_{random}\),
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Set of Bias/Precision Plots Constructed for Each Spacing Schedule in Experiment 2}
{results-plot-primer-exp2}
{.77}
{Figures/logistic_results_plot_exp2}
{A bias/precision plot is constructed for each parameter of the logistic function (see Equation \ref{eq:logFunction-generation}). Bias/precision plots with black borders show the results for day-unit parameters and plots with gray border show the results for Likert-unit parameters. For each parameter, bias and precision are shown across each combination of measurement number and time structuredness.}
\end{apaFigure}
\noindent respectively{]}). The results for the Likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters {[}\(\uptheta_{fixed}\), \(\uptheta_{random}\), \(\upalpha_{fixed}\), \(\upalpha_{random}\), respectively{]}) were largely trivial and so are presented in Appendix \ref{complete-versions}. Therefore, the results of time structuredness level will only present the bias/precision plots for four parameters (i.e., the day-unit parameters).

\hypertarget{pre-processing-of-data-and-model-convergence-2}{%
\subsection{Pre-Processing of Data and Model Convergence}\label{pre-processing-of-data-and-model-convergence-2}}

After collecting the output from the simulations, non-converged models
(and their corresponding parameter estimates) were removed from
subsequent analyses. Table \ref{tab:conv-exp-3} in Appendix \ref{convergence-tables} provides the convergence
success rates for each cell in Experiment 3. Model convergence never goes below 90\%.

\hypertarget{concise-example-exp3}{%
\subsection{Time-Structured Data}\label{concise-example-exp3}}

For time-structured data, Table \ref{tab:summary-table-time-struc-exp3} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp3_plot_days_time_struc} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-struc-exp3} and provide elaboration when necessary.

Before presenting the results for equal spacing, I provide a brief description of the concise summary table created for each level of time structuredness and shown below for time-structured data in Table \ref{tab:summary-table-time-struc-exp3}. Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the measurement number/sample size pairing that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across

\noindent

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-structured data). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\raggedright\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-time-struc-exp3}Concise Summary of Results for Time-Structured Data in Experiment 3}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp3_plot_days_time_struc}A)} & All cells & All cells & Unbiased and precise estimation in all cells & 15.13\\
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp3_plot_days_time_struc}B)} & All cells & NM $\ge$ 9 with \textit{N} = 500 & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} \vphantom{1} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 9.79\\
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp3_plot_days_time_struc}C)} & All cells & No cells & Largest improvements in precision with NM = 7 & 17.22\\
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp3_plot_days_time_struc}D)} & \thead[lt]{\textbf{NM $\boldsymbol{\ge}$ 9 with \textit{N} $\ge$ 200}} & No cells & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 10.08\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-structured data). The `Error Bar Length' column indicates the error bar length that results from using the lower-bounding measurement number/sample size pairing listed in the `Qualitative Description' column (i.e., the maximum error bar length).

\hypertarget{bias-time-struc-exp3}{%
\paragraph{Bias}\label{bias-time-struc-exp3}}

Before presenting the results for bias, I provide a description of the set of bias/precision plots shown in Figure \ref{fig:exp3_plot_days_time_struc} and in the results sections for the other level of time structuredness in Experiment 3. Figure \ref{fig:exp3_plot_days_time_struc} shows the bias/precision plots for each day-unit parameter and Table \ref{tab:omega-exp2-equal} provides the partial \(\upomega^2\) values for each independent variable of each day-unit parameter. In Figure \ref{fig:exp3_plot_days_time_struc}, blue horizontal lines indicate the population values for each parameter (with population values of \(\upbeta_{fixed}\) = 180.00, \(\upbeta_{random}\) = 10.00, \(\upgamma_{fixed}\) = 20.00, and \(\upgamma_{random}\) = 4.00). Gray bands indicate the \(\pm 10\%\) margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Panels A--B show the bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters (\(\upbeta_{fixed}\) and \(\upbeta_{random}\), respectively). Panels C--D show the bias/precision plots for the fixed- and random-effect triquarter-halfway delta parameters (\(\upgamma_{fixed}\) and \(\upgamma_{random}\), respectively). Note that random-effect parameter units are in standard deviation units.
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Structured Data in Experiment 3}
{exp3_plot_days_time_struc}
{0.165}
{Figures/exp3_plot_days_time structured}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-time-struc} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 100), NM x S = interaction between number of measurements and sample size.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp3-time-struc}Partial $\upomega^2$ Values for Manipulated Variables With Time-Structured Data in Experiment 3}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp3_plot_days_time_struc}A) & 0.00 & 0.02 & 0.00\\
$\upbeta_{random}$ (Figure \ref{fig:exp3_plot_days_time_struc}B) & 0.14 & 0.27 & 0.03\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp3_plot_days_time_struc}C) & 0.25 & 0.12 & 0.07\\
$\upgamma_{random}$ (Figure \ref{fig:exp3_plot_days_time_struc}D) & 0.18 & 0.03 & 0.01\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
With respect to bias for time-structured data, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_time_struc}A): no cells.
\item
  fixed-effect halfway-triquarter delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_time_struc}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_time_struc}C): no cells.
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp3_plot_days_time_struc}D): five and seven measurements across all sample sizes and nine and 11 measurements with \(N \le 100\).
\end{itemize}
In summary, with time-structured data, estimation of all the day-unit parameters across all manipulated nature-of-change values were unbiased using at least nine measurements with \(N \ge 200\), which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-time-struc-exp3}.

\hypertarget{precision-time-struc-exp3}{%
\paragraph{Precision}\label{precision-time-struc-exp3}}

With respect to precision for time-structured data, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_time_struc}A): no cells.
\item
  fixed-effect halfway-triquarter delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_time_struc}B): five and seven measurements across all sample sizes and nine and 11 measurements with \(N \le 200\).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_time_struc}C): all cells.
\item
  random-effect halfway-triquarter delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp3_plot_days_time_struc}D): all cells.
\end{itemize}
In summary, with time-structured data, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with \(N \ge 500\), but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-time-struc-exp3}).

\hypertarget{qualitative-time-struc-exp3}{%
\paragraph{Qualitative Description}\label{qualitative-time-struc-exp3}}

For time-structured data in Figure \ref{fig:exp3_plot_days_time_struc}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-structured data, the largest improvements resulted with the following measurement number/sample size pairing(s) for the random-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)):
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 100\) or nine measurements with \(N \le 50\).
\end{itemize}
\noindent With respect to precision under time-structured data, the largest improvements in the estimation of all the day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 9.79 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements across all manipulated sample sizes, which resulted in a error bar length of 17.22 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 10.08 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-structured data. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that the greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-time-struc-exp3}).

\hypertarget{summary-of-results-for-time-structured-data}{%
\subsubsection{Summary of Results for Time-Structured Data}\label{summary-of-results-for-time-structured-data}}

In summarizing the results for time-structured data, estimation of all the day-unit parameters was unbiased using at least nine measurements with \(N \ge 200\) (see \protect\hyperlink{bias-time-struc-exp3}{bias}). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-time-struc-exp3}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing under equal spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all the day-unit parameters resulted from using moderate measurement number/sample size pairings. With time-structured data, the largest improvements in bias and precision in the estimation of all the day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see \protect\hyperlink{qualitative-time-struc-exp3}{qualitiative description}).

\hypertarget{time-unstructured-data-characterized-by-a-fast-response-rate}{%
\subsection{Time-Unstructured Data Characterized by a Fast Response Rate}\label{time-unstructured-data-characterized-by-a-fast-response-rate}}

For time-unstructured data characterized by a fast response rate, Table \ref{tab:summary-table-fast-exp3} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp3_plot_days_fast} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-fast-exp3} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-fast-exp3}, see \protect\hyperlink{concise-example-exp3}{concise summary}).

\hypertarget{bias-fast-exp3}{%
\subsubsection{Bias}\label{bias-fast-exp3}}

With respect to bias for time-unstructured data characterized by a fast response rate, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_fast}A): no cells.
\item
  fixed-effect halfway-triquarter delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_fast}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_fast}C): no cells.
\end{itemize}
\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-unstructured data characterized by a fast response rate). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\raggedright\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-fast-exp3}Concise Summary of Results for Time-Unstructured Data (Fast Response Rate) in Experiment 3}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Description & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp3_plot_days_fast}A)} & All cells & All cells & Unbiased and precise estimation in all cells & 15.35\\
\thead[lt]{$\gamma_{fixed}$ \\  (Figure \ref{fig:exp3_plot_days_fast}B)} & All cells & NM $\ge$ 9 with \textit{N} $\ge$ 500 & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} \vphantom{1} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 10.25\\
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp3_plot_days_fast}C)} & All cells & No cells & Largest improvements in precision with NM = 7 & 17.47\\
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp3_plot_days_fast}D)} & \thead[lt]{
                                            \textbf{NM $\ge$ 7 with \textit{N} = 1000} or \\
                                            \textbf{NM $\ge$ 9 with \textit{N} $\ge$ 200} or \\
                                            \textbf{NM = 11 with \textit{N} = 100}} & No cells & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 10.51\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp3_plot_days_fast}D): five measurements across all sample sizes, seven measurements with \(N \le 500\), nine measurements with \(N \ge 100\), and 11 measurements with \(N \le 50\).
\end{itemize}
\noindent Importantly, for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)), although bias was still within the acceptable margin of error, bias appeared to be constant across all manipulated measurement number/sample size pairings. In comparing the bias/precision plots between time-unstructured data characterized by a fast response rate (Figure \ref{fig:exp3_plot_days_fast}A) and time-structured data (Figure \ref{fig:exp3_plot_days_time_struc}A), the systematic decline in bias observed for fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) appeared to result from thedecrease in time structuredness.

In summary, with time-unstructured data characterized by a fast response rate, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using at least seven measurements with \(N = 1000\), nine measurements with \(N \ge 200\), or 11 measurements with \(N \ge 100\), which is indicated by the emboldened text in the `Unbiased' column of Table \ref{tab:summary-table-fast-exp3}.

\hypertarget{precision-fast-exp3}{%
\subsubsection{Precision}\label{precision-fast-exp3}}

With respect to precision for time-unstructured data characterized by a fast response rate, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_fast}A): no cells.
\item
  fixed-effect halfway-triquarter delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_fast}B): five and seven measurements across all sample sizes and nine and 11 measurements with \(N \le 200\).
\end{itemize}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Unstructured Data Characterized by a Fast Response Rate in Experiment 3}
{exp3_plot_days_fast}
{0.165}
{Figures/exp3_plot_days_time unstructured (fast response)}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-fast} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 100), NM x S = interaction between number of measurements and sample size.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp3-fast}Partial $\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data Characterized by a Fast Response Rate in Experiment 3}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp3_plot_days_fast}A) & 0.00 & 0.02 & 0.00\\
$\upbeta_{random}$ (Figure \ref{fig:exp3_plot_days_fast}B) & 0.15 & 0.27 & 0.03\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp3_plot_days_fast}C) & 0.29 & 0.14 & 0.08\\
$\upgamma_{random}$ (Figure \ref{fig:exp3_plot_days_fast}D) & 0.17 & 0.04 & 0.01\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{itemize}
\tightlist
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_fast}C): all cells.
\item
  random-effect halfway-triquarter delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp3_plot_days_fast}D): all cells.
\end{itemize}
In summary, with time-unstructured data characterized by a fast response rate, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with \(N \ge 500\), but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-fast-exp3}).

\hypertarget{qualitative-fast-exp3}{%
\subsubsection{Qualitative Description}\label{qualitative-fast-exp3}}

For time-unstructured data characterized by a fast response rate (see Figure \ref{fig:exp3_plot_days_fast}), although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-unstructured data characterized by a fast response rate, the largest improvements in bias resulted with the following measurement number/sample size pairing(s) for the random-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)):
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 100\) or nine measurements with \(N \le 50\).
\end{itemize}
\noindent With respect to precision under time-unstructured data characterized by a fast response rate, the largest improvements in the estimation of all the day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 10.25 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements across all manipulated sample sizes, which resulted in a maximum error bar length of 17.47 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 10.51 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-unstructured data characterized by a fast response rate. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-fast-exp3}).

\hypertarget{summary-of-results-for-time-unstructured-characterized-by-a-fast-response-rate}{%
\subsubsection{Summary of Results for Time-Unstructured Characterized by a Fast Response Rate}\label{summary-of-results-for-time-unstructured-characterized-by-a-fast-response-rate}}

In summarizing the results for time-unstructured data characterized by a fast response rate, estimation of all the day-unit parameters was unbiased using least seven measurements with \(N = 1000\), nine measurements with \(N \ge 200\), or 11 measurements with \(N \ge 100\) (see \protect\hyperlink{bias-fast-exp3}{bias}). Importantly, bias for some day-unit parameters was constant across manipulated measurement number/sample size pairings. Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-fast-exp3}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing resulted in precise estimation of all the day-unit parameters with time-unstructured data characterized by a fast response rate, the largest improvements in precision (and bias) across all day-unit parameters resulted with moderate measurement number/sample size pairings. With time-unstructured data characterized by a fast response rate, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see \protect\hyperlink{qualitative-fast-exp3}{qualitiative description}).

\hypertarget{time-unstructured-data-characterized-by-a-slow-response-rate}{%
\subsection{Time-Unstructured Data Characterized by a Slow Response Rate}\label{time-unstructured-data-characterized-by-a-slow-response-rate}}

For time-unstructured data characterized by a slow response rate, Table \ref{tab:summary-table-slow-exp3} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp3_plot_days_slow} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-slow-exp3} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-slow-exp3}, see \protect\hyperlink{concise-example-exp3}{concise summary}).

\hypertarget{bias-slow-exp3}{%
\subsubsection{Bias}\label{bias-slow-exp3}}

With respect to bias for time-unstructured data characterized by a slow response rate, estimates were biased (i.e., above the acceptable 10\% cutoff) for each day-unit parameter in the following cells:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_slow}A): no cells.
\item
  fixed-effect halfway-triquarter delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_slow}B): no cells.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_slow}C): no cells.
\item
  random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp3_plot_days_slow}D): five measurements across all sample sizes, seven measurements with \(N \le 500\), nine measurements with \(N \ge 100\), and 11 measurements with \(N \le 50\).
\end{itemize}
\noindent Note that, for all parameters except the halfway-triquarter delta parameter (\(\upgamma_{fixed}\)), bias appeared to be constant across all manipulated measurement number/sample size pairings.

In summary, with time-unstructured data characterized by a slow response rate, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using at least seven measurements with \(N = 1000\), nine measurements with \(N \ge 200\), or 11 measurements with \(N \ge 100\), which is indicated by the emboldened text

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-unstructured data characterized by a slow response rate). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{6.5cm}>{\raggedright\arraybackslash}p{3cm}}
\caption{\label{tab:summary-table-slow-exp3}Concise Summary of Results for Time-Unstructured Data (Slow Response Rate) in Experiment 3}\\
\toprule
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Summary} \\
\cmidrule(l{3pt}r{3pt}){4-5}
\multicolumn{3}{c}{ } & \multicolumn{2}{c}{Description} \\
\cmidrule(l{3pt}r{3pt}){4-5}
Parameter & Unbiased & Precise & Qualitative Summary & Error Bar Length\\
\midrule
\thead[lt]{$\upbeta_{fixed}$ \\ (Figure \ref{fig:exp3_plot_days_slow}A)} & All cells & All cells & Low bias and high precision in all cells & 16.68\\
\thead[lt]{$\gamma_{fixed}$ \\ (Figure \ref{fig:exp3_plot_days_slow}B)} & All cells except NM = 5 with \textit{N} = 50 & \thead[lt]{NM = 7 with \textit{N} = 200 or \\ 
                                            NM = 9 with \textit{N} $\le$ 500} & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 10.53\\
\thead[lt]{$\upbeta_{random}$ \\ (Figure \ref{fig:exp3_plot_days_slow}C)} & No cells except NM = 5 with \textit{N} = 30 and NM = 11 with \textit{N} $\le$ 50 & No cells & Largest improvements in precision with NM = 7 & 18.44\\
\thead[lt]{$\upgamma_{random}$ \\ (Figure \ref{fig:exp3_plot_days_slow}D)} & No cells & No cells & \thead[lt]{Largest improvements in bias and \\
                                                      precision using NM = 7 with \textit{N} $\boldsymbol{\ge}$ 200 or \\
                                                      M = 9 with \textit{N} $\boldsymbol{\le}$ 100} & 10.9\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Unstructured Data Characterized by a Slow Response Rate in Experiment 3}
{exp3_plot_days_slow}
{0.165}
{Figures/exp3_plot_days_time unstructured (slow response)}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-slow} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 100), NM x S = interaction between number of measurements and sample size.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp3-slow}Partial $\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data Characterized by a Slow Response Rate in Experiment 3}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp3_plot_days_slow}A) & 0.00 & 0.02 & 0.00\\
$\upbeta_{random}$ (Figure \ref{fig:exp3_plot_days_slow}B) & 0.15 & 0.27 & 0.03\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp3_plot_days_slow}C) & 0.29 & 0.14 & 0.08\\
$\upgamma_{random}$ (Figure \ref{fig:exp3_plot_days_slow}D) & 0.17 & 0.04 & 0.01\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
in the `Unbiased' column of Table \ref{tab:summary-table-slow-exp3}.

\hypertarget{precision-slow-exp3}{%
\subsubsection{Precision}\label{precision-slow-exp3}}

With respect to precision for time-unstructured data characterized by a slow response rate, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10\% of a parameter's population value) in the following cells for each day-unit parameter:
\begin{itemize}
\tightlist
\item
  fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_slow}A): no cells.
\item
  fixed-effect halfway-triquarter delta parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_slow}B): five and seven measurements across all sample sizes and nine and 11 measurements with \(N \le 200\).
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_slow}C): all cells.
\item
  random-effect halfway-triquarter delta parameter {[}\(\upgamma_{random}\){]} in Figure \ref{fig:exp3_plot_days_slow}D): all cells.
\end{itemize}
In summary, with time-unstructured data characterized by a slow response rate, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with \(N \ge 500\), but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the `Precise' column of Table \ref{tab:summary-table-slow-exp3}).

\hypertarget{qualitative-slow-exp3}{%
\subsubsection{Qualitative Description}\label{qualitative-slow-exp3}}

For time-unstructured data characterized by a slow response rate (see Figure \ref{fig:exp3_plot_days_slow}), although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-unstructured data characterized by a slow response rate, the largest improvements resulted with the following measurement number/sample size pairings for the random-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)):
\begin{itemize}
\tightlist
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 100\) or nine measurements with \(N \le 50\).
\end{itemize}
\noindent With respect to precision under time-unstructured data characterized by a slow response rate, the largest improvements in the estimation of all the day-unit parameters (except the fixed-effect days-to-halfway elevation parameter {[}\(\upbeta_{fixed}\){]}) resulted from using the following measurement number/sample size pairings:
\begin{itemize}
\tightlist
\item
  fixed-effect triquarter-halfway delta parameter (\(\upgamma_{fixed}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 10.53 days.
\item
  random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\)): seven measurements across all manipulated sample sizes, which resulted in a maximum error bar length of 18.44 days.
\item
  random-effect triquarter-halfway delta parameter (\(\upgamma_{random}\)): seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\), which resulted in a maximum error bar length of 10.9 days.
\end{itemize}
For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-unstructured data characterized by a fast response rate. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that the greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see the emboldened text in the `Qualitative Description' column of Table \ref{tab:summary-table-slow-exp3}).

\hypertarget{summary-of-results-time-unstructured-characterized-by-a-slow-response-rate}{%
\subsubsection{Summary of Results Time-Unstructured Characterized by a Slow Response Rate}\label{summary-of-results-time-unstructured-characterized-by-a-slow-response-rate}}

In summarizing the results for time-unstructured data characterized by a slow response rate, estimation of all the day-unit parameters was unbiased using least seven measurements with \(N = 1000\), nine measurements with \(N \ge 200\), or 11 measurements with \(N \ge 100\) (see \protect\hyperlink{bias-slow-exp3}{bias}). Importantly, bias for most day-unit parameters was constant across manipulated measurement number/sample size pairings. Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see \protect\hyperlink{precision-slow-exp3}{precision}). Although it may be discouraging that no manipulated measurement number/sample size pairing resulted in precise estimation of all the day-unit parameters with time-unstructured data characterized by a slow response rate, the largest improvements in precision (and bias) across all day-unit parameters resulted with moderate measurement number/sample size pairings. With time-unstructured data characterized by a slow response rate, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) (see \protect\hyperlink{qualitative-slow-exp3}{qualitiative description}).

\hypertarget{how-does-time-structuredness-affect-model-performance}{%
\subsection{How Does Time Structuredness Affect Model Performance?}\label{how-does-time-structuredness-affect-model-performance}}

In Experiment 3, I was interested in how decreasing time structuredness affected model performance. Table \ref{tab:summary-table-exp3} summarizes the results for each spacing schedule in Experiment 3. Text within the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairing needed to, respectively, obtain unbiased an precise estimation for all the day-unit parameters. The `Error Bar Length' column indicates longest error bar lengths that result in the estimation of each day-unit parameter from using the measurement number/sample size pairings listed in the `Qualitative Description' column. In looking at the `Qualitative Description' column, the greatest improvements in bias and precision for all time structuredness levels result from using either seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\).

Although the same measurement number/sample size pairing can be used to obtain the greatest improvements in model performance under any time structuredness level, two results suggest that model performance decreases as the time structuredness decreases. First, the error bar lengths in Table \ref{tab:summary-table-exp3} increase as time structuredness decreases. As an

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }`Qualitative Description' column indicates the number of measurements that obtains the greatest improvements in bias and precision across all day-unit parameters. `Error Bar Summary' columns list the error bar lengths that result for each day-unit parameter using the measurement number listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\in$ \{80, 180, 280\}; $\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{5cm}>{\raggedright\arraybackslash}p{4.5cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{5.5cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}}
\caption{\label{tab:summary-table-exp3}Concise Summary of Results Across All Time Structuredness Levels in Experiment 3}\\
\toprule
\multicolumn{4}{c}{ } & \multicolumn{4}{c}{Error Bar Summary} \\
\cmidrule(l{3pt}r{3pt}){5-8}
Time Structuredness & Unbiased & Precise & Qualitative Description & $\upbeta_{fixed}$ & $\upgamma_{fixed}$ & $\upbeta_{random}$ & $\upgamma_{random}$\\
\midrule
\thead[lt]{Time structured \\ (see Figure \ref{fig:exp3_plot_days_time_struc} and Table \ref{tab:summary-table-time-struc-exp3})} & \thead[lt]{NM $\ge$ 9 with \textit{N} $\ge$ 200} & No cells & \thead[lt]{Largest improvements in precision \\
                                                          using \textbf{NM = 7 with \textit{N} $\ge$ 200} \vphantom{1} or \\
                                                          \textbf{NM = 9 with \textit{N} $\le$ 100}} & 15.13 & 9.79 & 17.22 & 10.08\\
\cmidrule{1-8}
Time unstructured (fast response rate; see Figure \ref{fig:exp3_plot_days_fast} and Table \ref{tab:summary-table-fast-exp3}) & \thead[lt]{NM $\ge$ 7 with \textit{N} = 1000 or \\
                                            NM $\ge$ 9 with \textit{N} $\ge$ 200 or \\
                                            NM = 11 with \textit{N} = 100} & No cells & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 15.35 & 10.25 & 17.47 & 10.51\\
\cmidrule{1-8}
Time unstructured (slow response rate; see Figure \ref{fig:exp3_plot_days_slow} and Table \ref{tab:summary-table-slow-exp3}) & No cells & No cells & \thead[lt]{Largest improvements in precision \\ 
                                                      using \textbf{NM = 7 with \textit{N} $\ge$ 200} or \\
                                                      \textbf{NM = 9 with \textit{N} $\le$ 100}} & 16.68 & 10.53 & 18.44 & 10.90\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\noindent example, the error bar length of the fixed-effect days-to-halfway elevation parameter is 15.13 days with time-structured data and increases to 16.68 days with time-unstructured data characterized by a slow response rate. Second, and more alarming, the bias incurred as time structuredness decreases is constant across all measurement number/sample size pairings (see Figure \ref{fig:exp3_plot_days_slow}). That is, the increase in bias that results from time-unstructured data cannot be reduced by increasing the number of measurements or sample size. An an example, the fixed-effect days-to-halfway elevation parameter is underestimated by approximately 6 days across all measurement number/sample size pairings (\(\upbeta_{fixed}\); see Figure \ref{fig:exp3_plot_days_slow}A).

To understand why bias is systematic as time structure decreases, it is important to first understand latent growth curve models more deeply. By default, latent growth curve models assume time-structured data. As a reminder, data are time structured when participants provide data at the exact same moment at each time point (e.g., if a study collects data on the first day of each month for a year, then time-structured data would only be obtained if participants all provide their data at the exact same moment each time data are collected). In other words, one response schedule characterized the response patterns of all participants. Consider a random-intercept-random-slope model shown in Figure \ref{fig:latent-growth} that is used to model stress ratings collected on the first day of each month over the course of five months from \(j\) people. Stress ratings at each \(i\) time point for each \(j\) person are predicted by person-specific intercepts (\(b_{0j}\)) and slopes (\(b_{1j}\); in addition to a residual term {[}\(\upepsilon_{ij}\){]}) as shown below in Equation \ref{eq:stressLevel1} (which is often called Level-1 equation):
\begin{align}
  Stress_{ij} = b_{0j} + b_{1j}(Stress_{ij}) + \upepsilon_{ij}.
  \label{eq:stressLevel1}
\end{align}
\noindent The person-specific intercepts and slopes are the sum of a fixed-effect parameter whose value is constant across all people (\(\upgamma_{00}\) and \(\upgamma_{10}\)) and a random-effect parameter that represents the variance of the person-specific variables (i.e., \(\upsigma_{00}\) and \(\upsigma_{10}\)). The fixed-effect intercept and slope, respectively, represent the mean starting stress value (i.e., average stress value at Time = 0) and the average slope value. Importantly, by estimating a random-effect parameter (in addition to the fixed-effect parameters), deviations from the mean intercept an slope values can be obtained for each \(j\) person (\(\upsigma_{0j}\) and \(\upsigma_{1j}\)) and these values can be used to compute person-specific intercepts and slopes as shown in Equations \ref{eq:intLevel2}--\ref{eq:slopeLevel2} (which are often called Level-2 equations):
\begin{align}
  b_{0j} = \hat{\upgamma_{00}} + \upsigma_{0j} \label{eq:intLevel2} \\
  b_{1j} = \hat{\upgamma_{10}} + \upsigma_{1j} \label{eq:slopeLevel2}
\end{align}
\noindent Note that the fixed- and random-effect parameters in Figure \ref{fig:latent-growth} are superscribed with a caret (\(\hat{\phantom{\beta}}\)) to indicate that the values of these parameters are estimated by the latent growth curve model. Also note that, in Figure \ref{fig:latent-growth}, circles indicate latent variables, triangles indicate constants, and squares indicate observed (or manifest variables).
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Path Diagram for a Random-Intercept-Random-Slope Latent Growth Curve Model}
{latent-growth}
{0.65}
{Figures/lgc_path_diagram}
{Stress at each $i$ time point for each $j$ person is predicted by a person-specific slope ($b_{0j}$), person-specific intercept ($b_{1j}$), and residual ($\upepsilon_{ij}$; see Equation \ref{eq:stressLevel1} [Level-1 equation]). The person-specific effects are also called \textit{random effects} and each is the sum of a fixed-effect parameter whose value is constant across all people ($\upgamma_{00}$ and $\upgamma_{10}$) and a random-effect parameter that represents the variance of the person-specific variables (i.e., $\upsigma_{00}$ and $\upsigma_{10}$; see Equations \ref{eq:intLevel2}--\ref{eq:slopeLevel2} [Level-2 equations]). Note that the fixed- and random-effect parameters are superscribed with a caret ($\hat{\phantom{\beta}}$) to indicate that the values of these parameters are estimated by the latent growth curve model. Also note that circles indicate latent variables, triangles indicate constants, and squares indicate observed (or manifest variables).}
\end{apaFigure}
To understand why bias in parameter estimation increases as time structuredness decreases, it is important to discuss one component of the latent growth curve model not yet discussed: loadings. In latent variable models, \emph{loadings} comprise numbers that indicate how a latent variable should be modelled. The numbers in loadings satisfy two needs of latent variables. First, loadings give latent variables a unit; latent variables are inherently unitless, and so require a unit so that they can be meaningfully interpreted. By fixing at least one pathway between a latent variable and observed variable with a loading, the latent variable takes on the units of the observed variable. In the current example, the intercept and slope latent variables take on the units of the stress ratings (e.g., Likert units). Second, in latent growth curve models, latent variables need their effect to be specified, and loadings satisfy this need. In the current example, the intercept has a constant effect at each time point, and this is represented by setting its loadings at each time point to 1. The slope represents linearly increasing change over time, and so its loadings are set to increase by an integer value of 1 after each time point.

Although loadings allow latent variables to model change over time, their values are constant across participants and it is this characteristic that causes model performance to decrease as time structuredness decreases. In focusing on the slope variable in Figure \ref{fig:latent-growth}, the loadings of 0, 1, 2, 3, and 4 assume that only one response pattern describes how each participant provides their data over some period of time. If the period of time is assume to be five months, then the loadings assume that each participant provides data on the first day of each month, which is indicated by the gray rectangles (along with the loading number above each gray rectangle) in each panel of Figure \ref{fig:time-structure}. With time-structured data, constant loadings do not decrease model performance because each participant provides their data on the first day of each month. As examples of model performance with time-structured data, panels A and C of Figure \ref{fig:time-structure} show the predicted and actual patterns for individual participants with linear and logistic patterns of change, respectively. Because each individual participant displays a response pattern identical to the one specified by the loadings, the predicted and actual patterns of change are identical. With time-unstructured data however, the predicted and actual patterns of change no longer overlap because response patterns in participants differ from the one assumed by the
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Model Performance Decreases as Time Structuredness Decreases}
{time-structure}
{0.165}
{Figures/time_structure_plots}
{Panel A: Predicted and actual linear patterns of change are identical because of time-structured data. Panel B: Predicted and actual linear patterns of change are different because of time-untructured data. Panel C: Predicted and actual logistic patterns of change are identical because of time-structured data. Panel D: Predicted and actual logistic patterns of change differ because model because of time-unstructured data. Predicted patterns of change are based on empty dots and actual patterns of change are based on filled dots. Shaded vertical rectangles indicate the response pattern expected across all participants by the loadings set in the latent growth curve model depicted in Figure \ref{fig:latent-growth}.}
\end{apaFigure}
\noindent loadings. As examples of model performance with time-unstructured data, panels B and D of Figure \ref{fig:time-structure} show the predicted and actual patterns for individual participants with linear and logistic patterns of change, respectively. Although each participant provides data many days after the first day of each month, the constant loadings set in the model lead it to assume that data were collected on the first day of each month. Because the model misattributes the time at which data are recorded, the predicted patterns of change are shifted leftward, leading to a decrease in model performance. In Figure \ref{fig:time-structure}B, the intercept parameter value (\(b_{0j}\)) increases due to time-unstructured data. In Figure \ref{fig:time-structure}D, the value for the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\)) decreases due to time-unstructured data. Therefore, the loading structured specified by default in latent growth curve model causes model performance to decrease when data are time unstructured.

\hypertarget{def-variables}{%
\subsection{Eliminating the Bias Caused by Time Unstructuredness: Using Definition Variables}\label{def-variables}}

In examining the effects of time structuredness, the results show that model performance decreases as time structuredness decreases. Importantly, increasing the number of measurements and/or sample size has no effect on eliminating the decline in model performance. Because data are likely to be time unstructured under realistic conditions, the resulting decline in model performance seems inevitable and this can be disconcerting. Fortunately, the error incurred when time unstructuredness is overlooked can be prevented by allowing loadings to vary across people by using \emph{definition variables}: Observed variables are placed in parameter matrices so that values in the matrix (specifically, the loadings) are constrained to person-specific values \autocite{mehta2000,mehta2005,blozis2008,sterba2014}. In the current example, definition variables are used to set loadings to the specific time points at which each participant provides their data. Thus, the observed variable is the specific \(i\) time point at which a \(j\) person provides a datum and this value is inserted into the \(\uplambda\) matrix (for details of this matrix, see Appendix \ref{structured-lgc}). Figure \ref{fig:latent-def} shows a path diagram for a random-intercept-random-slope latent variable model with definition variables. In comparing it to the latent growth curve model in Figure \ref{fig:latent-growth}, there is only one difference. Instead of setting the loadings to be constant across all participants, definition variables (indicated by diamonds) are used so that loadings for each \(j\) person are set to the specific \(i\) time point at which a datum was provided.
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Path Diagram for a Random-Intercept-Random-Slope Latent Growth Curve Model With Definition Variables}
{latent-def}
{0.65}
{Figures/def_model}
{Stress at each $i$ time point for each $j$ person is predicted by a person-specific slope ($b_{0j}$), person-specific intercept ($b_{1j}$), and residual ($\upepsilon_{ij}$; see Equation \ref{eq:stressLevel1} [Level-1 equation]). The person-specific effects are also called \textit{random effects} and each is the sum of a fixed-effect parameter whose value is constant across all people ($\upgamma_{00}$ and $\upgamma_{10}$) and a random-effect parameter that represents the variance of the person-specific variables (i.e., $\upsigma_{00}$ and $\upsigma_{10}$; see Equations \ref{eq:intLevel2}--\ref{eq:slopeLevel2} [Level-2 equations]). Note that the fixed- and random-effect parameters are superscribed with a caret ($\hat{\phantom{\beta}}$) to indicate that the values of these parameters are estimated by the latent growth curve model. To account for time-unstructured data, loadings are allowed to vary using definition variables (diamonds). Specifically, loadings for each $j$ person are set to the specific $i$ time point at which a datum was provided. Also note that circles indicate latent variables, triangles indicate constants, and squares indicate observed (or manifest variables).}
\end{apaFigure}
To show that definition variables can eliminate the error incurred by time-unstructured data, I ran an additional set of simulations. In these simulations, time-unstructured data characterized by a slow response rate were analyzed with a structured latent growth curve model equipped with definition variables (see Appendix \ref{def-model-code} for the corresponding code). Number of measurements and sample size were manipulated as in Experiment 3, thus yielding 24 cells (i.e., 4{[}number of measurements: 5, 7, 9, 11{]} x 6{[}sample size: 30, 50, 100, 200, 500, 1000{]}). As in all previous simulation experiments, I only present the results for the day-unit parameters because the results for the Likert-unit parameters were largely negligible (for Likert-unit bias/precision plots, see Appendix \ref{complete-versions}). Similar to the results for convergence success rates obtained in all other simulation experiments, convergence success rates across all cells were always above 90\%, with the specific values presented in Table \ref{tab:conv-exp-3-def}.\footnote{It should be noted that convergence times increased by approximately eightfold when definition variables were used.}

Figure \ref{fig:exp3_plot_days_def} shows the bias/precision plots that result from using definition variables to model time-unstructured data characterized by a slow response rate. In comparing the bias/precision plot of Figure \ref{fig:exp3_plot_days_def} to that of Figure \ref{fig:exp3_plot_days_slow}, model performance improves in the following four ways:
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters When Using Definition Variables To Model Time-Unstructured Data Characterized by a Slow Response Rate}
{exp3_plot_days_def}
{0.165}
{Figures/exp3_defplot_days_time unstructured (slow response)}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-def} for $\upomega^2$ effect size values.}
\end{apaFigure}
\begin{ThreePartTable}
\begin{TableNotes}
\item NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 100), NM x S = interaction between number of measurements and sample size.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{6cm}ccc}
\caption{\label{tab:omega-exp3-def}Partial $\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data Characterized by a Slow Response Rate With a Model Using Definition Variables in Experiment 3}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Effect} \\
\cmidrule(l{3pt}r{3pt}){2-4}
Parameter & NM & S & NM x S\\
\midrule
$\upbeta_{fixed}$ (Figure \ref{fig:exp3_plot_days_def}A) & 0.00 & 0.02 & 0.00\\
$\upbeta_{random}$ (Figure \ref{fig:exp3_plot_days_def}B) & 0.14 & 0.27 & 0.03\\
$\upgamma_{fixed}$ (Figure \ref{fig:exp3_plot_days_def}C) & 0.25 & 0.12 & 0.07\\
$\upgamma_{random}$ (Figure \ref{fig:exp3_plot_days_def}D) & 0.18 & 0.03 & 0.01\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Bias in the estimation of the fixed-effect days-to-halfway elevation parameter (\(\upbeta_{fixed}\); Figure \ref{fig:exp3_plot_days_slow}A) almost entirely disappears when using definition variables (Figure \ref{fig:exp3_plot_days_def}A).
\item
  Bias in the estimation of the fixed-effect triquarter-halfway elevation parameter (\(\upgamma_{fixed}\); Figure \ref{fig:exp3_plot_days_slow}B) almost entirely disappears when using definition variables (Figure \ref{fig:exp3_plot_days_def}B).
\item
  Bias in the estimation of the random-effect days-to-halfway elevation parameter (\(\upbeta_{random}\); Figure \ref{fig:exp3_plot_days_slow}C) almost entirely disappears when using definition variables (Figure \ref{fig:exp3_plot_days_def}C).
\item
  Bias in the estimation of the random-effect triquarter-halfway elevation parameter (\(\upgamma_{random}\); Figure \ref{fig:exp3_plot_days_slow}D) returns to levels observed with time-structured data (see Figure \ref{fig:exp3_plot_days_time_struc}A) with definition variables. Precision also decreases (especially with five measurements) when using definition variables (Figure \ref{fig:exp3_plot_days_def}C).
\end{enumerate}
\noindent Therefore, given the improvements in the estimation of each day-unit parameter that follow from using definition variables, latent variable models, by default, should use definition variables to improve model performance when data are time unstructured.

\hypertarget{summary-of-experiment-3}{%
\section{Summary of Experiment 3}\label{summary-of-experiment-3}}

I designed Experiment 3 to investigate whether model performance decreased as time structuredness decreased. Across all manipulated levels of time structuredness, the greatest improvements in model performance result from using either seven measurements with \(N \ge 200\) and nine measurements with \(N \le 100\). Importantly, although the measurement number/sample size pairings that result in the greatest improvements in model performance do not change as time structuredness decreases, the absolute level of model performance itself decreases. In using the same measurement number/sample size pairing across all levels of time structuredness, precision slightly increases and, more importantly, bias decreases such that it is constant; that is, the decrease in bias cannot be avoided by using increasing measurement number and/or sample size. Given that data are unlikely to be time structured, then the decrease in model performance seems inevitable. Fortunately, the decrease in model performance that results from time-unstructured data can be avoided by using definition variables in latent growth curve models, which I show to be the case by in an additional set of simulations. Therefore, the greatest improvements in model performance result from using either seven measurements with \(N \ge 200\) or nine measurements with \(N \le 100\) and, definition variables should be used to prevent model performance from decreasing as time structuredness decreases.

\hypertarget{general-discussion}{%
\chapter{General Discussion}\label{general-discussion}}

In systematically reviewing the simulation literature, I found that studies rarely conducted comprehensive investigations into the effects of longitudinal design and analysis factors on model performance with nonlinear patterns of change. Specifically, few studies examined three-way interactions between any of the following four variables: 1) measurement spacing, 2) number of measurements, 3) sample size, and 4) time structuredness. Given that longitudinal designs are necessary for understanding the temporal dynamics of psychological processes (for a more detailed explanation, see Appendix \ref{ergodicity}), it is important that researchers understand how longitudinal design and analysis factors affect the performance of longitudinal analyses. Therefore, to address these gaps in the literature, I designed three simulation experiments.

In each simulation experiment, a logistic pattern of change (i.e., s-shaped change pattern) was modelled under conditions that varied in nature of change (i.e., shape of the logistic curve), measurement number, sample size, and time structuredness.\footnote{Importantly, no simulation experiment manipulated more than three variables at once so that results would not be too difficult to understand \parencite{halford2005}.} To fit a logistic function where each parameter could be meaningfully interpreted, each simulation experiment used a structured latent growth model to estimate nonlinear change (for a detailed explanation, see Appendix \ref{structured-lgc}).

To investigate the effects of longitudinal design and analysis factors on model performance, my simulation experiments examined the accuracy with which each logistic function parameter was estimated. In computing the estimation accuracy of each parameter, two questions were of importance: 1) How well was the parameter estimated on average (bias) and 2) what was a range of values that could be expected for an estimate from the output of a single model (precision). Thus, model performance was the combination of bias and precision, and these two metrics were computed for each logistic function parameter. To succinctly summarize each experiment, I have created Table \ref{tab:exp-summary-table}. Each row of Table \ref{tab:exp-summary-table} contains a summary of a simulation experiment.

In Experiment 1, I was interested in answering two questions: 1) Does placing measurements near periods of change increase model performance and 2) how should measurements be spaced when the nature of change is unknown. To answer these two questions, I manipulated measurement spacing, number of measurements, and nature of change (i.e., shape of the s-shaped curve). With respect to the first question, the results of Experiment 1 suggest that model performance increases when measurements are placed closer to periods of change (see section discussing \protect\hyperlink{meas-placing}{measurement spacing}). With respect to the second question, the results of Experiment 1 suggest that measurements should be spaced equally over time when the nature of change is unknown (see section discussing measurement spacing when the nature of change is \protect\hyperlink{unknown}{unknown}).

In Experiment 2, I was interested in the measurement number/sample size pairings needed to obtain high model performance (i.e., low bias, high precision) under different spacing schedules. To answer this question, I manipulated measurement spacing, measurement number, and sample size. Although no manipulated measurement number/sample size pairing results in high model performance (low bias, high precision) of all parameters, moderate measurement numbers and sample sizes often yield low bias and the largest improvements in model performance. For all spacing schedules (except middle-and-extreme spacing), the largest improvements in model performance result from using either either seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 100. The results for middle-and-extreme spacing are largely a byproduct of the nature of change used in Experiment 2, and so are of little value to emphasize.
\begin{longtable}[l]{ll>{\raggedright\arraybackslash}p{7.25cm}}
\caption{\label{tab:exp-summary-table}Summary of Each Simulation Experiment}\\
\toprule
Simulation Exeriment & Independent Variables & Main Results\\
\midrule
\endfirsthead
\caption[]{\label{tab:exp-summary-table}Summary of Each Simulation Experiment \textit{(continued)}}\\
\toprule
Simulation Exeriment & Independent Variables & Main Results\\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
Experiment 1 & \thead[lt]{Spacing of measurements \\ Number of measurements \\ Nature of change} & \tabitem Model performance is higher when measurements are placed closer to periods of change \newline
                                            \tabitem Measurements should be spaced equally when the nature of change is unknown\\
Experiment 2 & \thead[lt]{Spacing of measurements \\ Number of measurements \\ Sample size} & \tabitem The greatest improvements in model performance result from using either seven measurements with $N \ge$ 200 or nine measurements with $N \le$ 100\\
Experiment 3 & \thead[lt]{Number of Measurements \\ Sample size \\ Time structuredness} & \tabitem The greatest improvements in model performance across all time structuredness levels result from using either seven measurements with $N \ge$ 200 or nine measurements with $N \le$ 100 \newline
                                            \tabitem Use definition variables to prevent model performance from decreasing as time structuredness decreases\\*
\end{longtable}
In Experiment 3, I was interested in examining how time structuredness affected model performance. To answer this question, I manipulated measurement spacing, measurement number, and time structuredness. Although the measurement number/sample size pairings that result in the greatest improvements in model performance are the same as in Experiment 2, two results suggest that model performance decreases as time structuredness decreases. First, precision decreases as time structuredness decreases. That is, precision decreases as response patterns of participants become increasingly dissimilar. Second, and more concerning, bias decreases as time structuredness decreases regardless of the measurement number or sample size. That is, as response patterns of participants become increasingly dissimilar, bias increases across all measurement number/sample size pairings.

Importantly, the decrease in model performance that results as time structuredness decreases can be prevented by using a latent growth curve model with definition variables. By default. latent growth curve models assume an identical response pattern for all participants (i.e., time-structured data). Definition variables can be used in latent growth curve models to allow individual response patterns to be modelled \autocite{mehta2000,mehta2005}. In an additional set of simulations (see section on \protect\hyperlink{def-variables}{definition variables}), I generate time-unstructured data and analyze the data with a structured latent growth curve model that has definition variables. When definition variables are used, the decrease in model performance that results from a decrease in time structuredness disappears. Therefore, to obtain the largest improvements in model performance, either seven measurements with \emph{N} \(\ge\) 200 or nine measurements with \emph{N} \(\le\) 100 must be used and, importantly, the latent growth curve model must use definition variables.

In summary, the results of my simulation experiments are the first (to my knowledge) to provide specific measurement number and sample size recommendations needed to accurately model nonlinear change over time. Importantly, although previous studies have investigated the effects of some longitudinal design and analysis factors on model performance with nonlinear patterns of change, the results of these studies are limited because they either use unrealistic fixed-effects models \autocite[e.g.,][]{finch2017}, use models with with non-meaningful parameter interpretations \autocites[e.g.,][]{fine2019,liu2022}, or use unrealistic model fitting procedures \autocite{finch2017}. Additionally, I developed novel and replicable procedures for creating spacing schedules (see Appendix \ref{measurement-schedules}) and simulating time-unstructured data (see \protect\hyperlink{simulating-time-struc}{time structuredness}).

The sections that follow will discuss the limitations of the current simulation experiments and avenues for future research. The scope of the discussion will then expand to include issues concerning the nature of longitudinal designs, the importance of modelling nonlinear change, and suggestions for modelling such change.

\hypertarget{limitations-and-future-directions}{%
\section{Limitations and Future Directions}\label{limitations-and-future-directions}}

Recall that in designing each simulation experiment, I decided to manipulate no more than three variables so that results could be readily understood \autocite{halford2005}. Although limiting the number of independent variables has its advantages, there are a number of non-manipulated variables could have influenced the results. In the sections that follow, I review the possible impact of not manipulating these variables.

\hypertarget{cutoff-values-for-bias-and-precision}{%
\subsection{Cutoff Values for Bias and Precision}\label{cutoff-values-for-bias-and-precision}}

In simulation research, cutoff values for parameters are often set to a percentage of a parameter's population value \autocite[e.g.,][]{muthen1997} for two reasons. First, cutoff values are needed to allow bias and precision to be categorized so that results can be clearly presented. In the current set of simulation experiments, cutoff values for bias and precision were set to 10\% of the parameter's population value \autocite{muthen1997}. If a parameter estimate was outside a 10\% error margin, then estimation was considered biased. If an error bar whisker length was longer than 10\% of the parameter's population value, then estimation was considered imprecise. Therefore, using cutoff values allows categorical decisions to be made modelling performance.

Second, cutoff values are needed to allow results from different simulation studies to be meaningfully compared. If another study uses a cutoff value of 15\%, then the results of this study become difficult to compare with the results of the current simulation experiments because each study uses different cutoff standards. Therefore, it is
important that simulation studies use a common standard of 10\% \autocite{muthen1997}---as I have done in my simulation
experiments. Although simulation studies use cutoff values to simplify results and allow meaningful comparisons of results, it is also important that cutoff values themselves represent meaningful boundary values.

Given the need for using cutoff values in simulation research, it was necessary to do so in my experiments. Although several methods exist for setting cutoff values that each have their advantages and disadvantages, I decided to choose a method that aligned with the conventions of simulation research. Thus, I used a percentage-based cutoff rule \autocite{muthen1997}. Like other methods for setting cutoff values, the percentage-based cutoff method has limitations and I discuss these limitations in the paragraphs that follow.

In simply defining cutoff values as a percentage of a population value, cutoff values can lead to problematic conclusions. As a simple example, consider a scenario where a beverage company wants to produce a caffeinated drink that can only increase heart rate and body temperature by a certain amount. Specifically, neither heart rate nor body temperature can increase by 10\% of their resting values. Given that, for males and females, any value below 70 and 80, respectively, constitutes a healthy resting heart rate \autocite{nanchen2018}, a 10\% increase would translate to an increase of 7 and 8 beats per minute, which is arguably less than the increase in heart rate caused from walking \autocite[e.g.,][]{whitley1987}. Thus, requiring that a caffeinated drink not increase resting heart rate by a value equal to or greater than 10\% appears to be a responsible stipulation. Unfortunately, setting a 10\%-cutoff rule for body temperature allows for far less desirable outcomes than a 10\% cutoff for heart rate. Using a typical body temperature of 37 \(^\circ\)C for resting body temperature, a 10\%-cutoff would allow for a change in body temperature of 3.7 \(^\circ\)C. Given that deviations of less than 3.7 \(^\circ\)C from resting body temperature can lead to physiological impairments and even death \autocite{moran2002}, restricting the caffeinated drink to not increase body temperature by 10\% of its resting value is unwise. Therefore, a percentage cutoff rule can fail to create useful cutoff values by overlooking the underlying nature of the variable in question.

In the current simulation experiments, the percentage-cutoff rule may have led to overly pessimistic conclusions about model performance. As an example, consider the estimation of the random effect parameters. In each simulation experiment, no measurement number/sample size pairing resulted in high model performance (low bias, high precision) of any random-effect parameter\footnote{It should be mentioned that low bias was obtained from using moderate measurement number/sample size pairings.} Specifically, the random-effect day-unit parameters were never modelled precisely with any measurement number/sample size pairing. Although the lack of precise estimation for the random-effect day-unit parameters is concerning, the result may be a byproduct of having used conventional standards for precision. For a given parameter, the cutoff value used to deem estimation precise was proportional to the population value set for that parameter. Specifically, the cutoff values for precision (and bias) were set to 10\% of the parameter's population value \autocite{muthen1997}---as is suggested by the literature. In setting the cutoff value to a percentage of the parameter's population value, the margin of error becomes a function of the population value: Large population values have large margins of error and small population values have small margins of error. Given that the random-effect parameters had the smallest population values (e.g., 10.00, 4.00, and 0.05) and that even the largest measurement number/sample size pairing of 11 measurements with \emph{N} = 1000 did not model with high precision, it is conceivable that the associated 10\%-error margins (e.g., 1.00, 0.04, and 0.005) may have been too small.

Future research could consider using more useful cutoff values. One way to set useful cutoff values in simulation experiments is to contextualize cutoff values with respect to a real-world phenomenon. Using smallest effect sizes of interest offers one way to contextualize cutoff values \autocite{lakens2017,lakens2018}. Introduced to improve null-hypothesis significance testing, a smallest effect size of interest constitutes the smallest effect size above which a researcher considers an observed effect meaningful \autocite{lakens2017}. Instead of testing the typical zero-effect null hypothesis, a researcher can specify a smallest effect size of interest as the null hypothesis. Using a smallest effect size of interest (in tandem with equivalence testing), a researcher can more definitively conclude whether an effect is trivially small or not and, consequently, be less likely to incorrectly dismiss an effect as nonexistent. Thus, smallest effect sizes of interest allow researchers to make more meaningful conclusions. Although the current simulation experiments did not employ significance testing, the cutoff values used to determine whether estimation was biased and precise could be improved in future research by treating them as smallest cutoff values of interest. By replacing the current percentage-based cutoff values with smallest cutoff values of interest for each parameter, conclusions are likely to become more meaningful because cutoff values are contextualized with respect to real-world phenomena.

One effective way to determine smallest cutoff values of interest in future research would be to use anchor-based methods \autocite{anvari2021}. As an example, I detail a two-step procedure for how an anchor-based method could be used to determine a cutoff value for a the Likert-unit parameter of the fixed-effect baseline parameter (\(\uptheta_{fixed}\)). First, a survey for some Likert-unit variable such as job satisfaction could be given at two time points to employees. Importantly, after completing the survey at the second time point, employees would also indicate how much job satisfaction changed by answering an anchor question (e.g., ``Job satisfaction increased/decreased by a little, increased/decreased a lot, or did not change.''). Second, a smallest cutoff value of interest would need to be computed. Given that the fixed-effect baseline parameter (\(\uptheta_{fixed}\)) represents the starting value, then employees that indicated no change in job satisfaction could be said to still be at baseline and their data could be used to compute a smallest effect size of interest for the baseline parameter(\(\uptheta_{fixed}\)). Specifically, the difference in job satisfaction between the two time points could be calculated for employees that indicated no change. Therefore, using the anchor-based method, the smallest cutoff value of interest for the fixed-effect baseline parameter (\(\uptheta_{fixed}\)) is the mean change in some Likert-unit variable---job satisfaction in the current example---from respondents that indicate no change.\footnote{If the mean observed change in job satisfaction from employees that indicate no change is a near-zero value, using this value as a smallest effect-size of interest for the fixed-effect baseline parameter ($\uptheta_{fixed}$) would likely be too conservative. In such situations, the smallest effect-size of interest for the fixed-effect baseline parameter ($\uptheta_{fixed}$) could be determined by computing the mean change in job satisfaction from employees that indicate a small change (i.e., 'little increase/decrease), as it could be said that these employees have slightly moved away from baseline.}

\hypertarget{external-validity-of-simulation-experiments}{%
\subsection{External Validity of Simulation Experiments}\label{external-validity-of-simulation-experiments}}

In the current set of simulation experiments, data were were generated under ideal conditions in three ways. First, the current simulation experiments always assumed complete data (i.e., 100\% response rate). Unfortunately, researchers rarely obtain complete data and, instead, have some amount of data that are missing. One investigation estimated that, using a sample of 300 articles published over a period of three years, 90\% of articles had missing data, with each study estimated to have over 30\% of data points missing \autocite[Chapter 1]{mcknight2007}. Perhaps even more concerning, missing data often compound over time \autocite{newman2003}.\footnote{It should be noted that great recommendations exist on increasing response rate. In fact, an entire book of recommendations exists on this issue \parencite[see][]{dillman2014}.} Future research could simulate more realistic conditions for response rates in longitudinal designs, missing data could be set to increase---either linearly or nonlinearly---over time under three types of commonly simulated missing data mechanisms: 1) missing data are random, 2) missing data depend on the value of another variable, and 3) missing data depend on their own values \autocite{newman2009}.

Second, the current simulation experiments assumed measurement invariance over time. That is, at each time point, the manifest variable was assumed to be measured with the same measurement model---specifically, aspects of the measurement model such as factor loadings, intercepts, and error variances were assumed to remain constant over time \autocite{mellenbergh1989,vandenberg2000}. For a longitudinal design, it is important that the measurement of a latent variable meet the conditions for invariance so that change over time can be meaningfully interpreted. As an example, consider a situation where a researcher measures some latent variable over time such as job satisfaction using a four-item survey where each item measures some component of job satisfaction on a Likert scale (range of 1--5). If the loadings of a specific item change over time, then the response values from participants cannot be meaningfully interpreted. For example, if a participant gives the same answers to each item across two time points but factor loadings of any item(s) change between the two time points, then their job satisfaction scores between the time points will, counterintuitively, be different. Thus, even though job satisfaction did not change over time, changes in the measurement model of job satisfaction caused the observed scores to be different. Unfortunately, measurement invariance is seldom observed \autocite{vandenberg2000,vandeschoot2015} because measurement model components often change over time \autocite[e.g.,][]{fried2016}. Thus, it can be argued that it is more realistic to assume measurement non-invariance. To simulate measurement non-invariance, future research could generate data such that aspects of measurement models change over time \autocite[e.g.,][]{kim2014a}.

Third, the current simulations assumed error variances in the observed variables to be constant and uncorrelated over time. Unfortunately, error variances over time are likely to correlate with each other and be nonconstant or heterogeneous \autocite{goldstein1994,deshon1998,bliese2002,braun2013,ding2016,lester2019,blozis2018}. Future research could simulate more realistic error variance structures by generating errors to correlate with each other and to decrease over time---as observed in a longitudinal analysis of fatigue \autocite{lang2018}.

\hypertarget{simulations-with-other-longitudinal-analyses}{%
\subsection{Simulations With Other Longitudinal Analyses}\label{simulations-with-other-longitudinal-analyses}}

Given that researchers are often interested in investigating questions outside of modelling a nonlinear pattern of change, longitudinal analyses outside of the structured latent growth curve model used in the current simulation experiments may be used in other circumstances. Although the structured latent growth curve modelling framework used in the current simulations allows nonlinear change to be meaningfully modelled (see Appendix \ref{structured-lgc-code}), the framework cannot be used to understand all meaningful components of change. As an example, if a researcher is interested in modelling different response patterns in some variable in response to some organizational event---for instance, work engagement patterns after mergers \autocite{seppl2018}---a structured latent growth curve model could not meaningfully model such data because it assumes one pattern of responding. Therefore, to develop a comprehensive understanding of change over time, a variety of longitudinal analyses may be considered and it is important that future simulation research investigate the performance of these analyses. I outline four longitudinal analyses below that future simulation experiments should consider investigating.

First, discontinuous growth models are needed to model punctuated change \autocite{bliese2016,bliese2020}.\footnote{In the multilevel framework, discontinuous growth modelling is also referred to as piecewise hierarchical linear modelling \parencite{raudenbush2002} and multiphase mixed-effects models \parencite{cudeck2002}. In the latent variable or structural equation modelling framework, discontinuous growth modelling is also referred to as piecewise growth modelling \parencites{chou2004}{kohli2013}. Note that spline models are technically different from discontinuous growth models because spline models cannot model vertical displacements at knot points and, thus, are models for continuous change \parencite[for a review, see][]{edwards2017}.} Given that change in organizations often results from discrete events, the pattern of change is often punctuated or discontinuous \autocite{morgeson2015}. Examples of punctuated change in organizations have been observed in life satisfaction after unemployment \autocite{lucas2004}, trust after betrayal \autocite{fulmer2015}, and firm performance after an economic recession \autocites{kim2014b}[for more examples, see][]{bliese2016}. Discontinuous growth models can model punctuated change by selectively activating and deactivating growth factors---that is, assigning nonzero- and zero-value weights, respectively---after certain time points \autocite{bliese2016}. Therefore, given that punctuated change merits the need for discontinuous growth modelling in organizational research, future simulation studies should investigate the effects of longitudinal design and analysis factors on the performance of such models.

Second, time series models are needed to model cyclical patterns \autocite{pickup2014}. Technological advances such as smartphones and wearable sensors have allowed researchers to collect intensive longitudinal data sets where data are collected over at least 20 time points \autocite{collins2006} with the experience sampling method \autocite{larson2014}. With intensive longitudinal data sets, researchers are often interested in modelling cyclical patterns such as those with affect and performance \autocite{dalal2014} and stress \autocite{fuller2003}. Time series models allow researchers to model cyclical patterns through a variety of methods (e.g., decomposition, autoregressive integrated moving average, etc.). Therefore, the rise of intensive longitudinal data made possible by technological advances merits the use of time series models, and future simulation studies should investigate the effects of longitudinal design and analysis factors affect the performance of such models.

Third, second-order growth models are needed to model measurement invariance \autocite{sayer2001,hancock2001}. In organizational research, many variables are latent---that is, they cannot be directly observed (e.g., job satisfaction, organizational commitment, trust). Because latent variables cannot be directly measured, nomological networks\footnote{Although a nomological network gives meaning to a latent variable by specifying relations with other variables, it should be noted that nomological networks have limitations in establishing validity---whether a survey measures what is purports to measure. In psychology, almost all variables psychology are correlated with each other \parencite{meehl1978}, and so using the correlations specified in a nomological network to establish validity is imprecise because many latent variables are likely to satisfy the network of relations. One potentially more effective method to establish validity is to first assume the existence of the latent variable and then develop theory that specifies processes by which changes in the latent variable manifest themselves in reality. Surveys can the be constructed by causatively testing whether the theorized manifestations that follow from changes in the latent variable actually emerge \parencite[for a review, see][]{borsboom2004}.}---correlation matrices specifying relations between the target latent variable and other variables---are constructed to develop valid measures of latent variables \autocite{cronbach1955}. As discussed previously, an unfortunate phenomenon with surveys is that the accuracy with which they measure a latent variable is seldom invariant over time---that is, measurement accuracy is often non-invariant \autocite{vandenberg2000,vandeschoot2015}. If measurement non-invariance is overlooked, model performance decreases \autocite{kim2014b,jeon2020}. Fortunately, second-order latent growth curve models allow researchers to include measurement models and, thus, test for measurement invariance and estimate parameters with greater accuracy \autocite[e.g.,][]{kim2014a}. Therefore, given that the common occurrence of measurement non-invariance in organizational research merits the use of second-order latent growth models, future simulation studies should investigate the effects of longitudinal design and analysis factors on the performance of such models.

Fourth, growth mixture models are needed to model heterogeneous response patterns \autocite{wang2007,vandernest2020}. In organizations, employees are likely to respond to changes in different ways, thus exhibiting heterogeneous response patterns. Examples of heterogeneous response patterns have been observed in job performance patterns during organizational restructuring \autocite{miraglia2015}, work engagement patterns after mergers \autocite{seppl2018}, and leadership development throughout training \autocite{day2011}. Growth mixture models allow heterogeneity in response patterns to be modelled by including a latent categorical variable that allows participants to be placed into different response category patterns \autocite[cf.][]{bauer2007}. Therefore, given that heterogeneous response patterns in organizations merit the use of interest for modelling cyclical patterns with intensive longitudinal data merits the use of time series models, future simulation studies should investigate the effects of longitudinal design and analysis factors on the performance of such models.

\hypertarget{nonlinear-patterns-and-longitudinal-research}{%
\section{Nonlinear Patterns and Longitudinal Research}\label{nonlinear-patterns-and-longitudinal-research}}

\hypertarget{a-new-perpective-on-longitudinal-designs-for-modelling-change}{%
\subsection{A New Perpective on Longitudinal Designs for Modelling Change}\label{a-new-perpective-on-longitudinal-designs-for-modelling-change}}

The results of the current simulation experiments suggest that previous measurement number recommendations for longitudinal research need to be modified when modelling nonlinear patterns of change. Previous suggestions for conducting longitudinal research recommend that at least three measurements be used \autocite{chan1998,ployhart2010}. The requirement that a longitudinal study use at least three measurements is largely to obtain an estimate of change that is not confounded by measurement error \autocite{rogosa1982} and allow a nonlinear pattern of change to be modelled. Unfortunately, although using at least three measurements allows a nonlinear pattern of change to be modelled, doing so provides no guarantee that a nonlinear pattern of change will be accurately modelled. The results of the current simulation experiments suggest that, at the very least, five measurements are needed to accurately model a nonlinear pattern of change. Importantly, five measurements only results in adequate model performance if the measurements are placed near periods of change. Given that organizational theories seldom delineate nonlinear patterns of change \autocite[for a rare example, see][]{methot2017}, it is unlikely that researchers will place measurements near periods of change. In situations where researchers have little insight into the pattern of nonlinear change, the current simulation experiments suggest that at least seven measurements be used. Therefore, when researchers do not have strong theory to suggest a nonlinear pattern of change, the current simulations suggest that at least seven measurements are needed.

Although the current results suggest that seven measurements are needed to model nonlinear change, these results by no means imply that longitudinal designs with fewer measurements are of no value. Studies measuring a variable at two time points (i.e., pre-post designs) can be used to estimate meaningful anchors \autocite{anvari2021}. Studies measuring change between three and seven time points can, for instance, be used to investigate causality by determining whether reverse causality occurs \autocite{leszczensky2019}. As a last point, it should be noted that studies using fewer than seven measurements may be able to provide accurate parameter estimates for nonlinear models that estimate fewer parameters than the nine parameters estimated by the model in the current simulations. If a latent variable model estimates fewer parameters, the optimization problem becomes less complex, and so it is conceivable that the convergence algorithm can find accurate parameter estimates with fewer than seven measurements.

\hypertarget{why-is-it-important-to-model-nonlinear-patterns-of-change}{%
\subsection{Why is it Important to Model Nonlinear Patterns of Change?}\label{why-is-it-important-to-model-nonlinear-patterns-of-change}}

For at least 30 years, research in organizational psychology has had a minimal effect on practitioners and their practices \autocites{daft1990}[for a review, see][]{lawler2022}. Few practitioners--specifically, an estimated 1\%---read journal articles \autocite{rynes2002a}, which is accompanied by a poor understanding by managers of fundamental principles in organizational psychology, which has been observed across multiple countries including the Netherlands \autocite{sanders2008}, the United States \autocite{rynes2002a}, Finland, South Korea, and Spain \autocite{tenhil2014}. Perhaps most unfortunate, a poor understanding of organizational psychology by managers is associated with large effects on financial and individual performance \autocite[for a review, see][]{rynes2002b}. Additionally, an estimated 55\% of practitioners are skeptical that evidence-based human resource practices can affect any positive change \autocite{kpmg2015}. With the gap between academics and practitioners being so patently wide, some academics have cast doubt on the possibility of academic-practitioner research collaborations \autocite{kieser2009}.

One factor that may contribute to the academic-practitioner gap is that research seldom provides specific recommendations to practitioners. When considering the typical organizational theory, propositions often lack any degree of specificity: They often specify non-zero linear relations between variables \autocite{edwards2010}. Because it is difficult to develop specific recommendations from non-zero relations, it becomes unsurprising that reviews of the organizational literature estimate 3\% of human resource articles address problems faced by practitioners \autocite{sackett1990} and, in reviewing of 5780 articles from 1963--2007, concluded that research is often late to address practitioner issues \autocite{cascio2008}. Thus, with organizational theories often providing vague predictions, it becomes difficult to develop specific recommendations for practitioners.

Organizational research can provide specific recommendations to practitioners by modelling nonlinear patterns of change. In modelling nonlinear change, organizational researcher can understand how processes unfold over time and when specific psychological phenomena emerge \autocite{mitchell2001,navarro2020}. As an example of the usefulness of modelling nonlinear change, \textcite{vancouver2020} uses computational modelling to predict specific nonlinear patterns of self-efficacy and performance in response to different events over time. In predicting nonlinear patterns, the theory provides specific insight into how much specific events affect performance and self-efficacy, how long such effects last, and how performance and self-efficacy affect each other. Given that change over time is likely to be nonlinear \autocite{cudeck2007}, it is likely that many opportunities exist for organizational research to provide specific recommendations for solving problems faced by practitioners.

In summary, a concerning gap exists between academics and practitioners in organizational research whereby academics seldom address the problems faced by practitioners \autocite[e.g.,][]{sackett1990} and practitioners rarely consult research when making decisions \autocite{rynes2002b}. One cause for the academic-practitioner gap is the paucity of specific recommendations provided by academics. One way that academics can reduce the gap from practitioners is to model nonlinear patterns of change over time. In modelling a nonlinear patterns of change, organizational research can develop an understanding o how processes evolve over time and when psychological phenomena emerge \autocite{mitchell2001,navarro2020}. With an understanding of the temporal dynamics of psychological processes, organizational research can then provide specific recommendations to practitioners.

\hypertarget{suggestions-for-modelling-nonlinear-change}{%
\subsection{Suggestions for Modelling Nonlinear Change}\label{suggestions-for-modelling-nonlinear-change}}

In modelling nonlinear change, researchers can either do so using the multilevel or latent growth curve framework. Although the multilevel and latent growth curve frameworks return identical results under many conditions \autocite[e.g.,][]{bauer2003}, researchers should consider using the latent growth curve framework over the multilevel framework for two reasons. First, the multilevel framework encounters convergence problems when specifying nonlinear models, and the frequency of convergence problems increases with the number of random-effect parameters \autocite[for a review, see][]{mcneish2020}. Second, the latent variable framework allows data to be more realistically modelled than the multilevel approach thanks to, in large part, its ability to include measurement models to investigate phenomena such as measurement invariance \autocite{sayer2001,hancock2001}.

In modelling nonlinear change, researchers should prioritize the interpretability of their models so that results can be more easily applied. As an example, the structured latent growth curve model used in the current simulation experiments provides a meaningful representation of logistic pattern of change. In the current simulations, the number of days needed to reach the halfway- and triquarter-halfway elevation points (among other parameters) were estimated.\footnote{Note that parameters of nonlinear functions can be reparameterized to estimate other meaningful aspects of a curve \parencite{preacher2015}.} To add another level of meaning, a latent categorical variable can be added to the model to create a growth mixture model \autocite{vandernest2020}. Using a growth mixture model, not only can nonlinear change be defined in a meaningful way, but response groups can be modelled and people can be categorized into the groups based on their individual pattern of change. Thus, in prioritizing the meaning of statistical models, the current example shows how heterogeneous logistic response patterns can be meaningfully modelled and how frequently each pattern occurs.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

Investigating nonlinear patterns of change is a growing area of organizational research. By understanding nonlinear patterns of change, organizational research can develop a more nuanced understanding of temporal dynamics and provide practitioners with more specific recommendations. The simulation experiments conducted in my dissertation contribute to this goal by providing boundary conditions for model performance.

\newpage
\renewcommand\bibname{References}
\phantomsection
\addcontentsline{toc}{chapter}{References}
\printbibliography

%change numbering for figures, tables, and equations for appendices
\renewcommand\thefigure{\theapp.\arabic{figure}} %change figure numbering for appendix such that it goes A.1, A.2, etc.
\counterwithin{figure}{app} %reset figure number counter for each appendix

\renewcommand\thetable{\theapp.\arabic{table}} %change figure numbering for appendix such that it goes A.1, A.2, etc.
\counterwithin{table}{app} %reset figure number counter for each appendix

%reset equation number number counter for each appendix
\renewcommand{\theequation}{\theapp.\arabic{equation}}
\counterwithin{equation}{app} %reset figure number counter for each appendix

\counterwithin{chunk}{app} %reset code chunk numbering

\appendix

\newpage

\app{Ergodicity and the Need to Conduct Longitudinal Research}

\label{ergodicity}

To understand why cross-sectional results are unlikely to agree with longitudinal results for any given analysis, a discussion of data structures is apropos. Consider an example where a researcher obtains data from 50 people measured over 100 time points such that each row contains a \(p\) person's data over the 100 time points and each column contains data from 50 people at a \(t\) time point. For didactic purposes, all data are assumed to be sampled from a normal distribution. To understand whether findings in any given cross-sectional data set yield the same findings in any given longitudinal data set, the researcher randomly samples one cross-sectional and one longitudinal data set and computes the mean and variance in each set. To conduct a cross-sectional analysis, the researcher randomly samples the data across the 50 people at a given time point and computes a mean of the scores at the sampled time point (\(\bar{X}_t\)) using Equation \ref{eq:cross-mean} shown below:
\begin{align}
\bar{X}_t = \frac{1}{P}\sum^P_{p = 1} x_p,
\label{eq:cross-mean}
\end{align}
\noindent where the scores of all \(P\) people are summed (\(x_p\)) and then divided by the number of people (\(P\)). To compute the variance of the scores at the sampled time point (\(S^2_t\)), the researcher uses Equation \ref{eq:cross-variance} shown below:
\begin{align}
S^2_t = \frac{1}{P}\sum^P_{p = 1} (x_p - \bar{X}_t)^2,
\label{eq:cross-variance}
\end{align}
\noindent where the sum of the squared differences between each person's score (\(x_p\)) and the average value at the given \(t\) time point (\(\bar{X}_t\)) is computed and then divided by the number of people (\(P\)). To conduct a longitudinal analysis, the researcher randomly samples one person's data across the 100 time points and also computes a mean and variance of the scores. To compute the mean across the \(t\) time points of the longitudinal data set (\(\bar{X}_p\)), the researcher uses Equation \ref{eq:long-mean} shown below:
\begin{align}
\bar{X}_p = \frac{1}{T}\sum^T_{t = 1} x_t,
\label{eq:long-mean}
\end{align}
\noindent where the scores at each \(t\) time point are summed (\(x_t\)) and then divided by the number of time points (\(T\)). The researcher also computes a variance of the sampled person's scores across all time points (\(S^2_p\)) using Equation \ref{eq:long-variance} shown below:
\begin{align}
S^2_p = \frac{1}{T}\sum^T_{t = 1} (x_t - \bar{X}_p)^2,
\label{eq:long-variance}
\end{align}
\noindent where the sum of squared differences between the score at each time point (\(x_t\)) and the average value of the \(p\) person's scores (\(\bar{X}_p\)) is computed and then divided by the number of time points (\(T\)).

If the researcher wants to treat the mean and variance from the cross-sectional and longitudinal data sets as interchangeable, then two conditions outlined by ergodic theory must be satisfied \autocite{molenaar2004,molenaar2009}.\footnote{Note that ergodic theory is an entire mathematical discipline \parencite[for an introduction, see][]{petersen1983}. In the current context, the most important ergodic theorems are those proven by \citeauthor{birkhoff1931} \parentext{\cite*{birkhoff1931}, \cite[for a review, see][Chapter 3]{choe2005}}} First, a given cross-sectional mean and variance can only closely estimate the mean and variance of any given person's data (i.e., a longitudinal data set) to the extent that each person's data originate from a normal distribution with the same mean and variance. If each person's data originate from a different normal distribution, then computing the mean and variance at a given time point would, at best, describe the values of one person. When each person's data are generated from the same normal distribution, the condition of \emph{homogeneity} is met. Importantly, satisfying the condition of homogeneity does not guarantee that the mean and variance obtained from another cross-sectional data set will closely estimate the mean and variance of any given person (i.e., any given longitudinal data set). The mean and variance values computed from any given cross-sectional data set can only closely estimate the values of any given person to the extent that the cross-sectional mean and variance remain constant over time. If the mean and variance of observations remain constant over time, then the second condition of \emph{stationarity} is satisfied. Therefore, the researcher can only treat means and variances from cross-sectional and longitudinal data sets as interchangeable if each person's data are generated from the same normal distribution (homogeneity) and if the mean and variance remain constant over time (stationarity). When the conditions of homogeneity and stationarity are satisfied, a process is said to be \emph{ergodic}: Analyses of cross-sectional data sets will return the same values as analyses on longitudinal data sets.

Given that psychological studies almost never collect data from only one person, one potential reservation may be that the conditions required for ergodicity only hold when a longitudinal data set contains the data of one person. That is, if the researcher uses the full data set containing the data of 100 people sampled over 100 time points and computes 100 cross-sectional means and variances (Equation \ref{eq:cross-mean} and Equation \ref{eq:cross-variance}, respectively) and 100 longitudinal means and variances (Equation \ref{eq:long-mean} and Equation \ref{eq:long-variance}, respectively), wouldn't the average of the cross-sectional means and variances be the same as the average of the longitudinal means and variances? Although averaging the cross-sectional means returns the same value as averaging the longitudinal means, the average longitudinal variance remains different from the average cross-sectional variance \autocite[for several empirical examples, see][]{fisher2018}. Therefore, the conditions of ergodicity apply even with larger longitudinal and cross-sectional sample sizes.

The guaranteed differences in cross-sectional and longitudinal variance values that result from non-ergodic processes have far-reaching implications. Almost every analysis employed in organizational research---whether it be correlation, regression, factor analysis, mediation, etc.---analyzes variability, and so, when a process is non-ergodic, cross-sectional variability will differ from longitudinal variability, and the results obtained from applying any given analysis on each of the variabilities will differ as a consequence. Because variability is central to so many analyses, the non-equivalence of longitudinal and cross-sectional variances that results from a non-ergodic process explains why discussions of ergodicity often point out that ``for non-ergodic processes, an analysis of the structure of IEV {[}interindividual variability{]} will yield results that differ from results obtained in an analogous analysis of IAV {[}intraindividual variability{]}''\autocite[p.~202]{molenaar2004}.\footnote{It is important to note that a violation of one or both ergodic conditions (homogeneity and stationarity) does not mean that an analysis of cross-sectional variability yields results that have no relation to the results gained from applying the analysis on longitudinal variability (i.e., the causes of cross-sectional variability are independent from the causes of longitudinal variability). An analysis of cross-sectional variability can still give insight into temporal dynamics if the causes of non-ergodicity can be identified \parencites{voelkle2014}[for similar discussion, see][]{spector2019}. Thus, conceptualizing ergodicity on a continuum with non-erdogicity and ergodicity on opposite ends provides a more accurate perspective for understanding ergodicity \parencites{adolf2019}{medaglia2019}.}

With an understanding of the conditions required for ergodicity, a brief review of organizational phenomena finds that these conditions are regularly violated. Focusing only on homogeneity (each person's data are generated from the same distribution), several instances in organizational research violate this condition. As examples of homogeneity violations, employees show different patterns of absenteeism over five years \autocite{magee2016}, leadership development over the course of a seminar \autocite{day2011}, career stress over the course of 10 years \autocite{igic2017}, and job performance in response to organizational restructuring \autocite{miraglia2015}. With respect to stationarity (constant values for statistical parameters across people over time), several examples can be generated by realizing how calendar events affect psychological processes and behaviours throughout the year. As examples of stationarity violations, consider how salespeople, on average, undoubtedly sell more products during holidays, how employees, on average, take more sick days during the winter months, and how accountants, on average, experience more stress during tax season. With violations of ergodic conditions commonly occurring in organizational psychology, it becomes fitting to echo the commonly held sentiment that few, if any, psychological processes are ergodic \autocite{molenaar2004,molenaar2008,molenaar2009,fisher2018,curran2011,wang2015,hamaker2012}. As a result, longitudinal research is necessary for understanding psychological processes.

\app{Code Used to Run Monte Carlo Simulations for all Experiments}

\label{simulation-code}

The code used to compute the simulations of each experiment are shown in Code Block \ref{sim-code}. Note that the cell size is 1000 (i.e., \texttt{num\_iterations\ =\ 1000}).

\captionof{chunk}{Code Use to Run Monte Carlo Simulations for Each Simulation Experiment}\restoreparindent\label{sim-code}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\AttributeTok{repo =} \StringTok{\textquotesingle{}sciarraseb/nonlinSims\textquotesingle{}}\NormalTok{, }\AttributeTok{force=}\NormalTok{T)}

\FunctionTok{library}\NormalTok{(easypackages)}
\NormalTok{packages }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}devtools\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}nonlinSims\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}parallel\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tidyverse\textquotesingle{}}\NormalTok{, }\StringTok{"OpenMx"}\NormalTok{, }\StringTok{"data.table"}\NormalTok{, }\StringTok{\textquotesingle{}progress\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}tictoc\textquotesingle{}}\NormalTok{)}
\FunctionTok{libraries}\NormalTok{(packages)}

\NormalTok{time\_period }\OtherTok{\textless{}{-}} \DecValTok{360}

\CommentTok{\#Population values for parameters }
\CommentTok{\#fixed effects}
\NormalTok{sd\_scale }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{common\_effect\_size }\OtherTok{\textless{}{-}} \FloatTok{0.32}
\NormalTok{theta\_fixed }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{alpha\_fixed }\OtherTok{\textless{}{-}}\NormalTok{ theta\_fixed }\SpecialCharTok{+}\NormalTok{ common\_effect\_size}
\NormalTok{beta\_fixed }\OtherTok{\textless{}{-}} \DecValTok{180}
\NormalTok{gamma\_fixed }\OtherTok{\textless{}{-}} \DecValTok{20}

\CommentTok{\#random effects }
\NormalTok{sd\_theta }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{sd\_alpha }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{sd\_beta }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{sd\_gamma }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{sd\_error }\OtherTok{\textless{}{-}} \FloatTok{0.05}

\CommentTok{\#List containing population parameter values}
\NormalTok{pop\_params\_4l }\OtherTok{\textless{}{-}} \FunctionTok{generate\_four\_param\_pop\_curve}\NormalTok{(}
  \AttributeTok{theta\_fixed =}\NormalTok{  theta\_fixed, }\AttributeTok{alpha\_fixed =}\NormalTok{ alpha\_fixed, }
   \AttributeTok{beta\_fixed =}\NormalTok{ beta\_fixed, }\AttributeTok{gamma\_fixed =}\NormalTok{ gamma\_fixed, }
   \AttributeTok{sd\_theta =}\NormalTok{ sd\_theta, }\AttributeTok{sd\_alpha =}\NormalTok{ sd\_alpha, }
   \AttributeTok{sd\_beta =}\NormalTok{ sd\_beta, }\AttributeTok{sd\_gamma =}\NormalTok{ sd\_gamma, }\AttributeTok{sd\_error =}\NormalTok{ sd\_error}



\NormalTok{num\_iterations }\OtherTok{\textless{}{-}} \FloatTok{1e3} \CommentTok{\#n=1000 (cell size)}
\NormalTok{seed }\OtherTok{\textless{}{-}} \DecValTok{27} \CommentTok{\#ensures replicability }

\CommentTok{\# Experiment 1 (number measurements,  spacing, midpoint) {-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{factor\_list\_exp\_1 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}num\_measurements\textquotesingle{}} \OtherTok{=} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{5}\NormalTok{, }\AttributeTok{to =} \DecValTok{11}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{), }
                          \StringTok{\textquotesingle{}time\_structuredness\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}time\_structured\textquotesingle{}}\NormalTok{),}
                          \StringTok{\textquotesingle{}spacing\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}time\_inc\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}time\_dec\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}mid\_ext\textquotesingle{}}\NormalTok{), }
                          \StringTok{\textquotesingle{}midpoint\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{80}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{280}\NormalTok{),  }
                          \StringTok{\textquotesingle{}sample\_size\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{225}\NormalTok{))}

\FunctionTok{tic}\NormalTok{()}
\NormalTok{exp\_1\_data }\OtherTok{\textless{}{-}} \FunctionTok{run\_exp\_simulation}\NormalTok{(}\AttributeTok{factor\_list =}\NormalTok{ factor\_list\_exp\_1, }\AttributeTok{num\_iterations =}\NormalTok{ num\_iterations, }\AttributeTok{pop\_params =}\NormalTok{ pop\_params\_4l, }
                                 \AttributeTok{num\_cores =} \FunctionTok{detectCores}\NormalTok{()}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{seed =}\NormalTok{ seed)}
\FunctionTok{toc}\NormalTok{()}

\CommentTok{\#Average computation time is 1 iteration per second. As an example, Experiment has 48 cells x 1000 iterations/cell = 48 000 iterations and seconds/3600s/hour \textasciitilde{} 13.33 hours (simulations computed with 15 cores)}
\FunctionTok{write\_csv}\NormalTok{(}\AttributeTok{x =}\NormalTok{ exp\_1\_data, }\AttributeTok{file =} \StringTok{\textquotesingle{}\textasciitilde{}/Desktop/exp\_1\_data.csv\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Experiment 2 (number measurements, spacing,  sample size) {-}{-}{-}}
\NormalTok{factor\_list\_exp\_2 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}num\_measurements\textquotesingle{}} \OtherTok{=} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{5}\NormalTok{, }\AttributeTok{to =} \DecValTok{11}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{), }
                          \StringTok{\textquotesingle{}time\_structuredness\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}time\_structured\textquotesingle{}}\NormalTok{),}
                          \StringTok{\textquotesingle{}spacing\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}time\_inc\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}time\_dec\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}mid\_ext\textquotesingle{}}\NormalTok{),}
                          \StringTok{\textquotesingle{}midpoint\textquotesingle{}} \OtherTok{=} \DecValTok{180}\NormalTok{, }
                          \StringTok{\textquotesingle{}sample\_size\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{1000}\NormalTok{))}

\FunctionTok{tic}\NormalTok{()}
\NormalTok{exp\_2\_data }\OtherTok{\textless{}{-}} \FunctionTok{run\_exp\_simulation}\NormalTok{(}\AttributeTok{factor\_list =}\NormalTok{ factor\_list\_exp\_2, }\AttributeTok{num\_iterations =}\NormalTok{ num\_iterations, }\AttributeTok{pop\_params =}\NormalTok{ pop\_params\_4l, }
                                 \AttributeTok{num\_cores =} \FunctionTok{detectCores}\NormalTok{(), }\AttributeTok{seed =}\NormalTok{ seed)}
\FunctionTok{toc}\NormalTok{()}

\FunctionTok{write\_csv}\NormalTok{(}\AttributeTok{x =}\NormalTok{ exp\_2\_data, }\AttributeTok{file =} \StringTok{\textquotesingle{}Desktop/exp\_2\_data.csv\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Experiment 3 (number measurements, sample size, time structuredness) {-}{-}{-}{-}{-}}
\NormalTok{factor\_list\_exp\_3 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}num\_measurements\textquotesingle{}} \OtherTok{=} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{5}\NormalTok{, }\AttributeTok{to =} \DecValTok{11}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{), }
                          \StringTok{\textquotesingle{}time\_structuredness\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}time\_structured\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}fast\_response\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}slow\_response\textquotesingle{}}\NormalTok{),}
                          \StringTok{\textquotesingle{}spacing\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{), }
                          \StringTok{\textquotesingle{}midpoint\textquotesingle{}} \OtherTok{=} \DecValTok{180}\NormalTok{, }
                          \StringTok{\textquotesingle{}sample\_size\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{1000}\NormalTok{))}
\FunctionTok{tic}\NormalTok{()}
\NormalTok{exp\_3\_data }\OtherTok{\textless{}{-}} \FunctionTok{run\_exp\_simulation}\NormalTok{(}\AttributeTok{factor\_list =}\NormalTok{ factor\_list\_exp\_3, }\AttributeTok{num\_iterations =}\NormalTok{ num\_iterations, }\AttributeTok{pop\_params =}\NormalTok{ pop\_params\_4l, }
                                 \AttributeTok{num\_cores =} \FunctionTok{detectCores}\NormalTok{(), }\AttributeTok{seed =}\NormalTok{ seed)}
\FunctionTok{toc}\NormalTok{()                }

\FunctionTok{write\_csv}\NormalTok{(}\AttributeTok{x =}\NormalTok{ exp\_3\_data, }\AttributeTok{file =} \StringTok{\textquotesingle{}\textasciitilde{}/Desktop/exp\_3\_data.csv\textquotesingle{}}\NormalTok{)}



\CommentTok{\# Experiment 3 (definition variables with slow response rate ) {-}{-}{-}{-}{-}{-}}
\NormalTok{factor\_list\_exp\_def }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}num\_measurements\textquotesingle{}} \OtherTok{=} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{5}\NormalTok{, }\AttributeTok{to =} \DecValTok{11}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{), }
                            \StringTok{\textquotesingle{}time\_structuredness\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}slow\_response\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}spacing\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{), }
                            \StringTok{\textquotesingle{}midpoint\textquotesingle{}} \OtherTok{=} \DecValTok{180}\NormalTok{, }
                            \StringTok{\textquotesingle{}sample\_size\textquotesingle{}} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{1000}\NormalTok{))}
\FunctionTok{tic}\NormalTok{()}
\NormalTok{exp\_3\_def\_data }\OtherTok{\textless{}{-}} \FunctionTok{run\_exp\_simulation}\NormalTok{(}\AttributeTok{factor\_list =}\NormalTok{ factor\_list\_exp\_def, }\AttributeTok{num\_iterations =}\NormalTok{ num\_iterations, }\AttributeTok{pop\_params =}\NormalTok{ pop\_params\_4l, }
                                     \AttributeTok{num\_cores =} \FunctionTok{detectCores}\NormalTok{() }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{seed =}\NormalTok{ seed, }\AttributeTok{definition =}\NormalTok{ T)}
\FunctionTok{toc}\NormalTok{()                }
\CommentTok{\#240734.993 sec elapsed (7 cores used; simulation time increased by roughly a magnitude of 8). }
\FunctionTok{write\_csv}\NormalTok{(}\AttributeTok{x =}\NormalTok{ exp\_3\_def\_data, }\AttributeTok{file =} \StringTok{\textquotesingle{}exp\_3\_def.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\app{Procedure for Generating Measurement Schedules Measurement Schedules}

\label{measurement-schedules}

Given that no procedure existed (to my knowledge) for creating measurement schedules, I devised a method for generating measurement schedules for the four spacing conditions (equal, time-interval increasing, time-interval decreasing, and middle-and-extreme spacing). The code I used to automate the generation of these schedules can be found within the code for the \texttt{compute\_measurement\_schedules()} function for the \texttt{nonlinSims} package (see \url{https://github.com/sciarraseb/nonlinSims}). For each measurement spacing conditions across all measurement number levels, a two-step procedure was employed to generate measurement schedules in Experiments 1 and 2. At a broad level, the first step computes values for setup variables and the second step computes the interval lengths.

\secapp{Procedure for Constructing Measurement Schedules With Equal Spacing}

Figure \ref{fig:equal_spacing_schedule} shows how the two-step procedure
is implemented to construct a measurement schedule with equal spacing
and five measurements. In the first step, the number of intervals (\(NI\))
is computed by subtracting one from the number of measurements (\(NM\)). With five measurements (\(NM = 5\)), there are four intervals (\(NI = 4\)). In the second step, interval lengths are calculated by dividing the length
of the measurement period (\(MP\)) by the number of intervals (\(NI\)),
yielding an interval length of 90 days (\(\frac{MP}{NI} = \frac{360}{4} = 90\)) for each interval and the following measurement days:
\begin{itemize}
\tightlist
\item
  \(m_1\) = day 0
\item
  \(m_2\) = day 90
\item
  \(m_3\) = day 180
\item
  \(m_4\) = day 270
\item
  \(m_5\) = day 360.
\end{itemize}
\secapp{Procedure for Constructing Measurement Schedules With Time-Interval Increasing Spacing}

\label{time-inc-proc}

Figure \ref{fig:time_inc_diagram} shows how the two-step procedure is implemented to construct a measurement schedule with time-interval increasing spacing and five measurements. In the first step, the number of intervals (\(NI\)) is computed by subtracting one from the number of measurements (\(NM\)). With five measurements (\(NM = 5\)), there are four intervals
\begin{apaFigure}
[landscape]
[samepage]
{Procedure for Computing Measurement Schedules With Equal Spacing}
{equal_spacing_schedule}
{0.90}
{Figures/equal_spacing_schedule}
{In Step 1, setup variables are calculated. With five measurements ($NM = 5$), there are four intervals ($NI = 4$). In Step 2, interval lengths are calculated by dividing the length of the measurement period ($MP$) by the number of intervals ($NI$), yielding an interval length of 90 days ($\frac{MP}{NI} = \frac{360}{4} = 90$) for each interval.}
\end{apaFigure}
\noindent (\(NI = 4\)). Because interval lengths increase over time, I decided that intervals would increase by an integer multiple of a constant length (\(c\)) after each measurement day (\(m_i\)) according to the function shown below in Equation \ref{eq:constant-length}:
\begin{align}
\text{Constant-length increment} = \sum^{NI - 1}_{x=0} xc, 
  \label{eq:constant-length} 
\end{align}
where \(x\) represents the integer multiple that increases by 1 after each measurement day. Importantly, to calculate the constant-length increment (\(c\)) by which interval lengths increase over time, it is important to realize that two terms contribute to the length of any interval: A shortest-interval length (\(s\)) and a constant-length value (\(c\)), as shown below in Equation \ref{eq:time-inc-interval-length}:
\begin{align}
\text{Interval length} = s + \sum^{NI - 1}_{x=0} xc. 
  \label{eq:time-inc-interval-length} 
\end{align}
\noindent Because the shortest-interval length (\(s\)) contributes to the length of each interval--in this example, four intervals---then the sum of these lengths can be subtracted from the measurement period length of 360 days (\(MP = 360\)). In the current example with five measurements, 240 days remain (\(r = 240\)) after subtracting the days needed for the shortest-interval lengths (see Equation \ref{eq:eq-remaining}).
\begin{align}
\text{Remaining days (} \textit{r})  = MP - (NI)s = 360 - (30)4 = 240 \text{ days}
  \label{eq:eq-remaining} 
\end{align}
\noindent Having computed the number of remaining days, the constant-length value (\(c\)) can then be obtained by dividing the number of remaining days by the number of constant-value interval lengths (\(c_i\)), as shown below in Equation \ref{eq:eq-constant}:
\begin{align}
\text{Constant-value interval length(} \textit{c}\text{)} = \frac{r}{\sum^{NI - 2}_{i = 0}i} = \frac{240}{3 + 2 + 1} = \text{40 days}
  \label{eq:eq-constant} 
\end{align}
\noindent Therefore, having computed the value for \(c\), the following interval lengths are obtained:
\begin{itemize}
\tightlist
\item
  \(i_{1} = s + 0(c) = 30 + 0(30)\) = 30 days
\item
  \(i_{2} = s + 1(c) = 30 + 1(40)\) = 70 days
\item
  \(i_{3} = s + 0(c) = 30 + 2(40)\) = 110 days
\item
  \(i_{4} = s + 0(c) = 30 + 3(40)\) = 150 days
\end{itemize}
\noindent and the following measurement days are obtained:
\begin{itemize}
\tightlist
\item
  \(m_1\) = day 0
\item
  \(m_2\) = day 30
\item
  \(m_3\) = day 100
\item
  \(m_4\) = day 210
\item
  \(m_5\) = day 360.
\end{itemize}
\secapp{Procedure for Constructing Measurement Schedules With Time-Interval Decreasing Spacing}

Figure \ref{fig:time_dec_diagram} shows how the two-step procedure
is implemented to construct a measurement schedule with time-interval decreasing spacing and five measurements. Because the procedure for calculating time-decreasing intervals simply requires that the order of time-interval increasing intervals are reversed, the procedure is, thus, essentially identical to the procedure shown in the \protect\hyperlink{time-inc-proc}{previous section}. Therefore, with five measurements, time-interval decreasing spacing produces the following intervals:
\begin{apaFigure}
[landscape]
[samepage]
{Procedure for Computing Measurement Schedules With Time-Interval Increasing Spacing}
{time_inc_diagram}
{0.65}
{Figures/time_inc_schedule}
{In Step 1, setup variables are calculated. With five measurements ($NM = 5$), there are four intervals ($NI = 4$). In Step 2, two components contribute to each interval length: A shortest-interval length ($s$) and a constant-length value ($c$), as shown in Equation \ref{eq:time-inc-interval-length}. Because the shortest-interval length ($s$) contributes to each interval, the sum of these lengths can be subtracted from the measurement period length of 360 days ($MP = 360$). In the current example with five measurements, 240 days remain ($r = 240$) after subtracting the days needed for the shortest-interval lengths (see Equation \ref{eq:eq-remaining}). To calculate the constant-length value ($c$), the remaining days ($r$) are divided by the number of constant-value interval lengths ($c_i$), as shown in Equation \ref{eq:eq-constant}.}
\end{apaFigure}
\begin{itemize}
\tightlist
\item
  \(i_{1} = s + 0(c) = 30 + 3(40)\) = 150 days
\item
  \(i_{2} = s + 0(c) = 30 + 2(40)\) = 110 days
\item
  \(i_{3} = s + 1(c) = 30 + 1(40)\) = 70 days
\item
  \(i_{4} = s + 0(c) = 30 + 0(30)\) = 30 days
\end{itemize}
\noindent and the following measurement days are obtained:
\begin{itemize}
\tightlist
\item
  \(m_1\) = day 0
\item
  \(m_2\) = day 150
\item
  \(m_3\) = day 260
\item
  \(m_4\) = day 330
\item
  \(m_5\) = day 360.
\end{itemize}
\secapp{Procedure for Constructing Measurement Schedules With Middle-and-Extreme Spacing}

Figure \ref{fig:mid_ext_diagram} shows how the two-step procedure is implemented to construct a measurement schedule with middle-and-extreme spacing and five measurements. In the first step, the number of intervals (\(NI\)) is computed by subtracting one from the number of measurements (\(NM\)). With five measurements (\(NM = 5\)), there are four intervals (\(NI = 4\)). Importantly, because middle-and-extreme spacing places measurements near the extremities and the middle of the measurement window, the number of measurements in both these sections must also be calculated. The number of extreme measurements is first calculated by dividing the number of measurements by 3 and taking the floor (i.e., rounded-down value {[}\(\lfloor x\rfloor\){]}) of this value and multiplying it by 2, as shown below in Equation \ref{eq:extreme}:
\begin{apaFigure}
[landscape]
[samepage]
{Procedure for Computing Measurement Schedules With Time-Interval Decreasing Spacing}
{time_dec_diagram}
{0.65}
{Figures/time_dec_schedule}
{In Step 1, setup variables are calculated. With five measurements ($NM = 5$), there are four intervals ($NI = 4$). In Step 2, two components contribute to each interval length: A shortest-interval length ($s$) and a constant-length value ($c$), as shown in Equation \ref{eq:time-inc-interval-length}. Because the shortest-interval length ($s$) contributes to each interval, the sum of these lengths can be subtracted from the measurement period length of 360 days ($MP = 360$). In the current example with five measurements, 240 days remain ($r = 240$) after subtracting the days needed for the shortest-interval lengths (see Equation \ref{eq:eq-remaining}). To calculate the constant-length value ($c$), the remaining days ($r$) are divided by the number of constant-value interval lengths ($c_i$), as shown in Equation \ref{eq:eq-constant}.}
\end{apaFigure}
\begin{align}
\text{Number of extreme measurements(} \textit{ex}\text{)} = 2\lfloor\frac{NM}{3}\rfloor = 2\lfloor\frac{5}{3}\rfloor = 2.
  \label{eq:extreme} 
\end{align}
\noindent The number of middle measurements can then be calculated by subtracting the number of extreme measurements (\(ex\)) from the number of measurements (\(NM\)), as shown below in Equation \ref{eq:middle}:
\begin{align}
\text{Number of middle measurements(} \textit{mi}\text{)} = NM - ex = 5 - 2 = 3.
  \label{eq:middle} 
\end{align}
In Step 2, interval lengths are calculated. For middle-and-extreme spacing, there are two types of interval lengths: 1) Intervals separating either two middle or two extreme measurements and 2) intervals separating one middle and one extreme measurement. Intervals separating two middle or two extreme measurements (\(w_i\)) are set to the shortest-interval length (\(s\)), which I set to be 30 days (\(w_i = s = 30\)). Intervals separating one middle and one extreme measurement (\(b_i\)) are set to the sum of two components: 1) A shortest-interval length (\(s\)) and a 2) constant-value interval length (\(c\)), as shown below in Equation \ref{eq:middle}:
\begin{align}
b_i = s + c.
  \label{eq:middle} 
\end{align}
\noindent To obtain the constant-value interval length (\(c\)), the sum of shortest-value interval lengths (\(s\)) is subtracted from the measurement period of 360 days (\(MP = 360\)). In the current example with five measurements, 240 days remain (\(r = 240\)) after subtracting the days needed for the shortest-interval lengths (see Equation \ref{eq:eq-remaining-mid}).
\begin{align}
\text{Remaining days (} \textit{r})  = MP - (NI)s = 360 - (30)4 = 240 \text{ days}
  \label{eq:eq-remaining-mid} 
\end{align}
\noindent Having computed the number of remaining days, the constant-length value (\(c\)) can then be obtained by dividing the number of remaining days by the number of intervals separating middle and extreme measurements, which will always be 2, as shown below in Equation \ref{eq:eq-constant-mid}:
\begin{align}
\text{Constant-value interval length(} \textit{c}\text{)} = \frac{r}{2} = \frac{240}{2} = \text{120 days}
  \label{eq:eq-constant-mid} 
\end{align}
\noindent Therefore, having computed the value for \(c\), the following interval lengths are obtained:
\begin{itemize}
\tightlist
\item
  \(b_{1} = s + c = 30 + 120\) = 150 days
\item
  \(w_{1} = s = 30\) = 30 days
\item
  \(w_{2} = s = 30\) = 30 days
\item
  \(b_{2} = s + c = 30 + 120\) = 150 days
\end{itemize}
\noindent and the following measurement days are obtained:
\begin{itemize}
\tightlist
\item
  \(m_1\) = day 0
\item
  \(m_2\) = day 150
\item
  \(m_3\) = day 180
\item
  \(m_4\) = day 21
\item
  \(m_5\) = day 360.
\end{itemize}
\begin{apaFigure}
[landscape]
[samepage]
[0cm]
{Procedure for Computing Measurement Schedules With Middle-and-Extreme Spacing}
{mid_ext_diagram}
{0.65}
{Figures/mid_ext_schedule}
{In Step 1, setup variables are calculated. With five measurements ($NM = 5$), there are four intervals ($NI = 4$). Importantly, because middle-and-extreme spacing places measurements near the extremities and the middle of the measurement window, the number of measurements in both these sections must also be calculated. The number of extreme measurements is first calculated by dividing the number of measurements by 3 and taking the taking the floor (i.e., rounded-down value [$\lfloor x\rfloor$]) of this value and multiplying it by 2 (see Equation \ref{eq:extreme}). The number of middle measurements can then be calculated by subtracting the number of extreme measurements ($ex$) from the number of measurements ($NM$; see Equation \ref{eq:middle}). In Step 2, interval lengths are calculated. For middle-and-extreme spacing, there are two types of interval lengths: 1) Intervals separating either two middle or two extreme measurements and 2) intervals separating one middle and one extreme measurement. Intervals separating two middle or two extreme measurements are set to the shortest-interval length ($s$), which I set to be 30 days ($w_i = s = 30$). Intervals separating one middle and one extreme measurement are set to the sum of two components: 1) A shortest-interval length ($s$) and a 2) constant-value interval length ($c$; see Equation \ref{eq:eq-constant-mid}). To obtain the constant-value interval length ($c$), the sum of shortest-value interval lengths ($s$) is subtracted from the measurement period of 360 days ($MP = 360$). In the current example with five measurements, 240 days remain ($r = 240$) after subtracting the days needed for the shortest-interval lengths (see Equation \ref{eq:eq-remaining-mid}). Having computed the number of remaining days, the constant-length value ($c$) can then be obtained by dividing the number of remaining days by the number of intervals separating middle and extreme measurements, which will always be 2 (see Equation \ref{eq:eq-constant-mid}).}
\end{apaFigure}
\app{Using Nonlinear Function in the Structural Equation Modelling Framework}

\label{structured-lgc}
\secapp{Nonlinear Latent Growth Curve Model Used to Analyze Each Generated Data Set}

The sections that follow will first review the framework used to build
latent growth curve models and then explain how nonlinear functions can
be modified to fit into this framework.

\subapp{Brief Review of the Latent Growth Curve Model}

The latent growth curve model proposed by \textcite{meredith1990} is briefly reviewed here \autocite[for a review, see][]{preacher2008}. Consider an example where
data are collected at five time points (\(T = 5\)) from \(p\) people (\(\mathbf{y_p} = [y_1, y_2, y_3, y_4, y_5]\)). A simple model to fit is
one where change over time is defined by a straight line and each person's pattern of change is some variation of this straight line. In
modelling parlance, an intercept-slope model is fit where both the intercept and slope are random effects whose values are allowed to vary for
each person.

To fit a random-effect intercept-slope model, a general linear pattern can first be specified in the \(\mathbf{\Uplambda}\) matrix
shown below in Equation \ref{eq:int-slope-mat}:
\begin{align}
\mathbf{\Uplambda} = 
\begin{bmatrix}
1 & 0 \\ 
1 & 1 \\ 
1 & 2 \\ 
1 & 3 \\
1 & 4 \\
\end{bmatrix}.
 \label{eq:int-slope-mat}
\end{align}
\noindent In each column of \(\mathbf{\Uplambda}\), the effect a parameter is specified over the five time points; that is, \(\mathbf{\Uplambda}\) is a matrix with two columns (one for the intercept and one for the slope parameter) and five rows (one for each time point).\footnote{The columns of $\mathbf{\Uplambda}$ are often called basis curves \parencite{blozis2004} or basis functions \parencites{meredith1990}{browne1993} because each column specifies a particular component of change.} The first column of \(\mathbf{\Uplambda}\) specifies the intercept parameter. Because the effect of the intercept parameter is constant over time, a column of 1s is used to represent its effect. The second column of \(\mathbf{\Uplambda}\) specifies the slope parameter. Because a linear pattern of growth is assumed, the second column contains a series of monotonically increasing integer numbers across the time points and begins with 0. \footnote{The set of numbers specified for the slope starts at zero because there is presumably no effect of any variable at the first time point.}

To specify the intercept and slope parameters as random effects that vary across people, a weight can be applied to each column of
\(\mathbf{\Uplambda}\) and each weight can vary across people. That is, a \(p\) person's pattern of change can be reproduced with a unique set of weights in \(\mathbf{\upiota_p}\) that determines the extent to which each basis column of \(\mathbf{\Uplambda}\) contributes to the person's observed change over time. By allowing the weights for the intercept and slope parameters to vary across people, variability can be estimated in these parameters. Discrepancies between the values predicted by \(\mathbf{\Uplambda\upiota_p}\) and a person's observed scores across all
five time points are stored in an error vector \(\mathbf{\mathcal{E}_p}\). Thus, a person's observed data (\(\mathbf{y_p}\)) is
reproduced using the function shown below in Equation \ref{eq:sem-framework}:
\begin{align}
 y_p = \mathbf{\Uplambda\upiota_p} + \mathbf{\mathcal{E}_p}.
 \label{eq:sem-framework}
\end{align}
\noindent Note that Equation \ref{eq:sem-framework} defines the general structural equation modelling framework.

\subapp{Fitting a Nonlinear Function in the Structural Equation Modelling Framework}

Unfortunately, the logistic function of Equation \ref{eq:logFunction-generation}---where each parameter is estimated as a fixed- and random-effect---cannot be directly used in a latent growth curve model because it violates the linear nature of the structural equation modelling framework (Equation \ref{eq:sem-framework}). Structural equation models only permit linear combinations---specifically, the products of matrix-vector and/or matrix-matrix multiplication---and so directly fitting a nonlinear function such as the logistic function in Equation \ref{eq:logFunction-generation} is not possible.

One solution to fitting the logistic function within the structural equation modelling framework is to implement the structured latent curve modelling approach \autocites{browne1991,browne1993}[for an excellent review, see][]{preacher2015}. Briefly, the structured latent curve modelling approach constructs a Taylor series approximation of a nonlinear function so that the nonlinear function can be fit into the structural equation modelling framework (Equation \ref{eq:sem-framework}). The sections that follow will present the structured latent curve modelling approach in four parts such that 1) Taylor series approximations will first be reviewed, 2) a Taylor series approximation will then be constructed for the logistic function, 3) the logistic Taylor series approximation will be modified and fit into the structural equation modelling framework, and 4) the process of parameter estimation will be reviewed.

\subsubapp{Taylor Series': Approximations of Linear Functions}

A Taylor series uses derivative information of a nonlinear function to
construct a linear function that is an approximation of the nonlinear function.\footnote{Linear functions are
defined as functions where no parameter exists within its own partial
derivative (at any order). For example, none of the parameters in the polynomial
equation of $y = a + bt + ct^2 + dt^3$ exist within their own partial
derivative: $\frac{\partial y}{\partial a} = 1$,
$\frac{\partial y}{\partial b} = t$,
$\frac{\partial y}{\partial c} = t^2$, and
$\frac{\partial y}{\partial d} = t^3$. Conversely, the logistic function
is nonlinear because $\upbeta$ and $\upgamma$ exist in their own
partial derivatives. For example, the derivative of the logistic function  $y = \uptheta + \frac{\upalpha - \uptheta}{1 + e^{\frac{\upbeta - t}{\upgamma}}} $with respect to $\upbeta$ is $\frac{(\uptheta - \upalpha) (e^{\frac{\upbeta - t}{\upgamma}})(\frac{1}{\upgamma})}{1 + (e^{\frac{\upbeta - t}{\upgamma}})^2}$and so is nonlinear because it contains $\upbeta$.} Equation \ref{eq:taylor} shows the general formula for a Taylor series such that
\begin{align}
P^N(f(x), a)= \sum^{N}_{n = 0} \frac{f^na}{n !}(x-a)^n,
\label{eq:taylor}
\end{align}
\noindent where \(N\) is the highest derivative order of the function \(f(a)\) that is taken beginning from a zero-value derivative order (\(n=0\)), \(a\) is the point where the Taylor series is derived (i.e., the point of derivation), and \(x\) is the point where the Taylor series is evaluated (i.e., the point of evaluation). As an example of a Taylor series, consider the second-order Taylor series of \(f(x) = \cos(x)\). Note that, across the continuum of \(x\) values (i.e., from \(-\infty\) to \(\infty\)), \(\cos(x)\) returns values between -1 and 1 in an oscillatory manner. Computing the second-order Taylor series of \(f(x) = \cos(x)\) yields the following function shown in Equation \ref{eq:example-taylor}:
\begin{align} 
P^2(\cos(x), a) &=  \frac{\frac{\partial^0 \cos(a)}{\partial a^0}}{0!}(x -a)^0 + \frac{\frac{\partial^1 \cos(a)}{\partial a^1}}{1!}(x -a)^1 + \frac{\frac{\partial^2 \cos(a)}{\partial a^2}}{2!} (x -a)^2 \nonumber \\ 
&=  \frac{\cos(0)}{0!}(x -0)^0 - \frac{\sin(0)}{1!}(x -0)^1 - \frac{\cos(0)}{2!}(x -0)^2  \nonumber \\ 
&=  \frac{1}{1}1 - \frac{0}{1}x - \frac{1}{2}x^2  \nonumber \\ 
P^2(\cos(x), 0) &=  1- \frac{1}{2}x^2. 
  \label{eq:example-taylor}
\end{align}
\noindent Importantly, the second-order Taylor series of \(\cos(x)\) shown in Equation \ref{eq:example-taylor} is linear, whereas the function \(\cos(x)\) is not linear. To show that the second-order Taylor series of \(1- \frac{1}{2}x^2\) is linear, we can reformulate it by adding placeholder parameters in front of each term (\(b\) and \(c\)), resulting in the following modified equation of Equation \ref{eq:taylor-modified}:
\begin{align}
P^2_{reform}(\cos(x), a) = b1- c\frac{1}{2}x^2. 
\label{eq:taylor-modified}
\end{align}
\noindent If the partial derivative of \(P^2(\cos(x), a)\) is taken with respect to \(b\) and \(c\), no parameter exists within its own partial derivative, meaning the function is linear (see Equations \ref{eq:taylor-b}--\ref{eq:taylor-c} below).
\begin{align}
\frac{\partial P^2_{reform}(\cos(x), a)}{\partial b} = 1 \text{ and} \label{eq:taylor-b}\\
\frac{\partial P^2_{reform}(\cos(x), c)}{\partial c} = -\frac{1}{2}x^2. \label{eq:taylor-c}
\end{align}
\noindent Conversely, the fourth-order partial derivative of \(\cos(x)\) contains itself (see Equation \ref{eq:cos-four}), and so is a nonlinear function.
\begin{align}
\frac{\partial^4 \cos(x)}{\partial x^4}  = \cos(x).
\label{eq:cos-four} 
\end{align}
\noindent Therefore, Taylor series' can generate linear versions of nonlinear functions by using local derivative information.

Although Taylor series' provide linear versions of nonlinear functions, it is important to emphasize that the linear versions are approximations. More specifically, the second-order Taylor series of \(\cos(x)\)
perfectly estimates \(\cos(x)\) when the point of evaluation \(x\) is set
equal to the point of derivation \(a\), but estimates \(\cos(x)\) with an
increasing amount of error as the difference between \(x\) and \(a\)
increases (see Example \ref{exm:taylor-estimates}). Thus, Taylor series are approximations because they are only locally accurate (i.e., near the point of derivation).
\begin{example}
\protect\hypertarget{exm:taylor-estimates}{}\label{exm:taylor-estimates}Estimates of Taylor series approximation of \(f(x) = \cos(x)\) as the difference between the point of evaluation \(\mathrm{x}\) and the point of derivation \(\mathrm{a}\) increases.

\textup{Taylor series approximation of $\cos(x)$ (specifically, the second-order Taylor series; $P^2[\cos(x), a]$) estimates values that are exactly equal to the values returned by $\cos(x)$ when the point of evaluation (\textit{x}) is set to the point of derivation (\textit{a}). The example below computes the value predicted by the Taylor series approximation of $P^2[\cos(x), a]$ and by $\cos(x)$ when \textit{x} = \textit{a} = 0.}
\begin{align*}
P^2(\cos(x=0), a=0) &= \cos(x=0) \nonumber \\ 
1- \frac{1}{2}x^2 &=  \cos(0) \nonumber \\ 
1- \frac{1}{2}0^2 &=  1 \nonumber \\ 
1- 0 &=  1 \nonumber \\ 
1 &=  1 \nonumber \\ 
\end{align*}
\vspace*{-25mm}

\textup{Taylor series approximation of $\cos(x)$ (specifically, the second-order Taylor series; $P^2[\cos(x), a]$) estimates a value that is approximately equal ($\thickapprox$) to the value returned by $f\cos(x)$ when the difference between the point of evaluation \textit{x} and the point of derivation \textit{a} is small. The example below computes the value predicted by the Taylor series approximation of $P^2[\cos(x), a]$ and by $\cos(x)$ when \textit{x} = 1 and  \textit{a} = 0.}
\begin{align*}
P^2(\cos(x = 1), 0) &\thickapprox \cos(x = 1) \nonumber \\ 
1- \frac{1}{2}x^2 &\thickapprox   \cos(1) \nonumber \\ 
1- \frac{1}{2}1^2 &\thickapprox   0.54 \nonumber \\ 
1- 0.5 &\thickapprox   0.54 \nonumber \\ 
0.5 &\thickapprox 0.54 \nonumber \\ 
\end{align*}
\vspace*{-25mm}

\textup{Taylor series approximation of $f\cos(x)$ (specifically, the second-order Taylor series; $P^2[\cos(x), a]$) estimates a a value that is clearly not equal ($\neq$) to the value returned by $f\cos(x)$ when the difference between the point of evaluation \textit{x} and the point of derivation \textit{a} is large. The example below computes the value predicted by the Taylor series approximation of $P^2[\cos(x), a]$ and by $\cos(x)$ when \textit{x} = 4 and  \textit{a} = 0.}
\begin{align*}
P^2(\cos(x = 4), 0) &\neq \cos(x = 4) \nonumber \\ 
1- \frac{1}{2}x^2 &\neq  \cos(4) \nonumber \\ 
1- \frac{1}{2}4^2 &\neq  -0.65 \nonumber \\ 
1- 16 &\neq  -0.65 \nonumber \\ 
0.5 &\neq  -0.65 \nonumber \\ 
\end{align*}
\vspace*{-25mm}

\noindent \hrulefill
\end{example}
Figure \ref{fig:taylor-vs-nonlin} provides a comprehensive visualization of the of the point conveyed in Example \ref{exm:taylor-estimates} about the accuracy of Taylor series approximations. In Figure \ref{fig:taylor-vs-nonlin}, the values returned by the nonlinear function of \(\cos(x)\) and its second-order Taylor series \(P^2[\cos(x)] = 1- \frac{1}{2}x^2\) are shown. The
second order Taylor series perfectly estimates \(\cos(x)\) when the point
of evaluation (\(x\)) equals the point of derivation (\(a\); \(x = a = 0\)),
but incurs an increasingly large amount of error as the difference
between the point of evaluation and the point of derivation increases.
For example, at \(x = 10\), \(\cos(10) = -0.84\), but the Taylor series
outputs a value of -49.50 (\(P^2[cos(50)] = 1- \frac{1}{2}10^2 = -49.50\)).
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Estimation Accuracy of Taylor Series Approximation of Nonlinear Function (cos(x))}
{taylor-vs-nonlin}
{0.7}
{Figures/taylor_vs_nonlin}
{The second order Taylor series perfectly estimates $\cos(x)$ when the point of evaluation ($x$) equals the point of derivation ($a$; $x = a = 0$), but incurs an increasingly large amount of error as the difference between the point of evaluation and the point of derivation increases. For example, at $x = 10$, $\cos(x) = -0.84$, but the Taylor series outputs a value of -49.50 ($P^2[cos(50)] = 1- \frac{1}{2}10^2 = -49.50$).}
\end{apaFigure}
\subsubapp{Taylor Series of the Logistic Function}

Given that the Taylor series provides a linear version of a nonlinear function, the structured latent curve modelling approach uses Taylor series' to fit nonlinear functions into the linear nature of the structural equation modelling framework \autocite{browne1991,browne1993}. In the current simulations, the logistic function was used to generate data (see Equation \ref{eq:logistic}), and so a Taylor series approximation was constructed for the logistic function in the analysis. Note that, because the logistic function had four parameters (\(\uptheta\), \(\upalpha\), \(\upbeta\), \(\upgamma\)), partial derivatives were computed with respect to each of the parameters. Using a derivative order set to one
(\(n = 1\)), the following Taylor series was constructed for the logistic
function (Equation \ref{eq:logistic-approx}):
\begin{align}
 P^1(L(\Uptheta, t)) = L + \frac{\partial L}{\partial \uptheta}(x_{\uptheta}-a_{\uptheta})^1 + \frac{\partial L}{\partial \upalpha}(x_{\upalpha}-a_{\upalpha})^1 + \frac{\partial L}{\partial \upbeta}(x_{\upbeta}-a_{\upbeta})^1 + \frac{\partial L}{\partial \upgamma_{\upgamma}}(x_{\upgamma}-a_{\upgamma})^1, 
\label{eq:logistic-approx}
\end{align}
\noindent where \(\mathbf{L(\Uptheta, t)}\) represents the logistic function shown below in
Equation \ref{eq:logistic}:
\begin{align}
  \mathbf{L(\Uptheta, t)} = \uptheta + \frac{\upalpha - \uptheta}{{1 + e^\frac{\upbeta - t}{\upgamma}}} + \upepsilon, 
\label{eq:logistic}
\end{align}
\noindent with \(\mathbf{\Uptheta} = [\uptheta, \upalpha, \upbeta, \upgamma]\) and \(\mathbf{L(\Uptheta, t)}\) being a vector of scores across all \(\mathbf{t}\) time points. Because each parameter of the logistic function has a unique meaning (see section on \protect\hyperlink{data-generation}{data generation}), they are unlikely to have the same population value, and so the derivation (\(a\)) will, therefore, differ for each parameter. To set the derivation values (\(a\)), the mean values estimated by the structured latent growth curve model for each parameter (i.e., fixed-effect values) are used, meaning that each derivation value in Equation \ref{eq:logistic-approx} is replaced with a model estimate as shown below:
\begin{itemize}
\tightlist
\item
  \(a_{\uptheta} = \hat{\uptheta}\)
\item
  \(a_{\upalpha} = \hat{\upalpha}\)
\item
  \(a_{\upbeta} = \hat{\upbeta}\)
\item
  \(a_{\upgamma} = \hat{\upgamma}\)
\end{itemize}
\noindent where a caret (\(\hat{\phantom{\beta}}\)) denotes a parameter value that is estimated by the analysis. In order to compute curves for each \(p\) person, evaluation points for each parameter (\(x_{\uptheta}\), \(x_{\upalpha}\), \(x_{\upbeta}\), \(x_{\upgamma}\)) are set to the value computed for a given person (\(\uptheta_p\), \(\upalpha_p\), \(\upbeta_p\), \(\upgamma_p\)). Thus, each evaluation value in Equation \ref{eq:logistic-approx} is replaced with a person-specfic value as shown below:
\begin{itemize}
\tightlist
\item
  \(x_{\uptheta} = \uptheta_p\)
\item
  \(x_{\upalpha} = \upalpha_p\)
\item
  \(x_{\upbeta} = \upbeta_p\)
\item
  \(x_{\upgamma} = \upgamma_p\).
\end{itemize}
\noindent Substituting the above values for the derivation and evaluation values of \(x\) and \(a\) in the initial logistic Taylor series (Equation \ref{eq:logistic-approx}) yields the following function (Equation \ref{eq:taylor-full}):
\begin{align}
 P^1(L(\Uptheta, t)) = L(\Uptheta, t) + \frac{\partial L}{\partial \uptheta}(\uptheta_p-\hat{\uptheta})^1 + \frac{\partial L}{\partial \upalpha}(\upalpha_p-\hat{\upalpha})^1 + \frac{\partial L}{\partial \upbeta}(\upbeta_p-\hat{\upbeta})^1 + \frac{\partial L}{\partial \upgamma}(\upgamma_p-\hat{\upbeta})^1.
\label{eq:taylor-full}
\end{align}
Two important points about Equation \ref{eq:logistic-approx} deserve mentioning. First, the average population logistic curve (i.e., the fixed-effect parameter values) will have a perfect logistic function shape. In estimating the average population logistic curve, the evaluation values (\(x\)) are set equal to the derivation value counterparts (\(a\)); that is, each mean value estimated for a parameter (\(\hat{\uptheta}\), \(\hat{\upalpha}\), \(\hat{\upbeta}\), \(\hat{\upgamma}\)) replaces the corresponding derivation-evaluation pair in Equation \ref{eq:logistic-approx}. Second, it is possible that estimates of random-effect parameters (i.e., variability observed in a parameter's value across people) may be misleading. To compute the values for the random-effect parameters, the evaluation values (\(a\)) are set to the logistic function values needed to compute each \(p\) person's observed curve (\(\uptheta_p\), \(\upalpha_p\), \(\upbeta_p\), \(\upgamma_p\)). Because Taylor series approximations are only locally accurate, the curves computed for individuals can accommodate shapes that do not resemble a logistic (i.e., s-shaped) pattern (see Example \ref{exm:taylor-estimates}). Thus, estimates of random-effect parameters (i.e., variability observed in a parameter's value across people) can be influenced by curves that do not have a logistic shape and, therefore, may be misleading.

\subsubapp{Fitting the Logistic Taylor Series Into the Structual Equation Modelling Framework}

With the logistic Taylor series computed in Equation \ref{eq:taylor-full}, it can be fit into the structural equation modelling framework by transforming it from its scalar form (Equation \ref{eq:taylor-full}) into its matrix form (see Equation \ref{eq:taylor-final}). In transforming the scalar form of the logistic Taylor series into a matrix form, three steps will be completed, with each step transforming a component of the scalar form into a matrix representation. The paragraphs that follow detail each of these three steps.

First, the partial derivative information must be transformed into their matrix form. The matrix \(\mathbf{\Uplambda}\) shown below contains the partial derivative information presented in the scalar Taylor series function (see Equation \ref{eq:taylor-full}):\footnote{This is also known as a Jacobian matrix.}

\[ 
\mathbf{\Uplambda} = 
\begin{bmatrix}
\frac{\partial L(\Uptheta, t_1)}{\partial \uptheta} & \frac{\partial L(\Uptheta, t_1)}{\partial \upalpha}  &  \frac{\partial L(\Uptheta, t_1)}{\partial \upbeta} & \frac{\partial L(\Uptheta, t_1)}{\partial \upgamma}   \\ 
\frac{\partial L(\Uptheta, t_2)}{\partial \uptheta}  & \frac{\partial L(\Uptheta, t_2)}{\partial \upalpha} &  \frac{\partial L(\Uptheta, t_2)}{\partial \upbeta} & \frac{\partial L(\Uptheta, t_2)}{\partial \upgamma} & \\ 
\vdots & \vdots & \vdots & \vdots \\ 
\frac{\partial L(\Uptheta, t_n)}{\partial \uptheta} & \frac{\partial L(\Uptheta, t_n)}{\partial \upalpha}  & \frac{\partial L(\Uptheta, t_n)}{\partial \upbeta} & \frac{\partial L(\Uptheta, t_n)}{\partial \upgamma} \\
\end{bmatrix}.
\]

\noindent As in the structural equation modelling framework (see Equation \ref{eq:sem-framework}) where each column of \(\mathbf{\Uplambda}\) specifies a basis curve (i.e., loadings of a growth parameter onto all time points that specify the effect of the parameter over time), each column of \(\mathbf{\Uplambda}\) in the structured latent curve modelling approach similarly contains the loadings of a logistic function parameter across all the \(n\) time points, but the loading values are now determined by the partial derivative of the logistic function with respect to that parameter.

Second, the difference between the evaluation and derivation values (\(x - a\)) must be transformed into their matrix form. As a reminder, the difference between the evaluation and derivation values is needed so that person-specific curves can be computed. Thus, the difference between the evaluation and derivation values can be conceptualized as person-specific deviation. The vector \(\mathbf{\upiota_p}\) contains the person-specific deviations (e.g., \(\hat{\uptheta} - \uptheta_p\)) from each mean estimated parameter value as shown below:

\[ 
\mathbf{\upiota_p} = 
\begin{bmatrix}
\hat{\uptheta} - \uptheta_p   \\ 
\hat{\upalpha} - \upalpha_p   \\ 
\hat{\upbeta} - \upbeta_p \\ 
\hat{\upgamma_i} - \upgamma_p \\
\end{bmatrix},
\]

\noindent where a caret (\(\hat{\phantom{\beta}}\)) denotes the mean value estimated
for a given parameter and a subscript \(p\) indicates a parameter value
computed for a person.

With a matrix of logistic function loadings (\(\mathbf{\Uplambda}\)) and the vector of person-specific deviations (\(\mathbf{\upiota_p}\)), person-specific deviations can be computed for each basis column of \(\mathbf{\Uplambda}\). Specifically, the person-specific basis column deviations can be computed by post-multiplying the matrix of loadings (\(\mathbf{\Uplambda}\)) by the vector of person-specific deviations (\(\mathbf{\upiota_p}\)), as shown below in Equation \ref{eq:person-weights}:
\begin{align}
 \text{Basis column deviations}_p = \mathbf{\Uplambda\upiota_p}.
 \label{eq:person-weights}
\end{align}
\noindent Because \(\mathbf{\Uplambda\upiota_p}\) only provides the extent to which each person's curve deviates from the average curve (\(\mathbf{L(\Uptheta, t)}\)), it cannot alone be used to compute person-specfic curves. To compute person-specific curves (\(\mathbf{y_p}\)), the average logistic curve must be added to Equation \ref{eq:person-weights}, as shown below in Equation \ref{eq:slcm-nonsem}:
\begin{align}
 \mathbf{y_p} = \mathbf{L(\Uptheta, t)} + \mathbf{\Uplambda\upiota_p} + \mathbf{\mathcal{E}_p}.
 \label{eq:slcm-nonsem}
\end{align}
\noindent Unfortunately, the logistic function (\(\mathbf{L(\Uptheta, t)}\)) in the above expression (Equation \ref{eq:slcm-nonsem}) is simply the original logistic function (see Equation \ref{eq:logistic}), and so Equation \ref{eq:slcm-nonsem} above is nonlinear. Because Equation \ref{eq:slcm-nonsem} is nonlinear, it cannot be inserted in the structural equation modelling framework, which requires a linear function (see Equation \ref{eq:sem-framework}). Thus, the logistic function term in Equation \ref{eq:slcm-nonsem} (\(\mathbf{L(\Uptheta, t)}\)) must be linearized so that the logistic Taylor series can be used in the structural equation modelling framework.

Third, and last, the logistic function component (\(\mathbf{L(\Uptheta, t)}\)) must be linearized. By taking advantage of some clever linear algebra, the logistic function component can be rewritten as the product of the partial derivative matrix (\(\mathbf{\Uplambda}\)) and a mean vector \autocites[\(\mathbf{\uptau}\);][]{shapiro1987,browne1993} as shown below in Equation \ref{eq:logistic-matrix-vector}:
\begin{align}
 \mathbf{L(\Uptheta, t)} = \mathbf{\Lambda\uptau}.
\label{eq:logistic-matrix-vector}
\end{align}
\noindent Importantly, the values of the mean vector \(\mathbf{\uptau}\) need to be determined so that a linear representation of the logistic function can be created. Example \ref{exm:tau-vector} below solves for the mean vector (\(\mathbf{\uptau}\)) and shows that the values obtained for the linear parameters (i.e., \(\uptheta\) and \(\upalpha\)) constitute the mean values estimated by the analysis (i.e., the fixed-effect values) and zeroes are obtained for the nonlinear parameters (i.e., \(\uptheta\) and \(\upalpha\)). Given that the vector \(\mathbf{\uptau}\) contains mean estimated values, it is often called the mean vector \autocite{blozis2004,preacher2015}.
\begin{example}
\protect\hypertarget{exm:tau-vector}{}\label{exm:tau-vector}Computation of mean vector \(\mathbf{\uptau}\).

\noindent \textup{Given the parameter estimates of $\hat{\uptheta} = 3.00$, $\hat{\upalpha} = 3.32$, $\hat{\upbeta} = 180.00$, and $\hat{\upgamma} = 20.00$ and $\mathbf{t}$ = [0, 1, 2, 3], $\mathbf{\uptau}$ = [3.00, 3.32, 0, 0], then }
\begin{align*}
\mathbf{L(\Uptheta, t)} &= \mathbf{\Lambda\uptau} \\ 
[3.00, 3.02, 3.30, 3.32] &= \begin{bmatrix}
1.00 & 0.00 & 0.00  & 0.00 \\ 
0.95  & 0.05 & -0.00 & 0.00 \\ 
0.05 & 0.95 & -0.00 & -0.00 \\ 
0.00 & 1.00  & 0.00 & 0.00 \\
\end{bmatrix} \mathbf{\uptau} \\ 
\begin{bmatrix}
1.00 & 0.00 & 0.00  & 0.00 \\ 
0.95  & 0.05 & -0.00 & 0.00 \\ 
0.05 & 0.95 & -0.00 & -0.00 \\ 
0.00 & 1.00  & 0.00 & 0.00 \\
\end{bmatrix}^{-1}
\begin{bmatrix} 
3.00 \\ 3.02 \\ 3.30 \\ 3.32
\end{bmatrix} &=  \mathbf{\Lambda\uptau} \\ 
 \mathbf{\uptau} &= [3.00, 3.32, 0, 0]\\
\end{align*}
\vspace*{-25mm}

\noindent \hrulefill
\end{example}
With \(\mathbf{L(\Uptheta, t)} = \mathbf{\Uplambda\uptau}\), Equation \ref{eq:slcm-nonsem} can be rewritten in a linear equation as shown below in Equation \ref{eq:taylor-linear}:
\begin{align}
 \mathbf{y_p} = \mathbf{\Uplambda\uptau} + \mathbf{\Uplambda\upiota_p} + \mathbf{\mathcal{E}_p}.
 \label{eq:taylor-linear}
 \end{align}
\noindent Two important points should be made about Equation \ref{eq:taylor-linear}. First, with some algebraic modification, it can be shown to have the exact same form as the general structural equation modelling framework (see Equation \ref{eq:sem-framework}) that expresses a person's score (\(y_p\)) as the sum of a loading matrix (\(\mathbf{\Uplambda}\)) post-multiplied by a vector of person-specific deviations (\(\upiota_p\)) and an error vector (\(\mathbf{\mathcal{E}_p}\)). To show the equivalence between Equation \ref{eq:taylor-linear} and Equation \ref{eq:sem-framework}, the mean vector \(\mathbf{\uptau}\) and vector of person-specific deviations \(\mathbf{\upiota_p}\) can be combined into a new vector \(\mathbf{s_p}\) that, like the product of \(\mathbf{\Lambda\uptau}\) (see Equation \ref{eq:logistic-matrix-vector}), also represents the person-specific weights applied to the basis curves in \(\mathbf{\Uplambda}\) such that

\[  
\mathbf{s_p} = \mathbf{\uptau + \upiota_p} =
\begin{bmatrix} 
\hat{\uptheta} + \hat{\uptheta} - \uptheta_p \\ 
\hat{\upalpha} + \hat{\upalpha} - \upalpha_p \\ 
0 + \hat{\upbeta} - \upbeta_p \\ 
0 + \hat{\upgamma} - \upgamma_p \\
\end{bmatrix},
\]

\noindent which allows Equation \ref{eq:taylor-linear} to be reexpressed in Equation \ref{eq:taylor-final} below and, thus, take on the exact same form as the general structural equation modelling framework (see Equation \ref{eq:sem-framework})
\begin{align}
\mathbf{y_p} = \mathbf{\Uplambda s_p} + \mathbf{\mathcal{E}_p}.
\label{eq:taylor-final}
\end{align}
Second, the logistic Taylor series shown in Equation \ref{eq:taylor-linear} reproduces the nonlinear logistic function. Because the expected value of the person-specific weights (\(\mathbf{s_p}\)) is the mean vector (\(\mathbf{\uptau}\);
\(\mathbb{E}[{\mathbf{s_p}}] = \mathbf{\uptau}\)), the expected set
of scores predicted across all people (\(\mathbb{E}[{\mathbf{y_p}}]\)) gives back the original expression for the logistic function matrix-vector product in Equation \ref{eq:logistic-matrix-vector} as shown below in Equation \ref{eq:expected-value}:
\begin{align}
 \mathbb{E}[{\mathbf{y_p}}] = \mathbf{\Uplambda\uptau} = \mathbf{L(\Uptheta, t)}. 
\label{eq:expected-value}
\end{align}
\noindent Therefore, the structured latent curve modelling approach
successfully reproduces the output of the nonlinear logistic function
(Equation \ref{eq:logistic}) with the linear function of Equation
\ref{eq:taylor-final}. Note that that no error term exists in Equation \ref{eq:expected-value} because the expected value of the error
values is zero (\(\mathbb{E}[{\mathbf{\mathcal{E}_p}}] = 0\)).

\subsubapp{Estimating Parameters in the Structured Latent Curve Modelling Approach}

To estimate the parameter values, the full-information maximum
likelihood shown in Equation \ref{eq:fiml-person} is computed for each
person (i.e., likelihood of observing a \(p\) person's data given the
estimated parameter values):
\begin{align}
\mathcal{L}_p = k_p \ln(2\pi) + \ln(|\mathbf{\Sigma_p}| + (\mathbf{y_p} - \mathbf{\upmu_p})^\top \mathbf{\Sigma_p}^{-1}(\mathbf{y_p} - \mathbf{\upmu_p}),
\label{eq:fiml-person}
\end{align}
\noindent where \(k_p\) is the number of non-missing values for a given
\(p\) person, \(\mathbf{\Sigma_p}\) is the model-implied covariance matrix
with rows and columns filtered at time points where person \(p\) has
missing data, \(\mathbf{y_p}\) is a vector containing the data points collected for a \(p\) person (i.e., filtered data), and
\(\mathbf{\upmu_p}\) is the model-implied mean vector that is filtered at
time points where person \(p\) has missing data. Note that, because all
my simulations assumed complete data across all times points, no filtering
procedures were executed \autocite[for a review of the filtering procedure, see][Chapter 5]{boker2020}. Thus, computing the above full-information
maximum likelihood in Equation \ref{eq:fiml-person} is equivalent to
computing the below likelihood function in Equation
\ref{eq:ml-estimation}:
\begin{align}
\mathcal{L}_p = k_p \ln(2\pi) + \ln(|\mathbf{\Sigma}| + (\mathbf{y_p} - \mathbf{\upmu})^\top \mathbf{\Sigma}^{-1}(\mathbf{y_p} - \mathbf{\upmu}),  
\label{eq:ml-estimation}
\end{align}
\noindent where \(\mathbf{\Sigma}\) is the model-implied covariance matrix,
\(\mathbf{y_p}\) contains the data collected from a \(p\) person, and
\(\mathbf{\upmu}\) is the model-implied mean vector. The model-implied
covariance matrix \(\mathbf{\Sigma}\) is computed using Equation
\ref{eq:covariance} below:
\begin{align}
\mathbf{\Sigma} = \mathbf{\Uplambda\Uppsi\Uplambda} + \mathbf{\Upomega}_{\mathcal{E}},   
\label{eq:covariance}
\end{align}
\noindent where \(\mathbf{\Uppsi}\) is the random-effect covariance matrix
and \(\mathbf{\Upomega}_{\mathcal{E}}\) contains the error variances at
each time point. The mean vector \(\mathbf{\upmu}\) is computed using
Equation \ref{eq:mean-structure} shown below:
\begin{align}
\mathbf{\upmu} = \mathbf{\Uplambda\uptau}. 
\label{eq:mean-structure}
\end{align}
\noindent Parameter estimation is conducted by finding values for the model-implied
covariance matrix \(\mathbf{\Sigma}\) and the model-implied mean vector
\(\mathbf{\upmu}\) that maximizes the sum of log-likelihoods across all \(P\) people
(see Equation \ref{eq:max-ll} below):
\begin{align}
\mathcal{L} = \underset{\mathbf{\Sigma},\mathbf{\upmu} }{\argmax} \sum^P_{p = 1} \mathcal{L}_p.
\label{eq:max-ll}
\end{align}
\noindent In OpenMx, the above problem is solved using the sequential
least squares quadratic program \autocite[for a review, see][]{kraft1994}.

\app{OpenMx Code for Structured Latent Growth Curve Model Used in Simulation Experiments}

\label{structured-lgc-code}

The code that I used to model logistic pattern of change (see \protect\hyperlink{data-generation}{data generation}) is shown in Code Block \ref{structured-model}. Note that, the code is largely excerpted from the \texttt{run\_exp\_simulations()} and \texttt{create\_logistic\_model\_ns()} functions from the \texttt{nonlinSims} package, and so readers interested in obtaining more information should consult the source code of this package. One important point to mention is that the model specified in Code Block \ref{structured-model} assumes time-structured data.

\captionof{chunk}{OpenMx Code for Structured Latent Growth Curve Model That Assumes Time-Structured Data}\restoreparindent\label{structured-model}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{\#Days on which measurements are assumed to be taken (note that model assumes time{-}structured data; that is, at each time point, participants provide data at the exact same moment). The measurement days obtained by finding the unique values in the \textasciigrave{}measurement\_day\textasciigrave{} column of the generated data set. }
\NormalTok{measurement\_days }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{measurement\_day) }

\CommentTok{\#Manifest variable names (i.e., names of columns containing data at each time point,}
\NormalTok{manifest\_vars }\OtherTok{\textless{}{-}}\NormalTok{ nonlinSims}\SpecialCharTok{:::}\FunctionTok{extract\_manifest\_var\_names}\NormalTok{(}\AttributeTok{data\_wide =}\NormalTok{ data\_wide)}

\CommentTok{\#Now convert data to wide format (needed for OpenMx)}
\NormalTok{data\_wide }\OtherTok{\textless{}{-}}\NormalTok{ data[ , }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ measurement\_day, }\AttributeTok{values\_from =} \FunctionTok{c}\NormalTok{(obs\_score, actual\_measurement\_day))}
  
\CommentTok{\#Remove . from column names so that OpenMx does not run into error (this occurs because, with some spacing schedules, measurement days are not integer values.) }
\FunctionTok{names}\NormalTok{(data\_wide) }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace}\NormalTok{(}\AttributeTok{string =} \FunctionTok{names}\NormalTok{(data\_wide), }\AttributeTok{pattern =} \StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.\textquotesingle{}}\NormalTok{, }\AttributeTok{replacement =} \StringTok{\textquotesingle{}\_\textquotesingle{}}\NormalTok{)}

\CommentTok{\#Latent variable names (theta = baseline, alpha = maximal elevation, beta = days{-}to{-}halfway elevation, gamma = triquarter{-}haflway elevation)}
\NormalTok{latent\_vars }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{) }

\NormalTok{latent\_growth\_curve\_model }\OtherTok{\textless{}{-}} \FunctionTok{mxModel}\NormalTok{(}
  \AttributeTok{model =}\NormalTok{ model\_name,}
  \AttributeTok{type =} \StringTok{\textquotesingle{}RAM\textquotesingle{}}\NormalTok{, }\AttributeTok{independent =}\NormalTok{ T,}
  \FunctionTok{mxData}\NormalTok{(}\AttributeTok{observed =}\NormalTok{ data\_wide, }\AttributeTok{type =} \StringTok{\textquotesingle{}raw\textquotesingle{}}\NormalTok{),}
  
  \AttributeTok{manifestVars =}\NormalTok{ manifest\_vars,}
  \AttributeTok{latentVars =}\NormalTok{ latent\_vars,}
  
  \CommentTok{\#Residual variances; by using one label, they are assumed to all be equal (homogeneity of variance). That is, there is no complex error structure. }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =}\NormalTok{ manifest\_vars,}
         \AttributeTok{arrows=}\DecValTok{2}\NormalTok{, }\AttributeTok{free=}\ConstantTok{TRUE}\NormalTok{,  }\AttributeTok{labels=}\StringTok{\textquotesingle{}epsilon\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{),}
  
  \CommentTok{\#Latent variable covariances and variances (note that only the variances are estimated. )}
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =}\NormalTok{ latent\_vars,}
         \AttributeTok{connect=}\StringTok{\textquotesingle{}unique.pairs\textquotesingle{}}\NormalTok{, }\AttributeTok{arrows=}\DecValTok{2}\NormalTok{,}
         \AttributeTok{free =} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{,}\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }
                  \ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }
                  \ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }
                  \ConstantTok{TRUE}\NormalTok{), }
         \AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                  \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                  \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{,}
                  \DecValTok{1}\NormalTok{),}
         \AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\_rand\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_theta\_alpha)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_theta\_beta)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}NA(cov\_theta\_gamma)\textquotesingle{}}\NormalTok{,}
                  \StringTok{\textquotesingle{}alpha\_rand\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}NA(cov\_alpha\_beta)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_alpha\_gamma)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}beta\_rand\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_beta\_gamma)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}gamma\_rand\textquotesingle{}}\NormalTok{), }
         \AttributeTok{lbound =} \FunctionTok{c}\NormalTok{(}\FloatTok{1e{-}3}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \FloatTok{1e{-}3}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{,}
                    \DecValTok{1}\NormalTok{), }
         \AttributeTok{ubound =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{90}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{45}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)),}
  
  \CommentTok{\# Latent variable means (linear parameters). Note that the parameters of beta and gamma do not have estimated means because they are nonlinear parameters (i.e., the logistic function\textquotesingle{}s first{-}order partial derivative with respect to each of those two parameters contains those two parameters. )}
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =} \StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{, }\AttributeTok{to =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{), }\AttributeTok{free =} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{), }\AttributeTok{arrows =} \DecValTok{1}\NormalTok{,}
         \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\_fixed\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}alpha\_fixed\textquotesingle{}}\NormalTok{), }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{, }\AttributeTok{ubound =} \DecValTok{7}\NormalTok{, }
         \AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)),}
  
  \CommentTok{\#Functional constraints (needed to estimate mean values of fixed{-}effect parameters)}
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}theta\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{,  }\AttributeTok{ubound =} \DecValTok{7}\NormalTok{), }
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}alpha\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{,  }\AttributeTok{ubound =} \DecValTok{7}\NormalTok{), }
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}beta\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{1}\NormalTok{, }\AttributeTok{ubound =} \DecValTok{360}\NormalTok{),}
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}gamma\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}g\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{1}\NormalTok{, }\AttributeTok{ubound =} \DecValTok{360}\NormalTok{), }

  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{FALSE}\NormalTok{, }
           \AttributeTok{values =}\NormalTok{ measurement\_days, }\AttributeTok{name =} \StringTok{\textquotesingle{}time\textquotesingle{}}\NormalTok{),}
  
  \CommentTok{\#Algebra specifying first{-}order partial derivatives; }
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g)), }\AttributeTok{name=}\StringTok{"Tl"}\NormalTok{),}
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g)), }\AttributeTok{name =} \StringTok{\textquotesingle{}Al\textquotesingle{}}\NormalTok{), }
  
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =} \SpecialCharTok{{-}}\NormalTok{((a }\SpecialCharTok{{-}}\NormalTok{ t) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{g))}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\AttributeTok{name =} \StringTok{\textquotesingle{}Bl\textquotesingle{}}\NormalTok{),}
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =}\NormalTok{  (a }\SpecialCharTok{{-}}\NormalTok{ t) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g) }\SpecialCharTok{*}\NormalTok{ ((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{time)}\SpecialCharTok{/}\NormalTok{g))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}Gl\textquotesingle{}}\NormalTok{),}
  
  \CommentTok{\#Factor loadings; all fixed and, importantly, constrained to change according to their partial derivatives (i.e., nonlinear functions) }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =} \StringTok{\textquotesingle{}theta\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{, }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,  }
         \AttributeTok{labels =} \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Tl[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))),}
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =} \StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{, }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,  }
         \AttributeTok{labels =} \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Al[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))), }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{,  }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,}
         \AttributeTok{labels =}  \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Bl[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))), }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from=}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{,  }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,}
         \AttributeTok{labels =}  \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Gl[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))), }
  
  \CommentTok{\#Fit function used to estimate free parameter values. }
  \FunctionTok{mxFitFunctionML}\NormalTok{(}\AttributeTok{vector =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{)}

\CommentTok{\#Use starting value function from OpenMx to generate good starting values (uses weighted least squares)}
\NormalTok{latent\_growth\_model }\OtherTok{\textless{}{-}} \FunctionTok{mxAutoStart}\NormalTok{(}\AttributeTok{model =}\NormalTok{ latent\_growth\_model)}

\CommentTok{\#Fit model using mxTryHard(). Increases probability of convergence by attempting model convergence by randomly shifting starting values. }
\NormalTok{model\_results }\OtherTok{\textless{}{-}} \FunctionTok{mxTryHard}\NormalTok{(latent\_growth\_model)}
\end{Highlighting}
\end{Shaded}
\app{Complete Versions of Bias/Precision Plots (Day- and Likert-Unit Parameters)}

\label{complete-versions}
\secapp{Experiment 1}
\subapp{Equal Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Equal Spacing in Experiment 1}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_days_equal spacing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Equal Spacing in Experiment 1 (continued)}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_likert_equal spacing}
{Panels A--B:  Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Interval Increasing Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Increasing Spacing in Experiment 1}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_days_time-interval increasing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Increasing Spacing in Experiment 1 (continued)}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_likert_time-interval increasing}
{Panels A--B:  Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Interval Decreasing Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 1}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_days_time-interval decreasing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 1 (continued)}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_likert_time-interval decreasing}
{Panels A--B:  Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Middle-and-Extreme Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Middle-and-Extreme Spacing in Experiment 1}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_days_middle-and-extreme spacing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Middle-and-Extreme Spacing in Experiment 1 (continued)}
{exp1_plot_equal_app}
{0.16}
{Figures/exp1_plot_likert_middle-and-extreme spacing}
{Panels A--B:  Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\secapp{Experiment 2}
\subapp{Equal Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Equal Spacing in Experiment 2}
{exp2_plot_equal_app}
{0.16}
{Figures/exp2_plot_days_equal spacing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Equal Spacing in Experiment 2 (continued)}
{exp2_plot_equal_app}
{0.16}
{Figures/exp2_plot_likert_equal spacing}
{Panels A--B: Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Interval Increasing Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Increasing Spacing in Experiment 2}
{exp2_plot_time_inc_app}
{0.16}
{Figures/exp2_plot_days_time-interval increasing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Increasing Spacing in Experiment 2 (continued)}
{exp2_plot_time_inc_app}
{0.16}
{Figures/exp2_plot_likert_time-interval increasing}
{Panels A--B:  Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Interval Decreasing Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 2}
{exp2_plot_time_dec_app}
{0.16}
{Figures/exp2_plot_days_time-interval decreasing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 2 (continued)}
{exp2_plot_time_dec_app}
{0.16}
{Figures/exp1_plot_likert_time-interval decreasing}
{Panels A--B: Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Middle-and-Extreme Spacing}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Middle-and-Extreme Spacing in Experiment 2}
{exp2_plot_mid_ext_app}
{0.16}
{Figures/exp2_plot_days_middle-and-extreme spacing}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Middle-and-Extreme Spacing in Experiment 2 (continued)}
{exp2_plot_mid_ext_app}
{0.16}
{Figures/exp2_plot_likert_middle-and-extreme spacing}
{Panels A--B:  Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-2} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\secapp{Experiment 3}
\subapp{Time-Structured Data}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Structured Data in Experiment 3}
{exp3_plot_days_time_struc_app}
{0.16}
{Figures/exp3_plot_days_time structured}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Structured Data in Experiment 3 (continued)}
{exp3_plot_days_time_struc_app}
{0.16}
{Figures/exp3_plot_likert_time structured}
{Panels A--B: Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Unstructured Data Characterized by a Fast Response Rate}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Unstructured Data Characterized by a Fast Response Rate in Experiment 3}
{exp3_plot_days_fast_app}
{0.16}
{Figures/exp3_plot_days_time unstructured (fast response)}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Unstructured Data Characterized by a Fast Response Rate in Experiment 3 (continued)}
{exp3_plot_days_fast_app}
{0.16}
{Figures/exp3_plot_likert_time unstructured (fast response)}
{Panels A--B: Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Unstructured Data Characterized by a Slow Response Rate}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Unstructured Data Characterized by a Slow Response Rate in Experiment 3}
{exp3_plot_days_slow_app}
{0.16}
{Figures/exp3_plot_days_time unstructured (slow response)}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters With Time-Unstructured Data Characterized by a Slow Response Rate in Experiment 3 (continued)}
{exp3_plot_days_slow_app}
{0.16}
{Figures/exp3_plot_likert_time unstructured (slow response)}
{Panels A--B: Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter.}
[notrack]
\end{apaFigure}
\subapp{Time-Unstructured Data Characterized by a Slow Response Rate and Modelled with Definition Variables}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters When Using Definition Variables To Model Time-Unstructured Data Characterized by a Slow Response Rate}
{exp3_plot_days_def_app}
{0.165}
{Figures/exp3_defplot_days_time unstructured (slow response)}
{}
\end{apaFigure}
\addtocounter{figure}{-1}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day- and Likert-Unit Parameters When Using Definition Variables To Model Time-Unstructured Data Characterized by a Slow Response Rate (continued)}
{exp3_plot_days_def_app}
{0.165}
{Figures/exp3_defplot_likert_time unstructured (slow response)}
{Panels A--B: Bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters, respectively ($\upbeta_{fixed}$ and $\upbeta_{random}$). Panels C--D: Bias/precision plots for the fixed- and random-effect triquarter-halfway elevation parameters, respectively ($\upgamma_{fixed}$ and $\upgamma_{random}$). Panels E--F: Bias/precision plots for the fixed- and random-effect baseline parameters, respectively ($\uptheta_{fixed}$ and $\uptheta_{random}$). Panels G--H: Bias/precision plots for the fixed- and random-effect maximal elevation parameters, respectively ($\upalpha_{fixed}$ and $\upalpha_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\uptheta_{fixed}$ = 3.00, $\uptheta_{random}$ = 0.05, $\upalpha_{fixed}$ = 3.32, $\upalpha_{random}$ = 0.05, $\upepsilon$ = 0.05. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter.}
\end{apaFigure}
\app{Convergence Success Rates}

\label{convergence-tables}

\secapp{Experiment 1}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in gray indicate conditions where less than 90\% of models converged.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}}
\caption{\label{tab:conv-exp-1}Convergence Success Rates in Experiment 1}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{3}{c}{Days to Halfway Elevation} \\
\cmidrule(l{3pt}r{3pt}){3-5}
Measurement Spacing & Number of Measurements & 80 & 180 & 280\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.95}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-5}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-5}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.96} & \cellcolor[HTML]{eeeeee}{0.82}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-5}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.96} & \cellcolor[HTML]{eeeeee}{0.86}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\secapp{Experiment 2}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in gray indicate conditions where less than 90\% of models converged.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}}
\caption{\label{tab:conv-exp-2}Convergence Success Rates in Experiment 2}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{Sample Size (\textit{N})} \\
\cmidrule(l{3pt}r{3pt}){3-8}
Measurement Spacing & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.95} & \cellcolor[HTML]{ffffff}{0.92}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.95} & \cellcolor[HTML]{ffffff}{0.93} & \cellcolor[HTML]{eeeeee}{0.88}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.95}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.96} & \cellcolor[HTML]{eeeeee}{0.90} & \cellcolor[HTML]{eeeeee}{0.81}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\secapp{Experiment 3}

\label{conv-exp-3}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in gray indicate conditions where less than 90\% of models converged.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}>{}p{1cm}}
\caption{\label{tab:conv-exp-3}Convergence Success Rates in Experiment 3}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{Sample Size (\textit{N})} \\
\cmidrule(l{3pt}r{3pt}){3-8}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.96} & \cellcolor[HTML]{eeeeee}{0.90}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time structured} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.96} & \cellcolor[HTML]{ffffff}{0.90}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98} & \cellcolor[HTML]{ffffff}{0.99}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (fast response)} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.95} & \cellcolor[HTML]{ffffff}{0.92}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response)} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in gray indicate conditions where less than 90\% of models converged.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}cccc}
\caption{\label{tab:conv-exp-3-def}Convergence Success in Experiment 3 With Definition Variables  }\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{Sample size (\textit{N})} \\
\cmidrule(l{3pt}r{3pt}){3-8}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99} & \cellcolor[HTML]{ffffff}{0.98}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{0.99}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00} & \cellcolor[HTML]{ffffff}{1.00}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\app{Parameter Estimate Tables}
\secapp{Experiment 1}

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 1}\label{tab:param-exp-1}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{3}{c}{\thead{$\upbeta_{fixed}$ (Days to \\ halfway elevation)}} & \multicolumn{3}{c}{\thead{$\upbeta_{random}$ (Days to \\ halfway elevation) \\ Pop value = 10.00}} & \multicolumn{3}{c}{\thead{$\upgamma_{fixed}$ (Triquarter- \\ halfway delta) \\ Pop value = 20.00}} & \multicolumn{3}{c}{\thead{$\upgamma_{random}$ (Triquarter- \\ halfway delta) \\ Pop value = 4.00}} \\
\cmidrule(l{3pt}r{3pt}){3-5} \cmidrule(l{3pt}r{3pt}){6-8} \cmidrule(l{3pt}r{3pt}){9-11} \cmidrule(l{3pt}r{3pt}){12-14}
Measurement Spacing & Number of Measurements & 80 & 180 & 280 & 80 & 180 & 280 & 80 & 180 & 280 & 80 & 180 & 280\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{79.73} & \cellcolor[HTML]{ffffff}{179.78} & \cellcolor[HTML]{ffffff}{279.81$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.14} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.08} & \cellcolor[HTML]{8cb9e3}{19.37} & \cellcolor[HTML]{8cb9e3}{19.49} & \cellcolor[HTML]{8cb9e3}{19.71} & \cellcolor[HTML]{8cb9e3}{7.41$^{\square}$} & \cellcolor[HTML]{8cb9e3}{14.53$^{\square}$} & \cellcolor[HTML]{8cb9e3}{8.11$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{80.21} & \cellcolor[HTML]{ffffff}{178.99} & \cellcolor[HTML]{ffffff}{279.55$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.16} & \cellcolor[HTML]{8cb9e3}{10.55} & \cellcolor[HTML]{8cb9e3}{10.13} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{20.83} & \cellcolor[HTML]{8cb9e3}{20.60} & \cellcolor[HTML]{8cb9e3}{4.37} & \cellcolor[HTML]{8cb9e3}{ 5.14$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.41$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{80.00} & \cellcolor[HTML]{ffffff}{179.94} & \cellcolor[HTML]{ffffff}{279.99$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.29} & \cellcolor[HTML]{8cb9e3}{10.37} & \cellcolor[HTML]{8cb9e3}{10.34} & \cellcolor[HTML]{8cb9e3}{20.77} & \cellcolor[HTML]{8cb9e3}{20.76} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{4.24} & \cellcolor[HTML]{8cb9e3}{ 4.14} & \cellcolor[HTML]{8cb9e3}{4.30}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{ffffff}{80.03} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{279.88$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.27} & \cellcolor[HTML]{8cb9e3}{10.29} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{20.64} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{8cb9e3}{20.64} & \cellcolor[HTML]{8cb9e3}{4.13} & \cellcolor[HTML]{8cb9e3}{ 4.08} & \cellcolor[HTML]{8cb9e3}{4.18}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{79.88} & \cellcolor[HTML]{8cb9e3}{180.10} & \cellcolor[HTML]{8cb9e3}{274.37$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{ 9.73} & \cellcolor[HTML]{8cb9e3}{13.04$^{\square}$} & \cellcolor[HTML]{8cb9e3}{20.71} & \cellcolor[HTML]{8cb9e3}{20.39} & \cellcolor[HTML]{8cb9e3}{18.32} & \cellcolor[HTML]{8cb9e3}{4.57$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.99$^{\square}$} & \cellcolor[HTML]{8cb9e3}{6.20$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{80.19} & \cellcolor[HTML]{ffffff}{179.82} & \cellcolor[HTML]{ffffff}{279.86$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.42} & \cellcolor[HTML]{8cb9e3}{10.47} & \cellcolor[HTML]{8cb9e3}{10.14} & \cellcolor[HTML]{8cb9e3}{20.66} & \cellcolor[HTML]{8cb9e3}{20.79} & \cellcolor[HTML]{8cb9e3}{19.78} & \cellcolor[HTML]{8cb9e3}{4.29} & \cellcolor[HTML]{8cb9e3}{ 4.87$^{\square}$} & \cellcolor[HTML]{8cb9e3}{7.03$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{79.59} & \cellcolor[HTML]{ffffff}{179.06} & \cellcolor[HTML]{ffffff}{279.70$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.07} & \cellcolor[HTML]{8cb9e3}{10.22} & \cellcolor[HTML]{8cb9e3}{10.20} & \cellcolor[HTML]{8cb9e3}{20.33} & \cellcolor[HTML]{8cb9e3}{20.66} & \cellcolor[HTML]{8cb9e3}{20.72} & \cellcolor[HTML]{8cb9e3}{4.17} & \cellcolor[HTML]{8cb9e3}{ 4.25} & \cellcolor[HTML]{8cb9e3}{4.32}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{79.89} & \cellcolor[HTML]{ffffff}{179.84} & \cellcolor[HTML]{ffffff}{279.62$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.38} & \cellcolor[HTML]{8cb9e3}{10.30} & \cellcolor[HTML]{8cb9e3}{10.47} & \cellcolor[HTML]{8cb9e3}{20.78} & \cellcolor[HTML]{8cb9e3}{20.75} & \cellcolor[HTML]{8cb9e3}{20.68} & \cellcolor[HTML]{8cb9e3}{4.23} & \cellcolor[HTML]{8cb9e3}{ 4.18} & \cellcolor[HTML]{8cb9e3}{4.13}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{70.67} & \cellcolor[HTML]{8cb9e3}{179.92} & \cellcolor[HTML]{ffffff}{279.63$^{\square}$} & \cellcolor[HTML]{8cb9e3}{15.28$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 9.80} & \cellcolor[HTML]{8cb9e3}{10.22} & \cellcolor[HTML]{8cb9e3}{16.63} & \cellcolor[HTML]{8cb9e3}{20.07} & \cellcolor[HTML]{8cb9e3}{20.55} & \cellcolor[HTML]{8cb9e3}{5.48$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.17$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.59$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{78.23} & \cellcolor[HTML]{ffffff}{178.22} & \cellcolor[HTML]{ffffff}{279.84$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.08} & \cellcolor[HTML]{8cb9e3}{10.46} & \cellcolor[HTML]{8cb9e3}{10.39} & \cellcolor[HTML]{8cb9e3}{19.38} & \cellcolor[HTML]{8cb9e3}{20.59} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{6.80$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.09$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.24}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{79.95} & \cellcolor[HTML]{ffffff}{179.34} & \cellcolor[HTML]{ffffff}{278.98$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.03} & \cellcolor[HTML]{8cb9e3}{10.20} & \cellcolor[HTML]{8cb9e3}{10.05} & \cellcolor[HTML]{8cb9e3}{20.42} & \cellcolor[HTML]{8cb9e3}{20.54} & \cellcolor[HTML]{8cb9e3}{20.28} & \cellcolor[HTML]{8cb9e3}{4.37} & \cellcolor[HTML]{8cb9e3}{ 4.32} & \cellcolor[HTML]{8cb9e3}{4.19}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{79.42} & \cellcolor[HTML]{ffffff}{179.70} & \cellcolor[HTML]{ffffff}{279.52$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.38} & \cellcolor[HTML]{8cb9e3}{10.13} & \cellcolor[HTML]{8cb9e3}{10.06} & \cellcolor[HTML]{8cb9e3}{20.75} & \cellcolor[HTML]{8cb9e3}{20.45} & \cellcolor[HTML]{8cb9e3}{20.31} & \cellcolor[HTML]{8cb9e3}{4.17} & \cellcolor[HTML]{8cb9e3}{ 4.16} & \cellcolor[HTML]{8cb9e3}{4.17}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{71.95} & \cellcolor[HTML]{ffffff}{179.61} & \cellcolor[HTML]{8cb9e3}{287.73$^{\square}$} & \cellcolor[HTML]{8cb9e3}{16.78$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.26} & \cellcolor[HTML]{8cb9e3}{16.74$^{\square}$} & \cellcolor[HTML]{8cb9e3}{15.59} & \cellcolor[HTML]{8cb9e3}{20.61} & \cellcolor[HTML]{8cb9e3}{17.09} & \cellcolor[HTML]{8cb9e3}{6.54$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.24} & \cellcolor[HTML]{8cb9e3}{8.61$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{80.45} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{ffffff}{279.15$^{\square}$} & \cellcolor[HTML]{8cb9e3}{13.93$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.25} & \cellcolor[HTML]{8cb9e3}{13.69$^{\square}$} & \cellcolor[HTML]{8cb9e3}{20.71} & \cellcolor[HTML]{8cb9e3}{20.58} & \cellcolor[HTML]{8cb9e3}{20.61} & \cellcolor[HTML]{8cb9e3}{5.21$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.16} & \cellcolor[HTML]{8cb9e3}{4.98$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{80.28} & \cellcolor[HTML]{ffffff}{180.05} & \cellcolor[HTML]{ffffff}{279.63$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.42} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{20.91} & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{8cb9e3}{20.85} & \cellcolor[HTML]{8cb9e3}{4.74$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.26} & \cellcolor[HTML]{8cb9e3}{4.72$^{\square}$}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{ffffff}{80.19} & \cellcolor[HTML]{ffffff}{179.96} & \cellcolor[HTML]{ffffff}{279.86$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.27} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.15} & \cellcolor[HTML]{8cb9e3}{20.71} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{8cb9e3}{20.71} & \cellcolor[HTML]{8cb9e3}{4.14} & \cellcolor[HTML]{8cb9e3}{ 4.08} & \cellcolor[HTML]{8cb9e3}{4.16}\\
\bottomrule
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in light blue indicate cells where estimation is imprecise (i.e., lower and/or upper whisker lengths exceeding 10\% of the parameter's population value. Empty superscript squares ($^{\square}$) indicate biased estimates (i.e., bias exceeding 10\% of parameter's population value). Importantly, bias and precision cutoff values for the days-to-halfway elevation parameter ($\upbeta_{fixed}$) are based on a value of 180.00.
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}ccccccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 1 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{3}{c}{\thead{$\uptheta_{fixed}$ (Baseline)  \\ Pop value = 3.00}} & \multicolumn{3}{c}{\thead{$\uptheta_{random}$ (Baseline) \\ Pop value = 0.05}} & \multicolumn{3}{c}{\thead{$\upalpha_{fixed}$ (Maximal \\ elevation)  \\ Pop value = 3.32}} & \multicolumn{3}{c}{\thead{$\upalpha_{random}$ (Maximal \\ elevation) \\ Pop value = 0.05}} & \multicolumn{3}{c}{\thead{$\upepsilon$(error) \\ Pop value = 0.03}} \\
\cmidrule(l{3pt}r{3pt}){3-5} \cmidrule(l{3pt}r{3pt}){6-8} \cmidrule(l{3pt}r{3pt}){9-11} \cmidrule(l{3pt}r{3pt}){12-14} \cmidrule(l{3pt}r{3pt}){15-17}
Measurement Spacing & Number of Measurements & 80 & 180 & 280 & 80 & 180 & 280 & 80 & 180 & 280 & 80 & 180 & 280 & 80 & 180 & 280\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-17}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.33} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-17}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{2.99} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-17}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{2.99} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.33} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\secapp{Experiment 2}

\end{landscape}
\restoregeometry

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption{Parameter Values Estimated in Experiment 2}\label{tab:param-exp-2}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upbeta_{fixed}$ (Days to halfway elevation) \\ Pop value = 180.00}} & \multicolumn{6}{c}{\thead{$\upbeta_{random}$ (Days to halfway elevation) \\ Pop value = 10.00}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Measurement Spacing & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{179.71} & \cellcolor[HTML]{ffffff}{179.82} & \cellcolor[HTML]{ffffff}{179.53} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{ffffff}{179.64} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.36} & \cellcolor[HTML]{8cb9e3}{10.04} & \cellcolor[HTML]{8cb9e3}{10.51} & \cellcolor[HTML]{8cb9e3}{10.65} & \cellcolor[HTML]{8cb9e3}{10.74}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{180.05} & \cellcolor[HTML]{ffffff}{179.65} & \cellcolor[HTML]{ffffff}{179.53} & \cellcolor[HTML]{ffffff}{179.75} & \cellcolor[HTML]{ffffff}{179.76} & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{8cb9e3}{10.18} & \cellcolor[HTML]{8cb9e3}{10.59} & \cellcolor[HTML]{8cb9e3}{10.49} & \cellcolor[HTML]{8cb9e3}{10.54} & \cellcolor[HTML]{8cb9e3}{10.60} & \cellcolor[HTML]{8cb9e3}{10.58}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{179.84} & \cellcolor[HTML]{ffffff}{180.07} & \cellcolor[HTML]{ffffff}{179.94} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{ffffff}{180.02} & \cellcolor[HTML]{ffffff}{180.03} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.20} & \cellcolor[HTML]{8cb9e3}{10.30} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.39} & \cellcolor[HTML]{8cb9e3}{10.36}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{ffffff}{180.11} & \cellcolor[HTML]{ffffff}{180.11} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{180.03} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{8cb9e3}{10.08} & \cellcolor[HTML]{8cb9e3}{10.04} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.29} & \cellcolor[HTML]{8cb9e3}{10.38} & \cellcolor[HTML]{8cb9e3}{10.29}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{181.81} & \cellcolor[HTML]{8cb9e3}{181.16} & \cellcolor[HTML]{8cb9e3}{181.14} & \cellcolor[HTML]{8cb9e3}{180.27} & \cellcolor[HTML]{ffffff}{179.78} & \cellcolor[HTML]{ffffff}{179.57} & \cellcolor[HTML]{8cb9e3}{11.24$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{ 9.93} & \cellcolor[HTML]{8cb9e3}{ 9.59} & \cellcolor[HTML]{8cb9e3}{ 9.91} & \cellcolor[HTML]{8cb9e3}{10.22}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{ffffff}{179.96} & \cellcolor[HTML]{ffffff}{179.73} & \cellcolor[HTML]{ffffff}{179.77} & \cellcolor[HTML]{ffffff}{179.79} & \cellcolor[HTML]{ffffff}{179.83} & \cellcolor[HTML]{8cb9e3}{10.26} & \cellcolor[HTML]{8cb9e3}{10.43} & \cellcolor[HTML]{8cb9e3}{10.50} & \cellcolor[HTML]{8cb9e3}{10.43} & \cellcolor[HTML]{8cb9e3}{10.47} & \cellcolor[HTML]{8cb9e3}{10.47}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{179.33} & \cellcolor[HTML]{ffffff}{179.18} & \cellcolor[HTML]{ffffff}{178.99} & \cellcolor[HTML]{ffffff}{179.07} & \cellcolor[HTML]{ffffff}{179.11} & \cellcolor[HTML]{ffffff}{179.13} & \cellcolor[HTML]{8cb9e3}{10.15} & \cellcolor[HTML]{8cb9e3}{10.10} & \cellcolor[HTML]{8cb9e3}{10.17} & \cellcolor[HTML]{8cb9e3}{10.18} & \cellcolor[HTML]{8cb9e3}{10.21} & \cellcolor[HTML]{8cb9e3}{10.29}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{179.81} & \cellcolor[HTML]{ffffff}{179.79} & \cellcolor[HTML]{ffffff}{179.86} & \cellcolor[HTML]{ffffff}{179.88} & \cellcolor[HTML]{ffffff}{179.81} & \cellcolor[HTML]{ffffff}{179.82} & \cellcolor[HTML]{8cb9e3}{ 9.99} & \cellcolor[HTML]{8cb9e3}{10.19} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{10.27} & \cellcolor[HTML]{8cb9e3}{10.30} & \cellcolor[HTML]{8cb9e3}{10.30}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{177.01} & \cellcolor[HTML]{8cb9e3}{178.48} & \cellcolor[HTML]{8cb9e3}{179.13} & \cellcolor[HTML]{8cb9e3}{179.23} & \cellcolor[HTML]{8cb9e3}{179.86} & \cellcolor[HTML]{ffffff}{180.37} & \cellcolor[HTML]{8cb9e3}{10.95} & \cellcolor[HTML]{8cb9e3}{11.38$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 9.97} & \cellcolor[HTML]{8cb9e3}{ 9.55} & \cellcolor[HTML]{8cb9e3}{10.36} & \cellcolor[HTML]{8cb9e3}{10.11}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{178.98} & \cellcolor[HTML]{ffffff}{179.68} & \cellcolor[HTML]{ffffff}{179.12} & \cellcolor[HTML]{ffffff}{179.53} & \cellcolor[HTML]{ffffff}{180.07} & \cellcolor[HTML]{ffffff}{179.75} & \cellcolor[HTML]{8cb9e3}{10.07} & \cellcolor[HTML]{8cb9e3}{10.31} & \cellcolor[HTML]{8cb9e3}{10.48} & \cellcolor[HTML]{8cb9e3}{10.37} & \cellcolor[HTML]{8cb9e3}{10.46} & \cellcolor[HTML]{8cb9e3}{10.51}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{179.65} & \cellcolor[HTML]{ffffff}{179.01} & \cellcolor[HTML]{ffffff}{178.46} & \cellcolor[HTML]{ffffff}{179.47} & \cellcolor[HTML]{ffffff}{179.64} & \cellcolor[HTML]{ffffff}{179.75} & \cellcolor[HTML]{8cb9e3}{10.11} & \cellcolor[HTML]{8cb9e3}{10.16} & \cellcolor[HTML]{8cb9e3}{10.20} & \cellcolor[HTML]{8cb9e3}{10.17} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.26}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{179.48} & \cellcolor[HTML]{ffffff}{179.68} & \cellcolor[HTML]{ffffff}{179.70} & \cellcolor[HTML]{ffffff}{179.65} & \cellcolor[HTML]{ffffff}{179.64} & \cellcolor[HTML]{ffffff}{179.68} & \cellcolor[HTML]{8cb9e3}{ 9.85} & \cellcolor[HTML]{8cb9e3}{ 9.98} & \cellcolor[HTML]{8cb9e3}{10.03} & \cellcolor[HTML]{8cb9e3}{10.12} & \cellcolor[HTML]{8cb9e3}{10.13} & \cellcolor[HTML]{8cb9e3}{10.11}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{177.99} & \cellcolor[HTML]{ffffff}{179.65} & \cellcolor[HTML]{ffffff}{179.15} & \cellcolor[HTML]{ffffff}{179.83} & \cellcolor[HTML]{ffffff}{179.61} & \cellcolor[HTML]{ffffff}{178.74} & \cellcolor[HTML]{8cb9e3}{10.30} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.26}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{179.96} & \cellcolor[HTML]{ffffff}{179.82} & \cellcolor[HTML]{ffffff}{179.97} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{ffffff}{180.02} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{8cb9e3}{10.25} & \cellcolor[HTML]{8cb9e3}{10.20} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{10.26} & \cellcolor[HTML]{8cb9e3}{10.29} & \cellcolor[HTML]{8cb9e3}{10.27}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{179.88} & \cellcolor[HTML]{ffffff}{180.07} & \cellcolor[HTML]{ffffff}{179.89} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{8cb9e3}{10.12} & \cellcolor[HTML]{8cb9e3}{10.16} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{10.30} & \cellcolor[HTML]{8cb9e3}{10.24} & \cellcolor[HTML]{8cb9e3}{10.29}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{ffffff}{180.02} & \cellcolor[HTML]{ffffff}{179.96} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{8cb9e3}{10.08} & \cellcolor[HTML]{8cb9e3}{10.35} & \cellcolor[HTML]{8cb9e3}{10.15} & \cellcolor[HTML]{8cb9e3}{10.35} & \cellcolor[HTML]{8cb9e3}{10.30} & \cellcolor[HTML]{8cb9e3}{10.28}\\
\bottomrule
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 2 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upgamma_{fixed}$ (Triquarter-halfway delta) \\ Pop value = 20.00}} & \multicolumn{6}{c}{\thead{$\upgamma_{random}$ (Triquarter-halfway delta) \\ Pop value = 4.00}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Measurement Spacing & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{8cb9e3}{18.25} & \cellcolor[HTML]{8cb9e3}{18.11} & \cellcolor[HTML]{8cb9e3}{18.27} & \cellcolor[HTML]{8cb9e3}{19.59} & \cellcolor[HTML]{8cb9e3}{20.27} & \cellcolor[HTML]{8cb9e3}{20.60} & \cellcolor[HTML]{8cb9e3}{17.69$^{\square}$} & \cellcolor[HTML]{8cb9e3}{16.95$^{\square}$} & \cellcolor[HTML]{8cb9e3}{16.41$^{\square}$} & \cellcolor[HTML]{8cb9e3}{15.19$^{\square}$} & \cellcolor[HTML]{8cb9e3}{12.19$^{\square}$} & \cellcolor[HTML]{8cb9e3}{8.51$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.25} & \cellcolor[HTML]{8cb9e3}{20.53} & \cellcolor[HTML]{8cb9e3}{20.66} & \cellcolor[HTML]{8cb9e3}{20.75} & \cellcolor[HTML]{8cb9e3}{20.81} & \cellcolor[HTML]{8cb9e3}{20.74} & \cellcolor[HTML]{8cb9e3}{ 9.22$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 7.70$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.77$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.89$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.98$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.34}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.88} & \cellcolor[HTML]{8cb9e3}{20.72} & \cellcolor[HTML]{8cb9e3}{20.73} & \cellcolor[HTML]{8cb9e3}{20.76} & \cellcolor[HTML]{ffffff}{20.75} & \cellcolor[HTML]{ffffff}{20.73} & \cellcolor[HTML]{8cb9e3}{ 5.30$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.99$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.44$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.27} & \cellcolor[HTML]{8cb9e3}{ 4.03} & \cellcolor[HTML]{8cb9e3}{4.00}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{8cb9e3}{20.66} & \cellcolor[HTML]{8cb9e3}{20.73} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{ffffff}{20.69} & \cellcolor[HTML]{ffffff}{20.71} & \cellcolor[HTML]{8cb9e3}{ 4.86$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.49$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.20} & \cellcolor[HTML]{8cb9e3}{ 4.10} & \cellcolor[HTML]{8cb9e3}{ 4.02} & \cellcolor[HTML]{8cb9e3}{4.07}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{18.81} & \cellcolor[HTML]{8cb9e3}{19.11} & \cellcolor[HTML]{8cb9e3}{19.56} & \cellcolor[HTML]{8cb9e3}{20.25} & \cellcolor[HTML]{8cb9e3}{20.80} & \cellcolor[HTML]{8cb9e3}{20.92} & \cellcolor[HTML]{8cb9e3}{ 6.18$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.88$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.25$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.94$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.68$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.42$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.74} & \cellcolor[HTML]{8cb9e3}{20.74} & \cellcolor[HTML]{8cb9e3}{20.94} & \cellcolor[HTML]{8cb9e3}{20.83} & \cellcolor[HTML]{8cb9e3}{20.83} & \cellcolor[HTML]{ffffff}{20.82} & \cellcolor[HTML]{8cb9e3}{ 7.38$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.31$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.45$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.06$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.66$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.45$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.72} & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{ffffff}{20.63} & \cellcolor[HTML]{ffffff}{20.65} & \cellcolor[HTML]{8cb9e3}{ 5.15$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.83$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.44$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.26} & \cellcolor[HTML]{8cb9e3}{ 4.16} & \cellcolor[HTML]{8cb9e3}{4.23}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{8cb9e3}{20.80} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.84} & \cellcolor[HTML]{8cb9e3}{20.76} & \cellcolor[HTML]{ffffff}{20.78} & \cellcolor[HTML]{ffffff}{20.76} & \cellcolor[HTML]{8cb9e3}{ 4.84$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.43$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.25} & \cellcolor[HTML]{8cb9e3}{ 4.26} & \cellcolor[HTML]{8cb9e3}{ 4.17} & \cellcolor[HTML]{8cb9e3}{4.14}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{19.21} & \cellcolor[HTML]{8cb9e3}{18.50} & \cellcolor[HTML]{8cb9e3}{19.21} & \cellcolor[HTML]{8cb9e3}{19.90} & \cellcolor[HTML]{8cb9e3}{20.50} & \cellcolor[HTML]{8cb9e3}{20.79} & \cellcolor[HTML]{8cb9e3}{ 7.17$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.01$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.18$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.12$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.91$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.66$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.36} & \cellcolor[HTML]{8cb9e3}{20.49} & \cellcolor[HTML]{8cb9e3}{20.57} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{21.03} & \cellcolor[HTML]{ffffff}{20.76} & \cellcolor[HTML]{8cb9e3}{ 6.98$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.18$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.43$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.20$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.67$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.68$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.60} & \cellcolor[HTML]{8cb9e3}{20.55} & \cellcolor[HTML]{8cb9e3}{20.62} & \cellcolor[HTML]{ffffff}{20.70} & \cellcolor[HTML]{ffffff}{20.63} & \cellcolor[HTML]{8cb9e3}{ 5.48$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.12$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.72$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.52$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.72$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.83$^{\square}$}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{8cb9e3}{20.49} & \cellcolor[HTML]{8cb9e3}{20.53} & \cellcolor[HTML]{8cb9e3}{20.38} & \cellcolor[HTML]{8cb9e3}{20.41} & \cellcolor[HTML]{ffffff}{20.47} & \cellcolor[HTML]{ffffff}{20.41} & \cellcolor[HTML]{8cb9e3}{ 4.66$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.57$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.34} & \cellcolor[HTML]{8cb9e3}{ 4.20} & \cellcolor[HTML]{8cb9e3}{ 4.18} & \cellcolor[HTML]{8cb9e3}{4.17}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{20.80} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{ffffff}{20.64} & \cellcolor[HTML]{ffffff}{20.59} & \cellcolor[HTML]{8cb9e3}{ 5.21$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.68$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.43$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.18} & \cellcolor[HTML]{8cb9e3}{ 4.15} & \cellcolor[HTML]{8cb9e3}{4.11}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.76} & \cellcolor[HTML]{8cb9e3}{20.55} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{8cb9e3}{20.63} & \cellcolor[HTML]{ffffff}{20.60} & \cellcolor[HTML]{ffffff}{20.63} & \cellcolor[HTML]{8cb9e3}{ 5.07$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.60$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.39} & \cellcolor[HTML]{8cb9e3}{ 4.23} & \cellcolor[HTML]{8cb9e3}{ 4.19} & \cellcolor[HTML]{8cb9e3}{4.15}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.68} & \cellcolor[HTML]{8cb9e3}{20.71} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{20.63} & \cellcolor[HTML]{ffffff}{20.58} & \cellcolor[HTML]{ffffff}{20.63} & \cellcolor[HTML]{8cb9e3}{ 4.99$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.67$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.49$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.17} & \cellcolor[HTML]{8cb9e3}{ 4.13} & \cellcolor[HTML]{8cb9e3}{4.15}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{8cb9e3}{20.64} & \cellcolor[HTML]{8cb9e3}{20.74} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{ffffff}{20.66} & \cellcolor[HTML]{ffffff}{20.68} & \cellcolor[HTML]{8cb9e3}{ 4.57$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.47$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.22} & \cellcolor[HTML]{8cb9e3}{ 4.19} & \cellcolor[HTML]{8cb9e3}{ 4.09} & \cellcolor[HTML]{8cb9e3}{4.07}\\
\bottomrule
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 2 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\uptheta_{fixed}$ (Baseline) \\ Pop value = 3.00}} & \multicolumn{6}{c}{\thead{$\uptheta_{random}$ (Baseline) \\ Pop value = 0.05}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Measurement Spacing & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 2 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upalpha_{fixed}$ (Maximal elevation) \\ Pop value = 3.32}} & \multicolumn{6}{c}{\thead{$\upalpha_{random}$ (Maximal elevation) \\ Pop value = 0.05}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Measurement Spacing & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}

\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in light blue indicate cells where estimation is imprecise (i.e., lower and/or upper whisker lengths exceeding 10\% of the parameter's population value. Empty superscript squares ($^{\square}$) indicate biased estimates (i.e., bias exceeding 10\% of parameter's population value).
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 2 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upepsilon$(error) \\ Pop value = 0.03}} \\
\cmidrule(l{3pt}r{3pt}){3-8}
Measurement Spacing & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Equal spacing} & 11 & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval increasing} & 11 & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time-interval decreasing} & 11 & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Middle-and-extreme spacing} & 11 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\secapp{Experiment 3}
\end{landscape}
\restoregeometry

\newgeometry{margin=2.54cm}
\begin{landscape}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption{Parameter Values Estimated in Experiment 3}\label{tab:param-exp-3}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upbeta_{fixed}$ (Days to halfway elevation) \\ Pop value = 180.00}} & \multicolumn{6}{c}{\thead{$\upbeta_{random}$ (Days to halfway elevation) \\ Pop value = 10.00}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{179.71} & \cellcolor[HTML]{ffffff}{179.67} & \cellcolor[HTML]{ffffff}{179.75} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{ffffff}{179.66} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.27} & \cellcolor[HTML]{8cb9e3}{10.37} & \cellcolor[HTML]{8cb9e3}{10.56} & \cellcolor[HTML]{8cb9e3}{10.73} & \cellcolor[HTML]{8cb9e3}{10.69}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{180.05} & \cellcolor[HTML]{ffffff}{179.59} & \cellcolor[HTML]{ffffff}{179.02} & \cellcolor[HTML]{ffffff}{179.66} & \cellcolor[HTML]{ffffff}{180.03} & \cellcolor[HTML]{ffffff}{179.63} & \cellcolor[HTML]{8cb9e3}{10.18} & \cellcolor[HTML]{8cb9e3}{10.42} & \cellcolor[HTML]{8cb9e3}{10.65} & \cellcolor[HTML]{8cb9e3}{10.52} & \cellcolor[HTML]{8cb9e3}{10.76} & \cellcolor[HTML]{8cb9e3}{10.60}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{179.84} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{179.97} & \cellcolor[HTML]{ffffff}{180.01} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.28} & \cellcolor[HTML]{8cb9e3}{10.37} & \cellcolor[HTML]{8cb9e3}{10.46} & \cellcolor[HTML]{8cb9e3}{10.42} & \cellcolor[HTML]{8cb9e3}{10.41}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time structured} & 11 & \cellcolor[HTML]{ffffff}{180.11} & \cellcolor[HTML]{ffffff}{179.91} & \cellcolor[HTML]{ffffff}{179.94} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{ffffff}{180.00} & \cellcolor[HTML]{8cb9e3}{10.08} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{10.21} & \cellcolor[HTML]{8cb9e3}{10.29} & \cellcolor[HTML]{8cb9e3}{10.36} & \cellcolor[HTML]{8cb9e3}{10.31}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{177.48} & \cellcolor[HTML]{ffffff}{177.24} & \cellcolor[HTML]{ffffff}{176.74} & \cellcolor[HTML]{ffffff}{177.50} & \cellcolor[HTML]{ffffff}{177.42} & \cellcolor[HTML]{ffffff}{177.06} & \cellcolor[HTML]{8cb9e3}{10.65} & \cellcolor[HTML]{8cb9e3}{10.36} & \cellcolor[HTML]{8cb9e3}{10.38} & \cellcolor[HTML]{8cb9e3}{10.65} & \cellcolor[HTML]{8cb9e3}{10.85} & \cellcolor[HTML]{8cb9e3}{10.96}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{176.89} & \cellcolor[HTML]{ffffff}{177.03} & \cellcolor[HTML]{ffffff}{176.37} & \cellcolor[HTML]{ffffff}{175.92} & \cellcolor[HTML]{ffffff}{177.20} & \cellcolor[HTML]{ffffff}{176.95} & \cellcolor[HTML]{8cb9e3}{10.53} & \cellcolor[HTML]{8cb9e3}{10.60} & \cellcolor[HTML]{8cb9e3}{10.88} & \cellcolor[HTML]{8cb9e3}{10.83} & \cellcolor[HTML]{8cb9e3}{10.84} & \cellcolor[HTML]{8cb9e3}{10.84}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{177.54} & \cellcolor[HTML]{ffffff}{177.28} & \cellcolor[HTML]{ffffff}{177.27} & \cellcolor[HTML]{ffffff}{177.31} & \cellcolor[HTML]{ffffff}{177.34} & \cellcolor[HTML]{ffffff}{177.33} & \cellcolor[HTML]{8cb9e3}{10.66} & \cellcolor[HTML]{8cb9e3}{10.43} & \cellcolor[HTML]{8cb9e3}{10.44} & \cellcolor[HTML]{8cb9e3}{10.61} & \cellcolor[HTML]{8cb9e3}{10.65} & \cellcolor[HTML]{8cb9e3}{10.59}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (fast response)} & 11 & \cellcolor[HTML]{ffffff}{177.25} & \cellcolor[HTML]{ffffff}{177.35} & \cellcolor[HTML]{ffffff}{177.27} & \cellcolor[HTML]{ffffff}{177.37} & \cellcolor[HTML]{ffffff}{177.35} & \cellcolor[HTML]{ffffff}{177.30} & \cellcolor[HTML]{8cb9e3}{10.41} & \cellcolor[HTML]{8cb9e3}{10.37} & \cellcolor[HTML]{8cb9e3}{10.37} & \cellcolor[HTML]{8cb9e3}{10.45} & \cellcolor[HTML]{8cb9e3}{10.52} & \cellcolor[HTML]{8cb9e3}{10.51}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{174.13} & \cellcolor[HTML]{ffffff}{174.02} & \cellcolor[HTML]{ffffff}{173.65} & \cellcolor[HTML]{ffffff}{173.85} & \cellcolor[HTML]{ffffff}{173.41} & \cellcolor[HTML]{ffffff}{173.63} & \cellcolor[HTML]{8cb9e3}{11.23$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.93} & \cellcolor[HTML]{8cb9e3}{11.22$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.80$^{\square}$} & \cellcolor[HTML]{8cb9e3}{12.10$^{\square}$} & \cellcolor[HTML]{8cb9e3}{12.07$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{173.31} & \cellcolor[HTML]{ffffff}{173.63} & \cellcolor[HTML]{ffffff}{173.01} & \cellcolor[HTML]{ffffff}{173.06} & \cellcolor[HTML]{ffffff}{173.55} & \cellcolor[HTML]{ffffff}{173.55} & \cellcolor[HTML]{8cb9e3}{11.71$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.67$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.88$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.97$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.91$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.94$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{173.37} & \cellcolor[HTML]{ffffff}{173.37} & \cellcolor[HTML]{ffffff}{173.54} & \cellcolor[HTML]{ffffff}{173.52} & \cellcolor[HTML]{ffffff}{173.50} & \cellcolor[HTML]{ffffff}{173.49} & \cellcolor[HTML]{8cb9e3}{11.26$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.38$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.42$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.40$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.47$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.46$^{\square}$}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response)} & 11 & \cellcolor[HTML]{ffffff}{173.58} & \cellcolor[HTML]{ffffff}{173.56} & \cellcolor[HTML]{ffffff}{173.50} & \cellcolor[HTML]{ffffff}{173.51} & \cellcolor[HTML]{ffffff}{173.49} & \cellcolor[HTML]{ffffff}{173.47} & \cellcolor[HTML]{8cb9e3}{10.87} & \cellcolor[HTML]{8cb9e3}{10.98} & \cellcolor[HTML]{8cb9e3}{11.12$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.18$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.14$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.16$^{\square}$}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{179.92} & \cellcolor[HTML]{ffffff}{179.87} & \cellcolor[HTML]{ffffff}{179.97} & \cellcolor[HTML]{ffffff}{179.92} & \cellcolor[HTML]{ffffff}{179.87} & \cellcolor[HTML]{ffffff}{179.88} & \cellcolor[HTML]{8cb9e3}{10.70} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.35} & \cellcolor[HTML]{8cb9e3}{10.50} & \cellcolor[HTML]{8cb9e3}{10.66} & \cellcolor[HTML]{8cb9e3}{10.61}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{180.07} & \cellcolor[HTML]{ffffff}{179.96} & \cellcolor[HTML]{ffffff}{179.96} & \cellcolor[HTML]{ffffff}{179.92} & \cellcolor[HTML]{ffffff}{179.91} & \cellcolor[HTML]{ffffff}{179.94} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{10.33} & \cellcolor[HTML]{8cb9e3}{10.52} & \cellcolor[HTML]{8cb9e3}{10.53} & \cellcolor[HTML]{8cb9e3}{10.50}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{180.17} & \cellcolor[HTML]{ffffff}{179.86} & \cellcolor[HTML]{ffffff}{179.88} & \cellcolor[HTML]{ffffff}{179.97} & \cellcolor[HTML]{ffffff}{179.95} & \cellcolor[HTML]{ffffff}{179.98} & \cellcolor[HTML]{8cb9e3}{10.12} & \cellcolor[HTML]{8cb9e3}{10.26} & \cellcolor[HTML]{8cb9e3}{10.43} & \cellcolor[HTML]{8cb9e3}{10.32} & \cellcolor[HTML]{8cb9e3}{10.40} & \cellcolor[HTML]{8cb9e3}{10.38}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{ffffff}{179.93} & \cellcolor[HTML]{ffffff}{180.20} & \cellcolor[HTML]{ffffff}{179.94} & \cellcolor[HTML]{ffffff}{179.97} & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{ffffff}{179.99} & \cellcolor[HTML]{8cb9e3}{10.11} & \cellcolor[HTML]{8cb9e3}{10.20} & \cellcolor[HTML]{8cb9e3}{10.34} & \cellcolor[HTML]{8cb9e3}{10.31} & \cellcolor[HTML]{8cb9e3}{10.27} & \cellcolor[HTML]{8cb9e3}{10.32}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 3 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upgamma_{fixed}$ (Triquarter-halfway delta) \\ Pop value = 20.00}} & \multicolumn{6}{c}{\thead{$\upgamma_{random}$ (Triquarter-halfway delta) \\ Pop value = 4.00}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{8cb9e3}{18.25} & \cellcolor[HTML]{8cb9e3}{18.11} & \cellcolor[HTML]{8cb9e3}{18.46} & \cellcolor[HTML]{8cb9e3}{19.67} & \cellcolor[HTML]{8cb9e3}{20.55} & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{8cb9e3}{17.69$^{\square}$} & \cellcolor[HTML]{8cb9e3}{17.05$^{\square}$} & \cellcolor[HTML]{8cb9e3}{16.38$^{\square}$} & \cellcolor[HTML]{8cb9e3}{15.03$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.63$^{\square}$} & \cellcolor[HTML]{8cb9e3}{9.02$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.25} & \cellcolor[HTML]{8cb9e3}{20.79} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{20.77} & \cellcolor[HTML]{8cb9e3}{20.98} & \cellcolor[HTML]{8cb9e3}{20.93} & \cellcolor[HTML]{8cb9e3}{ 9.22$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 7.32$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.12$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.99$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.45$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.69$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.88} & \cellcolor[HTML]{8cb9e3}{20.79} & \cellcolor[HTML]{8cb9e3}{20.84} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{ffffff}{20.74} & \cellcolor[HTML]{ffffff}{20.71} & \cellcolor[HTML]{8cb9e3}{ 5.30$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.95$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.34} & \cellcolor[HTML]{8cb9e3}{ 4.13} & \cellcolor[HTML]{8cb9e3}{ 4.05} & \cellcolor[HTML]{8cb9e3}{3.96}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time structured} & 11 & \cellcolor[HTML]{8cb9e3}{20.65} & \cellcolor[HTML]{8cb9e3}{20.74} & \cellcolor[HTML]{8cb9e3}{20.73} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{ffffff}{20.71} & \cellcolor[HTML]{ffffff}{20.67} & \cellcolor[HTML]{8cb9e3}{ 4.86$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.41$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.17} & \cellcolor[HTML]{8cb9e3}{ 4.13} & \cellcolor[HTML]{8cb9e3}{ 4.09} & \cellcolor[HTML]{8cb9e3}{4.03}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{18.57} & \cellcolor[HTML]{8cb9e3}{18.16} & \cellcolor[HTML]{8cb9e3}{18.59} & \cellcolor[HTML]{8cb9e3}{19.45} & \cellcolor[HTML]{8cb9e3}{20.15} & \cellcolor[HTML]{8cb9e3}{20.58} & \cellcolor[HTML]{8cb9e3}{16.85$^{\square}$} & \cellcolor[HTML]{8cb9e3}{16.21$^{\square}$} & \cellcolor[HTML]{8cb9e3}{14.96$^{\square}$} & \cellcolor[HTML]{8cb9e3}{13.48$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 9.94$^{\square}$} & \cellcolor[HTML]{8cb9e3}{7.72$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.39} & \cellcolor[HTML]{8cb9e3}{20.44} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{20.73} & \cellcolor[HTML]{8cb9e3}{20.77} & \cellcolor[HTML]{8cb9e3}{20.77} & \cellcolor[HTML]{8cb9e3}{ 9.65$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 7.07$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.25$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.47$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.61$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.34}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.54} & \cellcolor[HTML]{8cb9e3}{20.66} & \cellcolor[HTML]{8cb9e3}{20.75} & \cellcolor[HTML]{8cb9e3}{20.71} & \cellcolor[HTML]{ffffff}{20.72} & \cellcolor[HTML]{ffffff}{20.74} & \cellcolor[HTML]{8cb9e3}{ 5.27$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.68$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.59$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.08} & \cellcolor[HTML]{8cb9e3}{ 4.06} & \cellcolor[HTML]{8cb9e3}{4.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (fast response)} & 11 & \cellcolor[HTML]{8cb9e3}{20.77} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{8cb9e3}{20.72} & \cellcolor[HTML]{8cb9e3}{20.70} & \cellcolor[HTML]{ffffff}{20.71} & \cellcolor[HTML]{ffffff}{20.73} & \cellcolor[HTML]{8cb9e3}{ 4.85$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.68$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.29} & \cellcolor[HTML]{8cb9e3}{ 4.14} & \cellcolor[HTML]{8cb9e3}{ 4.16} & \cellcolor[HTML]{8cb9e3}{4.14}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{18.66} & \cellcolor[HTML]{8cb9e3}{17.88} & \cellcolor[HTML]{8cb9e3}{18.34} & \cellcolor[HTML]{8cb9e3}{19.83} & \cellcolor[HTML]{8cb9e3}{20.57} & \cellcolor[HTML]{8cb9e3}{20.67} & \cellcolor[HTML]{8cb9e3}{14.54$^{\square}$} & \cellcolor[HTML]{8cb9e3}{13.26$^{\square}$} & \cellcolor[HTML]{8cb9e3}{11.51$^{\square}$} & \cellcolor[HTML]{8cb9e3}{10.05$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 7.89$^{\square}$} & \cellcolor[HTML]{8cb9e3}{6.65$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.51} & \cellcolor[HTML]{8cb9e3}{20.73} & \cellcolor[HTML]{8cb9e3}{20.75} & \cellcolor[HTML]{8cb9e3}{20.89} & \cellcolor[HTML]{8cb9e3}{20.89} & \cellcolor[HTML]{8cb9e3}{20.86} & \cellcolor[HTML]{8cb9e3}{ 7.62$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.65$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.61$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.21$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.83$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.67$^{\square}$}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.91} & \cellcolor[HTML]{8cb9e3}{20.82} & \cellcolor[HTML]{8cb9e3}{20.82} & \cellcolor[HTML]{8cb9e3}{20.89} & \cellcolor[HTML]{8cb9e3}{20.94} & \cellcolor[HTML]{ffffff}{20.89} & \cellcolor[HTML]{8cb9e3}{ 6.00$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.32$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.97$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.67$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.74$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.70$^{\square}$}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response)} & 11 & \cellcolor[HTML]{8cb9e3}{20.98} & \cellcolor[HTML]{8cb9e3}{20.85} & \cellcolor[HTML]{8cb9e3}{20.90} & \cellcolor[HTML]{8cb9e3}{20.92} & \cellcolor[HTML]{ffffff}{20.90} & \cellcolor[HTML]{ffffff}{20.90} & \cellcolor[HTML]{8cb9e3}{ 5.26$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.92$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.83$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.69$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.75$^{\square}$} & \cellcolor[HTML]{8cb9e3}{4.71$^{\square}$}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{20.58} & \cellcolor[HTML]{8cb9e3}{20.64} & \cellcolor[HTML]{8cb9e3}{20.76} & \cellcolor[HTML]{8cb9e3}{20.86} & \cellcolor[HTML]{8cb9e3}{20.90} & \cellcolor[HTML]{8cb9e3}{20.94} & \cellcolor[HTML]{8cb9e3}{11.12$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 9.82$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 8.51$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 6.86$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.78$^{\square}$} & \cellcolor[HTML]{8cb9e3}{5.17$^{\square}$}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{20.55} & \cellcolor[HTML]{8cb9e3}{20.68} & \cellcolor[HTML]{8cb9e3}{20.73} & \cellcolor[HTML]{8cb9e3}{20.87} & \cellcolor[HTML]{8cb9e3}{20.81} & \cellcolor[HTML]{ffffff}{20.78} & \cellcolor[HTML]{8cb9e3}{ 6.68$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.93$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 5.14$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.74$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.11} & \cellcolor[HTML]{8cb9e3}{4.12}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.68} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.74} & \cellcolor[HTML]{ffffff}{20.70} & \cellcolor[HTML]{ffffff}{20.73} & \cellcolor[HTML]{8cb9e3}{ 5.22$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.77$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.53$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.24} & \cellcolor[HTML]{8cb9e3}{ 4.05} & \cellcolor[HTML]{8cb9e3}{4.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{8cb9e3}{20.66} & \cellcolor[HTML]{8cb9e3}{20.77} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{8cb9e3}{20.69} & \cellcolor[HTML]{ffffff}{20.67} & \cellcolor[HTML]{ffffff}{20.69} & \cellcolor[HTML]{8cb9e3}{ 4.79$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.72$^{\square}$} & \cellcolor[HTML]{8cb9e3}{ 4.32} & \cellcolor[HTML]{8cb9e3}{ 4.01} & \cellcolor[HTML]{8cb9e3}{ 4.14} & \cellcolor[HTML]{8cb9e3}{4.11}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 3 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\uptheta_{fixed}$ (Baseline) \\ Pop value = 3.00}} & \multicolumn{6}{c}{\thead{$\uptheta_{random}$ (Baseline) \\ Pop value = 0.05}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time structured} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (fast response)} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response)} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{ffffff}{3.00} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}
\begin{ThreePartTable}
\begin{TableNotes}
\item 
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccccccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 3 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upalpha_{fixed}$ (Maximal elevation) \\ Pop value = 3.32}} & \multicolumn{6}{c}{\thead{$\upalpha_{random}$ (Maximal elevation) \\ Pop value = 0.05}} \\
\cmidrule(l{3pt}r{3pt}){3-8} \cmidrule(l{3pt}r{3pt}){9-14}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000 & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time structured} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (fast response)} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response)} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-14}\pagebreak[0]
 & 5 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{ffffff}{3.32} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\addtocounter{table}{-1}

\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note. }Cells shaded in light blue indicate cells where estimation is imprecise (i.e., lower and/or upper whisker lengths exceeding 10\% of the parameter's population value. Empty superscript squares ($^{\square}$) indicate biased estimates (i.e., bias exceeding 10\% of parameter's population value).
\end{TableNotes}
\begin{longtable}[l]{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{3cm}cccccc}
\caption[]{Parameter Values Estimated for Day- and Likert-Unit Parameters in Experiment 3 (continued)}\\
\toprule
\multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{6}{c}{\thead{$\upepsilon$(error) \\ Pop value = 0.03}} \\
\cmidrule(l{3pt}r{3pt}){3-8}
Time Structuredness & Number of Measurements & 30 & 50 & 100 & 200 & 500 & 1000\\
\midrule
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time structured} & 11 & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (fast response)} & 11 & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response)} & 11 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\cmidrule{1-8}\pagebreak[0]
 & 5 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 7 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
 & 9 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\nopagebreak
\multirow{-4}{3cm}{\raggedright\arraybackslash Time unstructured (slow response) with definition variables} & 11 & \cellcolor[HTML]{8cb9e3}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05} & \cellcolor[HTML]{ffffff}{0.05}\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{landscape}
\restoregeometry

\app{OpenMx Code for Structured Latent Growth Curve Model With Definition Variables}

\label{def-model-code}

The code that I used to model logistic pattern of change using definition variables (see \protect\hyperlink{definition-variables}{definition variables}) is shown in Code Block \ref{definition-model}. Note that, the code is largely excerpted from the \texttt{run\_exp\_simulations()} and \texttt{create\_definition\_model()} functions from the \texttt{nonlinSims} package, and so readers interested in obtaining more information should consult the source code of this package. One important point to mention is that the model specified in Code Block \ref{definition-model} can accurately model time-unstructured data because it uses definition variables.

\captionof{chunk}{OpenMx Code for Structured Latent Growth Curve Model With Definition Variables}\restoreparindent\label{definition-model}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{\#Now convert data to wide format (needed for OpenMx)}
\NormalTok{data\_wide }\OtherTok{\textless{}{-}}\NormalTok{ data[ , }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ measurement\_day, }\AttributeTok{values\_from =} \FunctionTok{c}\NormalTok{(obs\_score, actual\_measurement\_day))}

\CommentTok{\#Definition variable (data. prefix tells OpenMx to use recorded time of observation for each person\textquotesingle{}s data)}
\NormalTok{obs\_score\_days }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}data.\textquotesingle{}}\NormalTok{, }\FunctionTok{extract\_obs\_score\_days}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data\_wide), }\AttributeTok{sep =} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{) }

\CommentTok{\#Remove . from column names so that OpenMx does not run into error (this occurs because, with some spacing schedules, measurement days are not integer values.) }
\FunctionTok{names}\NormalTok{(data\_wide) }\OtherTok{\textless{}{-}} \FunctionTok{str\_replace}\NormalTok{(}\AttributeTok{string =} \FunctionTok{names}\NormalTok{(data\_wide), }\AttributeTok{pattern =} \StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.\textquotesingle{}}\NormalTok{, }\AttributeTok{replacement =} \StringTok{\textquotesingle{}\_\textquotesingle{}}\NormalTok{)}

\CommentTok{\#Latent variable names (theta = baseline, alpha = maximal elevation, beta = days{-}to{-}halfway elevation, gamma = triquarter{-}halfway elevation)}
\NormalTok{latent\_vars }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{) }

\NormalTok{def\_growth\_curve\_model }\OtherTok{\textless{}{-}} \FunctionTok{mxModel}\NormalTok{(}
  \AttributeTok{model =}\NormalTok{ model\_name,}
  \AttributeTok{type =} \StringTok{\textquotesingle{}RAM\textquotesingle{}}\NormalTok{, }\AttributeTok{independent =}\NormalTok{ T,}
  \FunctionTok{mxData}\NormalTok{(}\AttributeTok{observed =}\NormalTok{ data\_wide, }\AttributeTok{type =} \StringTok{\textquotesingle{}raw\textquotesingle{}}\NormalTok{),}
  
  \AttributeTok{manifestVars =}\NormalTok{ manifest\_vars,}
  \AttributeTok{latentVars =}\NormalTok{ latent\_vars,}
  
  \CommentTok{\#Residual variances; by using one label, they are assumed to all be equal (homogeneity of variance). That is, there is no complex error structure. }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =}\NormalTok{ manifest\_vars,}
         \AttributeTok{arrows=}\DecValTok{2}\NormalTok{, }\AttributeTok{free=}\ConstantTok{TRUE}\NormalTok{,  }\AttributeTok{labels=}\StringTok{\textquotesingle{}epsilon\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{),}
  
  \CommentTok{\#Latent variable covariances and variances (note that only the variances are estimated. )}
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =}\NormalTok{ latent\_vars,}
         \AttributeTok{connect=}\StringTok{\textquotesingle{}unique.pairs\textquotesingle{}}\NormalTok{, }\AttributeTok{arrows=}\DecValTok{2}\NormalTok{,}
         \AttributeTok{free =} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{,}\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }
                  \ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }
                  \ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }
                  \ConstantTok{TRUE}\NormalTok{), }
         \AttributeTok{values=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                  \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                  \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{,}
                  \DecValTok{1}\NormalTok{),}
         \AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\_rand\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_theta\_alpha)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_theta\_beta)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}NA(cov\_theta\_gamma)\textquotesingle{}}\NormalTok{,}
                  \StringTok{\textquotesingle{}alpha\_rand\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}NA(cov\_alpha\_beta)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_alpha\_gamma)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}beta\_rand\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}NA(cov\_beta\_gamma)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}gamma\_rand\textquotesingle{}}\NormalTok{), }
         \AttributeTok{lbound =} \FunctionTok{c}\NormalTok{(}\FloatTok{1e{-}3}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \FloatTok{1e{-}3}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{,}
                    \DecValTok{1}\NormalTok{), }
         \AttributeTok{ubound =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{90}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }
                    \DecValTok{45}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)),}
  
  \CommentTok{\# Latent variable means (linear parameters). Note that the parameters of beta and gamma do not have estimated means because they are nonlinear parameters (i.e., the logistic function\textquotesingle{}s first{-}order partial derivative with respect to each of those two parameters contains those two parameters)}
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =} \StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{, }\AttributeTok{to =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{), }\AttributeTok{free =} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{), }\AttributeTok{arrows =} \DecValTok{1}\NormalTok{,}
         \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}theta\_fixed\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}alpha\_fixed\textquotesingle{}}\NormalTok{), }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{, }\AttributeTok{ubound =} \DecValTok{7}\NormalTok{, }
         \AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)),}
  
  \CommentTok{\#Functional constraints (needed to estimate mean values of fixed{-}effect parameters)}
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}theta\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{,  }\AttributeTok{ubound =} \DecValTok{7}\NormalTok{), }
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}alpha\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{0}\NormalTok{,  }\AttributeTok{ubound =} \DecValTok{7}\NormalTok{), }
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}beta\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{1}\NormalTok{, }\AttributeTok{ubound =} \DecValTok{360}\NormalTok{),}
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(manifest\_vars), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{labels =} \StringTok{\textquotesingle{}gamma\_fixed\textquotesingle{}}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}g\textquotesingle{}}\NormalTok{, }\AttributeTok{values =} \DecValTok{1}\NormalTok{, }\AttributeTok{lbound =} \DecValTok{1}\NormalTok{, }\AttributeTok{ubound =} \DecValTok{360}\NormalTok{), }

  \CommentTok{\#Definition variables set for loadings (accounts for time{-}unstructured data) }
  \FunctionTok{mxMatrix}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}Full\textquotesingle{}}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(obs\_score\_days), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{free =} \ConstantTok{FALSE}\NormalTok{, }
  \AttributeTok{labels =}\NormalTok{ obs\_score\_days, }\AttributeTok{name =} \StringTok{\textquotesingle{}time\textquotesingle{}}\NormalTok{),}

  \CommentTok{\#Algebra specifying first{-}order partial derivatives; }
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g)), }\AttributeTok{name=}\StringTok{"Tl"}\NormalTok{),}
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g)), }\AttributeTok{name =} \StringTok{\textquotesingle{}Al\textquotesingle{}}\NormalTok{), }
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =} \SpecialCharTok{{-}}\NormalTok{((a }\SpecialCharTok{{-}}\NormalTok{ t) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{g))}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\AttributeTok{name =} \StringTok{\textquotesingle{}Bl\textquotesingle{}}\NormalTok{),}
  \FunctionTok{mxAlgebra}\NormalTok{(}\AttributeTok{expression =}\NormalTok{  (a }\SpecialCharTok{{-}}\NormalTok{ t) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g) }\SpecialCharTok{*}\NormalTok{ ((b }\SpecialCharTok{{-}}\NormalTok{ time)}\SpecialCharTok{/}\NormalTok{g}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((b }\SpecialCharTok{{-}}\NormalTok{time)}\SpecialCharTok{/}\NormalTok{g))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}Gl\textquotesingle{}}\NormalTok{),}
  
  \CommentTok{\#Factor loadings; all fixed and, importantly, constrained to change according to their partial derivatives (i.e., nonlinear functions) }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =} \StringTok{\textquotesingle{}theta\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{, }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,  }
         \AttributeTok{labels =} \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Tl[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))),}
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from =} \StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{, }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,  }
         \AttributeTok{labels =} \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Al[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))), }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{,  }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,}
         \AttributeTok{labels =}  \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Bl[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))), }
  \FunctionTok{mxPath}\NormalTok{(}\AttributeTok{from=}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{, }\AttributeTok{to =}\NormalTok{ manifest\_vars, }\AttributeTok{arrows=}\DecValTok{1}\NormalTok{,  }\AttributeTok{free=}\ConstantTok{FALSE}\NormalTok{,}
         \AttributeTok{labels =}  \FunctionTok{sprintf}\NormalTok{(}\AttributeTok{fmt =} \StringTok{\textquotesingle{}Gl[\%d,1]\textquotesingle{}}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(manifest\_vars))), }
  
  \CommentTok{\#Fit function used to estimate free parameter values. }
  \FunctionTok{mxFitFunctionML}\NormalTok{(}\AttributeTok{vector =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{)}

\CommentTok{\#Fit model using mxTryHard(). Increases probability of convergence by attempting model convergence by randomly shifting starting values. }
\NormalTok{model\_results }\OtherTok{\textless{}{-}} \FunctionTok{mxTryHard}\NormalTok{(def\_growth\_curve\_model)}
\end{Highlighting}
\end{Shaded}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(easypackages)}
\NormalTok{packages }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}nonlinSims\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}tidyverse\textquotesingle{}}\NormalTok{)}
\FunctionTok{libraries}\NormalTok{(packages)}

\NormalTok{theta }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FloatTok{3.32}
\NormalTok{beta }\OtherTok{\textless{}{-}} \DecValTok{180}
\NormalTok{gamma }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{time }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{360}

\CommentTok{\#curve scores}
\NormalTok{logistic\_curve }\OtherTok{\textless{}{-}}\NormalTok{ theta }\SpecialCharTok{+}\NormalTok{ (alpha }\SpecialCharTok{{-}}\NormalTok{ theta)}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((beta}\SpecialCharTok{{-}}\NormalTok{time)}\SpecialCharTok{/}\NormalTok{gamma))}

\NormalTok{logistic\_data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}score\textquotesingle{}} \OtherTok{=}\NormalTok{ logistic\_curve, }
                            \StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=}\NormalTok{ time)}

\CommentTok{\#day scores}
\NormalTok{equal\_spacing\_5 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{5}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}
\NormalTok{equal\_spacing\_7 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{7}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}
\NormalTok{equal\_spacing\_9 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{9}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}
\NormalTok{equal\_spacing\_11 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{11}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}


\CommentTok{\#provide curve score for each point }
\NormalTok{equal\_spacing\_5}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ equal\_spacing\_5}\SpecialCharTok{$}\NormalTok{day]}
\NormalTok{equal\_spacing\_7}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ equal\_spacing\_7}\SpecialCharTok{$}\NormalTok{day]}
\NormalTok{equal\_spacing\_9}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ equal\_spacing\_9}\SpecialCharTok{$}\NormalTok{day]}
\NormalTok{equal\_spacing\_11}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ equal\_spacing\_11}\SpecialCharTok{$}\NormalTok{day]}

\CommentTok{\#spacing schedules}
\NormalTok{equal\_spacing\_5 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{5}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}equal\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}
\NormalTok{time\_inc\_5 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{5}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}time\_inc\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}
\NormalTok{time\_dec\_5 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{5}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}time\_dec\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}
\NormalTok{mid\_ext\_5 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\StringTok{\textquotesingle{}day\textquotesingle{}} \OtherTok{=} \FunctionTok{compute\_measurement\_schedule}\NormalTok{(}\AttributeTok{time\_period =} \DecValTok{360}\NormalTok{, }\AttributeTok{num\_measurements =} \DecValTok{5}\NormalTok{, }\AttributeTok{smallest\_int\_length =} \DecValTok{30}\NormalTok{, }\AttributeTok{measurement\_spacing =} \StringTok{\textquotesingle{}mid\_ext\textquotesingle{}}\NormalTok{)}\SpecialCharTok{$}\NormalTok{measurement\_days)}

\NormalTok{time\_inc\_5}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ time\_inc\_5}\SpecialCharTok{$}\NormalTok{day]}
\NormalTok{time\_dec\_5}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ time\_dec\_5}\SpecialCharTok{$}\NormalTok{day]}
\NormalTok{mid\_ext\_5}\SpecialCharTok{$}\NormalTok{score }\OtherTok{\textless{}{-}}\NormalTok{ logistic\_data}\SpecialCharTok{$}\NormalTok{score[logistic\_data}\SpecialCharTok{$}\NormalTok{day }\SpecialCharTok{\%in\%}\NormalTok{ mid\_ext\_5}\SpecialCharTok{$}\NormalTok{day]}




\NormalTok{mid\_ext\_5 }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ logistic\_data, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ day, }\AttributeTok{y =}\NormalTok{ score)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linewidth =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ mid\_ext\_5, }\AttributeTok{size =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{name =} \StringTok{\textquotesingle{}Day\textquotesingle{}}\NormalTok{, }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{360}\NormalTok{, }\AttributeTok{by =} \DecValTok{60}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{name =} \StringTok{\textquotesingle{}Score\textquotesingle{}}\NormalTok{, }\AttributeTok{breaks =} \ConstantTok{NULL}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{(}\AttributeTok{base\_family =} \StringTok{\textquotesingle{}Helvetica\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{\textquotesingle{}black\textquotesingle{}}\NormalTok{, }\AttributeTok{size =} \DecValTok{16}\NormalTok{), }
        \AttributeTok{axis.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{20}\NormalTok{))}

\FunctionTok{ggsave}\NormalTok{(}\AttributeTok{filename =} \StringTok{\textquotesingle{}Figures/mid\_ext\_5.png\textquotesingle{}}\NormalTok{, }\AttributeTok{plot =}\NormalTok{ mid\_ext\_5, }\AttributeTok{width =} \DecValTok{8}\NormalTok{, }\AttributeTok{height =} \DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



\end{document}
